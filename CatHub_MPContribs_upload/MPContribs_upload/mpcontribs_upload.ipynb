{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "from mpcontribs.client import load_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase\n",
    "\n",
    "ase.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read IrOx DFT Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "import pickle; import os\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/processing_bulk_dft/creating_final_dataset_for_upload\",\n",
    "    \"out_data/df_dft_final_no_dupl.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_dft = pickle.load(fle)\n",
    "# #########################################################\n",
    "\n",
    "df_dft = df_dft.drop(columns=[\"id\", \"form_e_chris\", \"path\", \"source\"])\n",
    "df_dft = df_dft.sort_values([\"stoich\", \"dH\"])\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "# df_dft = df_dft.iloc[0:16]\n",
    "# df_dft = df_dft.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dft = df_dft.loc[[\n",
    "#     '94x5nkmjmf',\n",
    "#     'cazivwbq94',\n",
    "#     '8kvd8qnim4',\n",
    "#     '656qniby7j',\n",
    "#     '9yn4m16ux1',\n",
    "#     'cfzam1mdbf',\n",
    "#     'zy9dzknhnj',\n",
    "#     'zanqv2xtvk',\n",
    "#     'njntmu9w93',\n",
    "#     'mrbine8k72',\n",
    "\n",
    "#     'cg8p7fxq65',\n",
    "#     '64cg6j9any',\n",
    "#     '85z4msnl6o',\n",
    "#     'xozr8f7p7g',\n",
    "#     '949rnem5z2',\n",
    "#     'mkmsvkcyc5',\n",
    "#     'vwxfn3blxi',\n",
    "#     'nrml6dms9l',\n",
    "#     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "sys.path.insert(0, \n",
    "    os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        \"workflow/ml_modelling\"))\n",
    "\n",
    "from ml_methods import get_ml_dataframes\n",
    "DF_dict = get_ml_dataframes(\n",
    "    names=[\n",
    "        'static_irox_structures_path',\n",
    "        'df_prototype_dft_path',\n",
    "        'df_prototype_static_path',\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df_prototype_static = DF_dict[\"df_prototype_static\"]\n",
    "df_prototype_dft = DF_dict[\"df_prototype_dft\"]\n",
    "\n",
    "static_irox_structures = DF_dict['static_irox_structures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "import pickle; import os\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"CatHub_MPContribs_upload/MPContribs_upload/duplicate_MP_entries\",\n",
    "    \"out_data/df_mp_dupl.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_mp_dupl = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add 'Formula' Column to df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    stoich_to_form_dict = {\n",
    "        \"AB2\": \"IrO2\",\n",
    "        \"AB3\": \"IrO3\"}\n",
    "\n",
    "    stoich = row_i.stoich\n",
    "    formula = stoich_to_form_dict.get(stoich)\n",
    "    return(formula)\n",
    "\n",
    "df_i = df_dft\n",
    "df_i[\"formula\"] = df_i.apply(\n",
    "    method,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPContribs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "path_i = os.path.join(os.environ[\"PROJ_irox\"], \"config\", \"config.yml\")\n",
    "with open(path_i) as file:\n",
    "    config_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "api_key = config_dict[\"mpcontrib\"][\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'active_learned_irox_polymorphs'\n",
    "\n",
    "client = load_client(api_key)\n",
    "\n",
    "# print(dir(client))\n",
    "# print(dir(client.projects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting all data to start over"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 1234\n",
    "while total_count != 0:\n",
    "    deleted = client.contributions.delete_entries(project=project).result()\n",
    "\n",
    "    total_count = deleted[\"total_count\"]\n",
    "    num_deleted = deleted[\"count\"]\n",
    "\n",
    "    print(\n",
    "        num_deleted, 'contribution(s) deleted',\n",
    "        \"|\",\n",
    "        total_count, \"contribution(s) remaining\")\n",
    "\n",
    "# Delete entire project to start from scratch\n",
    "# DON'T DO THIS (PATRICK HAS TO MANUALLY APPROVE PROJECT EVERYTIME)\n",
    "if False:\n",
    "    results = client.projects.delete_entry(pk=project).result()\n",
    "\n",
    "# client.projects.delete_entry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Project (Once)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_public = True\n",
    "info = {\"project\": project}\n",
    "\n",
    "# CREATE PROJECT FROM SCRATCH (DO THIS SELDOMLY)\n",
    "# DON'T DO THIS (PATRICK HAS TO MANUALLY APPROVE PROJECT EVERYTIME)\n",
    "if False:\n",
    "# if True:\n",
    "    client.projects.create_entry(project=info).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    all_data = client.projects.get_entry(pk=project, _fields=['_all']).result()\n",
    "    # all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding new data rows"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = dict()\n",
    "for ind_i, row_i in df_dft.iterrows():\n",
    "    stoich = row_i.stoich\n",
    "    dH = row_i.dH\n",
    "    formula = row_i.formula\n",
    "    energy_pa = row_i.energy_pa\n",
    "    num_atoms = row_i.num_atoms\n",
    "    volume = row_i.volume\n",
    "    volume_pa = row_i.volume_pa\n",
    "\n",
    "    # #####################################################\n",
    "    if ind_i in df_prototype_dft.index:\n",
    "        row_proto_dft = df_prototype_dft.loc[ind_i]\n",
    "\n",
    "        prototype_name_dft = row_proto_dft.p_name\n",
    "        spacegroup_dft = int(row_proto_dft.spacegroup)\n",
    "    else:\n",
    "        print(\"Woops\", ind_i)\n",
    "        \n",
    "        prototype_name_dft = \"\"\n",
    "        spacegroup_dft = None\n",
    "\n",
    "    # #########################################################\n",
    "    if ind_i in df_prototype_static.index:\n",
    "        row_proto_static_i = df_prototype_static.loc[ind_i]\n",
    "\n",
    "        prototype_name_static = row_proto_static_i.p_name\n",
    "        spacegroup_static = int(row_proto_static_i.spacegroup)\n",
    "    else:\n",
    "        print(\"Woops\", ind_i)\n",
    "\n",
    "        prototype_name_static = \"\"\n",
    "        spacegroup_static = None\n",
    "\n",
    "    # prototype_name_static = prototype_name_static\n",
    "\n",
    "    # #####################################################\n",
    "    # #####################################################\n",
    "    dH = str(dH) + \" eV/atom\"\n",
    "    dft_energy_per_atom = str(energy_pa) + \" eV/atom\"\n",
    "    number_of_atoms = num_atoms\n",
    "    volume = str(volume) + \" angstrom**3\"\n",
    "    volume_pa = str(volume_pa) + \" angstrom**3/atom\"\n",
    "\n",
    "    # #####################################################\n",
    "    # Setting the MP id as identifier if available ########\n",
    "    identifier_i = ind_i\n",
    "    if ind_i in df_mp_dupl.index:\n",
    "        row_i = df_mp_dupl.loc[ind_i]\n",
    "        # row_i = df_mp_dupl.loc[\"cg8p7fxq65\"]\n",
    "\n",
    "        mp_duplicates = row_i.mp_duplicates\n",
    "        if len(mp_duplicates) > 1:\n",
    "            print(\"There is more than 1 MP duplicate found\")\n",
    "        if len(mp_duplicates) == 0:\n",
    "            print(\"There is no MP duplicate for this entry, but there should be\")\n",
    "\n",
    "        mp_duplicate = mp_duplicates[0]\n",
    "        identifier_i = mp_duplicate    \n",
    "    \n",
    "    # #####################################################\n",
    "    contributions[ind_i] = dict(\n",
    "        contrib=dict(\n",
    "            identifier=identifier_i,\n",
    "            # identifier=ind_i,\n",
    "            # identifier=\"NA\", project=project, is_public=is_public,\n",
    "            project=project, is_public=is_public,\n",
    "            data={\n",
    "                \"InternalID\": row_i.name,\n",
    "\n",
    "                \"\u0394H|formation\": dH,\n",
    "                \"Formula\": formula,\n",
    "                \"EnergyDFT\": dft_energy_per_atom,\n",
    "                \"NumberOfAtoms\": number_of_atoms,\n",
    "                \"Volume|UnitCell\": volume,\n",
    "                \"Volume\": volume_pa,\n",
    "\n",
    "                \"StructurePrototype|PreDFT\": prototype_name_static,\n",
    "                \"StructurePrototype|PostDFT\": prototype_name_dft,\n",
    "                \"SpaceGroupNumber|PreDFT\": spacegroup_static,\n",
    "                \"SpaceGroupNumber|PostDFT\": spacegroup_dft,\n",
    "                },\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    contribs = []\n",
    "    for key, val in contributions.items():\n",
    "        contribs.append(val[\"contrib\"])\n",
    "\n",
    "    chunk_size = 20\n",
    "    df_mp_list = []\n",
    "    for contribs_chunk_i in chunks(contribs, chunk_size):\n",
    "\n",
    "        created = client.contributions.create_entries(\n",
    "            contributions=contribs_chunk_i).result()\n",
    "\n",
    "        df_mp_i = pd.DataFrame(created[\"data\"]).set_index(\"identifier\")\n",
    "        df_mp_list.append(df_mp_i)\n",
    "\n",
    "\n",
    "df_mp = pd.concat(df_mp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Structures"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for id_chunk_i in chunks(df_mp.index.tolist(), chunk_size):\n",
    "    df_mp_i = df_mp.loc[id_chunk_i]\n",
    "\n",
    "    structure_contribs = []\n",
    "    for id_i, row_i in df_mp_i.iterrows():\n",
    "        print(id_i)\n",
    "\n",
    "        cid = row_i.id\n",
    "\n",
    "        # #####################################################\n",
    "        #  DFT Data ###########################################\n",
    "        row_dft_i= df_dft.loc[id_i]\n",
    "\n",
    "        formula = row_dft_i.formula\n",
    "        atoms_final = row_dft_i.atoms\n",
    "\n",
    "        # #####################################################\n",
    "        # Static IrOx #########################################\n",
    "        row_static_i = static_irox_structures.loc[id_i]\n",
    "\n",
    "        atoms_init = row_static_i.atoms\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        # #####################################################\n",
    "        structure_final = AseAtomsAdaptor.get_structure(atoms_final)\n",
    "        structure_init = AseAtomsAdaptor.get_structure(atoms_init)\n",
    "\n",
    "        # #####################################################\n",
    "        sdct = dict(contribution=cid,\n",
    "            name=id_i + \"_final\",\n",
    "            label=\"Final_DFT_Optimized\",\n",
    "            )\n",
    "        sdct.update(structure_final.as_dict())\n",
    "        structure_contribs.append(sdct)\n",
    "        # print(id_i + \"_final\")\n",
    "\n",
    "        sdct = dict(contribution=cid,\n",
    "            name=id_i + \"_init\",\n",
    "            # label=\"Initialstructuralprototype\",\n",
    "            label=\"Initial_Prototype\",\n",
    "            )\n",
    "        sdct.update(structure_init.as_dict())\n",
    "        structure_contribs.append(sdct)\n",
    "        # print(id_i + \"_init\")\n",
    "\n",
    "    sid = client.structures.create_entries(structures=structure_contribs).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data with `get_entries` methods"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# identifier = \"mp-1234\"\n",
    "\n",
    "# client.contributions.get_entries(\n",
    "#     project=project,\n",
    "#     identifier=identifier,\n",
    "#     # _fields=[\"formula\"],\n",
    "#     ).result()\n",
    "#     # ).result()['data']\n",
    "\n",
    "# # client.projects.get_entries?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mpcontribs]",
   "language": "python",
   "name": "conda-env-mpcontribs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
