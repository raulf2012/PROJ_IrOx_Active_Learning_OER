{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# #########################################################\n",
    "from ase import io\n",
    "\n",
    "# #########################################################\n",
    "from misc_modules.misc_methods import GetUniqueFriendlyID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of locations with an OUTCAR file: \n",
      " 879\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.join(\n",
    "    os.environ[\"gdrive\"],\n",
    "    \"norskov_research_storage/nersc/IrOx_Project_temp_190510\")\n",
    "outcar_locations = []\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    if \"OUTCAR\" in files:\n",
    "        # print(subdir)\n",
    "        outcar_locations.append(subdir)\n",
    "\n",
    "print(\"Number of locations with an OUTCAR file:\", \"\\n\", len(outcar_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/f/GDrive/norskov_research_storage/nersc/IrOx_Project_temp_190510/__temp__/1-att/_3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_i = \"/mnt/f/GDrive/norskov_research_storage/nersc/IrOx_Project_temp_190510/01_surface_calcs/IrO2/100/01_layers/_1\"\n",
    "# path_i = \"/mnt/f/GDrive/norskov_research_storage/nersc/IrOx_Project_temp_190510/01_surface_calcs/IrO2/100/03_layers/2-temp\"\n",
    "\n",
    "def include_path(path_i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # #########################################################\n",
    "    last_dir = path_i.split(\"/\")[-1]\n",
    "\n",
    "    start_with_ = False\n",
    "    if last_dir[0] == \"_\":\n",
    "        start_with_ = True\n",
    "\n",
    "    bool_list = []\n",
    "    for i in last_dir[1:]:\n",
    "        bool_list.append(i.isnumeric())\n",
    "    all_numeric = all(bool_list)\n",
    "\n",
    "    correct_format = False\n",
    "    if start_with_ and all_numeric:\n",
    "        correct_format = True\n",
    "\n",
    "    # #########################################################\n",
    "    blacklist_folders = [\"__temp__\", \"__failed__\"]\n",
    "    blacklist_path = False\n",
    "    for blacklist_i in blacklist_folders:\n",
    "        if blacklist_i in path_i:\n",
    "            blacklist_path = True\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "\n",
    "    include_path = False\n",
    "    if correct_format and not blacklist_path:\n",
    "        include_path = True\n",
    "    \n",
    "    return(include_path)\n",
    "\n",
    "def parse_cpu_time(outcar_lines):\n",
    "    # outcar_list = row_i.outcar\n",
    "    outcar_list = outcar_lines\n",
    "    search_lines = [i for i in outcar_list if \"Total CPU time used\" in i]\n",
    "    if len(search_lines) == 1:\n",
    "        time_i = float(search_lines[0].split()[-1])\n",
    "        return(time_i)    \n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "def get_prepath_rev_att(path_i):\n",
    "    # #########################################################\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    # #########################################################\n",
    "    pre_path = \"/\".join(path_i.split(\"/\")[0:-1])\n",
    "    data_dict_i[\"pre_path\"] = pre_path\n",
    "\n",
    "    # #########################################################\n",
    "    last_dir = path_i.split(\"/\")[-1]\n",
    "    rev_i = int(last_dir[1:])\n",
    "    data_dict_i[\"rev\"] = rev_i\n",
    "\n",
    "    # #########################################################\n",
    "    dir_i = path_i.split(\"/\")[-2]\n",
    "    if \"_attempt\" in dir_i:\n",
    "        att_i = int(dir_i.split(\"_\")[0])\n",
    "    else:\n",
    "        att_i = None\n",
    "    data_dict_i[\"attempt\"] = att_i\n",
    "\n",
    "    return(data_dict_i)\n",
    "\n",
    "def scf_cycles_model(slope, intercept, num_atoms=None):\n",
    "    y = slope * num_atoms + intercept\n",
    "\n",
    "    print(\"y:\", y)\n",
    "\n",
    "    out = 10 ** (y)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "# outcar_locations = outcar_locations[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for dir_i in outcar_locations:\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    data_dict_i[\"path\"] = dir_i\n",
    "\n",
    "    # #####################################################\n",
    "    include_path_i = include_path(dir_i)\n",
    "    data_dict_i[\"include\"] = include_path_i\n",
    "\n",
    "    if include_path_i:\n",
    "        out_dict = get_prepath_rev_att(dir_i)\n",
    "\n",
    "        data_dict_i[\"attempt\"] = out_dict[\"attempt\"]\n",
    "        data_dict_i[\"rev\"] = out_dict[\"rev\"]\n",
    "        data_dict_i[\"pre_path\"] = out_dict[\"pre_path\"]\n",
    "\n",
    "    # #####################################################\n",
    "    is_vib_calc = False\n",
    "    for file_i in listdir(dir_i):\n",
    "        if \".eq.pckl\" in file_i:\n",
    "            is_vib_calc = True\n",
    "\n",
    "    data_dict_i[\"vib_calc\"] = is_vib_calc\n",
    "    \n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "df_vib = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# df_vib[df_vib.vib_calc == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict_list = []\n",
    "# # for dir_i in outcar_locations:\n",
    "# iterator = tqdm(outcar_locations, desc=\"1st loop\")\n",
    "# for i_cnt, dir_i in enumerate(iterator):\n",
    "#     tmp = 42\n",
    "\n",
    "#     data_dict_i = dict()\n",
    "#     # print(\"dir_i:\", dir_i)\n",
    "#     print(dir_i)\n",
    "\n",
    "#     data_dict_i[\"path\"] = dir_i\n",
    "\n",
    "#     # #####################################################\n",
    "#     num_images = None\n",
    "#     try:\n",
    "#         traj = io.read(\n",
    "#             os.path.join(dir_i, \"OUTCAR\"),\n",
    "#             index=\":\")\n",
    "#         num_images = len(traj)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "#     data_dict_i[\"num_images\"] = num_images\n",
    "            \n",
    "#     # #####################################################\n",
    "#     for file_i in listdir(path=dir_i):\n",
    "\n",
    "\n",
    "#         if \"init\" in file_i:\n",
    "            \n",
    "#             atoms_i = io.read(\n",
    "#                 os.path.join(\n",
    "#                     dir_i,\n",
    "#                     file_i))\n",
    "\n",
    "#             # atoms_i = traj[-1]\n",
    "#             num_atoms = atoms_i.get_number_of_atoms()\n",
    "#             data_dict_i[\"num_atoms\"] = num_atoms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             break\n",
    "\n",
    "#     # #####################################################\n",
    "#     path_i = os.path.join(dir_i, \"OUTCAR\")\n",
    "#     my_file = Path(path_i)\n",
    "#     if my_file.is_file():\n",
    "#         with open(path_i, \"r\") as f:\n",
    "#             outcar_lines = f.read().splitlines()\n",
    "\n",
    "#         num_lines = len(outcar_lines)\n",
    "\n",
    "#         cpu_time_i = parse_cpu_time(outcar_lines)\n",
    "\n",
    "#         data_dict_i[\"time\"] = cpu_time_i\n",
    "#         data_dict_i[\"num_OUTCAR_lines\"] = num_lines\n",
    "#         data_dict_list.append(data_dict_i)\n",
    "\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# df = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# ids_list = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     id_i = GetUniqueFriendlyID(ids_list)\n",
    "#     ids_list.append(id_i)\n",
    "\n",
    "# df[\"ids\"] = ids_list\n",
    "# df = df.set_index(\"ids\")\n",
    "\n",
    "# df[\"time_min\"] = df.time / 60\n",
    "\n",
    "# print(\"Number of rows\", df.shape[0])\n",
    "\n",
    "# # Pickling data ###########################################\n",
    "# import os; import pickle\n",
    "# directory = \"out_data\"\n",
    "# if not os.path.exists(directory): os.makedirs(directory)\n",
    "# with open(os.path.join(directory, \"df_outcar.pickle\"), \"wb\") as fle:\n",
    "#     pickle.dump(df, fle)\n",
    "# # #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "import pickle; import os\n",
    "path_i = os.path.join(\"out_data\", \"df_outcar.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"images_per_min\"] = df.num_images / df.time_min\n",
    "\n",
    "df[\"images_per_min_log\"] = np.log(df.images_per_min)\n",
    "\n",
    "df = pd.concat([\n",
    "    df.reset_index().set_index(\"path\"),\n",
    "    df_vib.reset_index().set_index(\"path\"),\n",
    "    ], axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.set_index(\"ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df\n",
    "\n",
    "df_i = df_i[df_i.vib_calc == False]\n",
    "df_i = df_i[df_i.include == True]\n",
    "df_i = df_i[~df_i.time.isnull()]\n",
    "\n",
    "\n",
    "# df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log-linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y = df_i.images_per_min_log.tolist()\n",
    "\n",
    "X = df_i.num_atoms.to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)\n",
    "\n",
    "print(\"reg.coef_:\", reg.coef_)\n",
    "print(\"reg.intercept_:\", reg.intercept_)\n",
    "\n",
    "x_array = np.linspace(0, 100, num=101).reshape(-1, 1)\n",
    "y_array = [10 ** (i) for i in reg.predict(x_array)]\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "trace = go.Scatter(\n",
    "    x=x_array.flatten(),\n",
    "    y=y_array,\n",
    "    # text=df.index,\n",
    "    name=\"log-linear model\",\n",
    "    mode=\"lines\",\n",
    "    )\n",
    "data.append(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scf_poly_model(num_atoms, m0=None, m1=None, m2=None):\n",
    "\n",
    "\n",
    "    # X_min_ = poly.fit_transform(num_atoms)\n",
    "    # scf_per_min_i = lg.predict(X_min_)[0]\n",
    "\n",
    "    # print(\"m0:\", m0, \"m1:\", m1, \"m2:\", m2)\n",
    "\n",
    "    # #####################################################\n",
    "    scf_per_min_i = 0 + \\\n",
    "        (m0) * (num_atoms ** 0) + \\\n",
    "        (m1) * (num_atoms ** 1) + \\\n",
    "        (m2) * (num_atoms ** 2)\n",
    "    return(scf_per_min_i)\n",
    "\n",
    "def scf_per_min_model(num_atoms=None):\n",
    "    # m0 = lg.intercept_\n",
    "    # m1 = lg.coef_[1]\n",
    "    # m2 = lg.coef_[2]\n",
    "\n",
    "    m0 = +6.47968662\n",
    "    m1 = -0.12968329\n",
    "    m2 = +0.00068543\n",
    "\n",
    "\n",
    "    # min_x = -(m1 / (2 * m2))\n",
    "    x_min = -(m1 / (2 * m2))\n",
    "\n",
    "    X_min = np.array([x_min]).reshape(-1, 1)\n",
    "\n",
    "    y_min = scf_poly_model(x_min, m0=m0, m1=m1, m2=m2)\n",
    "\n",
    "    \n",
    "    # Linear region paramters\n",
    "    max_lin_x = 200  # End of linear region\n",
    "    x0 = x_min\n",
    "    y0 = y_min\n",
    "    x1 = max_lin_x\n",
    "    y1 = 0.06\n",
    "    if num_atoms >= x_min and num_atoms <= max_lin_x:\n",
    "        m = (y1 - y0) / (x1 - x0)\n",
    "        b = (x1 * y0 - x0 * y1) / (x1 - x0)\n",
    "\n",
    "        scf_per_min_i = m * num_atoms + b\n",
    "\n",
    "        # print(\"min_y:\", min_y)\n",
    "        # scf_per_min_i = y_min / 2\n",
    "\n",
    "    elif num_atoms > max_lin_x:\n",
    "        scf_per_min_i = y1\n",
    "\n",
    "    else:\n",
    "        scf_per_min_i = scf_poly_model(num_atoms, m0=m0, m1=m1, m2=m2)\n",
    "\n",
    "        # X_test = np.array([num_atoms, ]).reshape(-1, 1)\n",
    "        # X_test_ = poly.fit_transform(X_test)\n",
    "        # scf_per_min_i = lg.predict(X_test_)[0]\n",
    "\n",
    "    return(scf_per_min_i)\n",
    "\n",
    "def calc_wall_time(num_atoms=None, num_scf=None):\n",
    "    scf_per_min_i = scf_per_min_model(num_atoms=num_atoms)\n",
    "    wall_time_i = num_scf / scf_per_min_i\n",
    "\n",
    "    return(wall_time_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y = df_i.images_per_min.tolist()\n",
    "\n",
    "# X = df_i.num_atoms.to_numpy()\n",
    "# X = X.reshape(-1, 1)\n",
    "\n",
    "# # PolynomialFeatures (prepreprocessing)\n",
    "# poly = PolynomialFeatures(degree=2)\n",
    "# X_ = poly.fit_transform(X)\n",
    "\n",
    "# lg = LinearRegression()\n",
    "# lg.fit(X_, y)\n",
    "\n",
    "\n",
    "x_array = np.linspace(0, 250, num=901)\n",
    "y_array = [scf_per_min_model(num_atoms=i) for i in x_array]\n",
    "\n",
    "\n",
    "#########################################################\n",
    "trace = go.Scatter(\n",
    "    # x=x_array.flatten(),\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    # text=df.index,\n",
    "    name=\"Polynomial\",\n",
    "    mode=\"lines\",\n",
    "    )\n",
    "data.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lg.coef_)\n",
    "# print(lg.intercept_)\n",
    "\n",
    "num_atoms = 100\n",
    "(+6.47968662) * (num_atoms ** 0) + (-0.12968329) * (num_atoms ** 1) + (+0.00068543) * (num_atoms ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtain coefficients\n",
    "# lg.coef_\n",
    "# y_array = lg.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter(\n",
    "    x=df.num_atoms,\n",
    "\n",
    "#     y=df.time_min,\n",
    "    y=df.images_per_min,\n",
    "    # y=df_i.images_per_min_log,\n",
    "\n",
    "    text=df.index,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        opacity=0.8,\n",
    "        size=14,\n",
    "        ),\n",
    "    )\n",
    "data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(title=dict(text=\"Num Atoms\")),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"SCF Cycles/min\"),\n",
    "        # type=\"log\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200\n",
    "\n",
    "1/200 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting.my_plotly import my_plotly_plot\n",
    "\n",
    "my_plotly_plot(\n",
    "    figure=fig,\n",
    "    plot_name=\"scf_per_min_vs_atoms\",\n",
    "    write_html=True,\n",
    "    write_png=False,\n",
    "    png_scale=6.0,\n",
    "    write_pdf=False,\n",
    "    write_svg=False,\n",
    "    try_orca_write=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "desired_scf_cycles = 100\n",
    "\n",
    "y_array = []\n",
    "x_array = np.linspace(0, 200, num=401)\n",
    "for num_atoms_i in x_array:\n",
    "    # scf_per_min_i = scf_per_min_model(num_atoms=num_atoms_i)\n",
    "    # wall_time_i = desired_scf_cycles / scf_per_min_i\n",
    "    wall_time_i = calc_wall_time(num_atoms=num_atoms_i, num_scf=100)\n",
    "\n",
    "    y_array.append(wall_time_i / 60.)\n",
    "\n",
    "# #########################################################\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "\n",
    "    # text=df.index,\n",
    "    # mode=\"markers\",\n",
    "    # marker=dict(\n",
    "    #     opacity=0.8,\n",
    "    #     size=14,\n",
    "    #     ),\n",
    "    )\n",
    "data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(title=dict(text=\"Num Atoms\")),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Run time (hr)\"),\n",
    "        # type=\"log\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping by XX_attempt and _X revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i\n",
    "\n",
    "grouped = df_i.groupby([\"pre_path\"])\n",
    "for name, group in grouped:\n",
    "    tmp = 42\n",
    "\n",
    "    # print(group.shape[0])\n",
    "\n",
    "# group.iloc[0].pre_path\n",
    "group.iloc[0].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_i[df_i.path == \"/mnt/f/GDrive/norskov_research_storage/nersc/IrOx_Project_temp_190510/07_diff_coverages_term/IrO3_rutile-like/110/bare_covered/_3\"]\n",
    "\n",
    "df[df.path == \"/mnt/f/GDrive/norskov_research_storage/nersc/IrOx_Project_temp_190510/07_diff_coverages_term/IrO3_rutile-like/110/bare_covered/_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrase_i = \"muteg\"\n",
    "phrase_i = \"sihe\"\n",
    "\n",
    "matching_ids = [i for i in df.index if phrase_i in i]\n",
    "\n",
    "matching_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_i = df.loc[matching_ids[0]]\n",
    "\n",
    "print(row_i.path, \"\\n\")\n",
    "\n",
    "row_i"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for file_i in listdir(path=dir_i):\n",
    "#     if \"init\" in file_i:\n",
    "#         print(file_i)\n",
    "#         atoms_i = io.read(\n",
    "#             os.path.join(\n",
    "#                 dir_i,\n",
    "#                 file_i)\n",
    "#             )\n",
    "#         num_atoms = atoms_i.get_number_of_atoms()\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # path_i = \"/mnt/f/GDrive/norskov_research_storage/nersc/IrOx_Project_temp_190510/01_surface_calcs/IrO3/100/41_layers/_1\"\n",
    "# path_i = \"/mnt/f/GDrive/norskov_research_storage/nersc/IrOx_Project_temp_190510/03_OER_Calc/IrO3_battery/010/01_surface_type_a/01_O_covered/01_bare/01_attempt/_1\"\n",
    "\n",
    "# # #########################################################\n",
    "# data_dict_i = dict()\n",
    "\n",
    "# # #########################################################\n",
    "# pre_path = \"/\".join(path_i.split(\"/\")[0:-1])\n",
    "# data_dict_i[\"rev\"] = rev_i\n",
    "\n",
    "# # #########################################################\n",
    "# last_dir = path_i.split(\"/\")[-1]\n",
    "# rev_i = int(last_dir[1:])\n",
    "\n",
    "# # #########################################################\n",
    "# dir_i = path_i.split(\"/\")[-2]\n",
    "# if \"_attempt\" in dir_i:\n",
    "#     att_i = int(dir_i.split(\"_\")[0])\n",
    "# else:\n",
    "#     att_i = None\n",
    "# data_dict_i[\"attempt\"] = att_i\n",
    "\n",
    "# # #########################################################\n",
    "# data_dict_list.append(data_dict_i)\n",
    "\n",
    "# # pd.DataFrame(data_dict_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data_dict_list = []\n",
    "# # for path_i in df_i.path.tolist():\n",
    "# for path_i in outcar_locations:\n",
    "\n",
    "#     # #########################################################\n",
    "#     data_dict_i = dict()\n",
    "\n",
    "#     # #########################################################\n",
    "#     pre_path = \"/\".join(path_i.split(\"/\")[0:-1])\n",
    "#     data_dict_i[\"pre_path\"] = pre_path\n",
    "\n",
    "#     # #########################################################\n",
    "#     last_dir = path_i.split(\"/\")[-1]\n",
    "#     rev_i = int(last_dir[1:])\n",
    "#     data_dict_i[\"rev\"] = rev_i\n",
    "\n",
    "#     # #########################################################\n",
    "#     dir_i = path_i.split(\"/\")[-2]\n",
    "#     if \"_attempt\" in dir_i:\n",
    "#         att_i = int(dir_i.split(\"_\")[0])\n",
    "#     else:\n",
    "#         att_i = None\n",
    "#     data_dict_i[\"attempt\"] = att_i\n",
    "\n",
    "#     # #########################################################\n",
    "#     data_dict_list.append(data_dict_i)\n",
    "\n",
    "\n",
    "# df_paths = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# df_i.reset_index().set_index(\"path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
