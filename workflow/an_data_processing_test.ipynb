{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"Preprocess data from various sources.\n",
    "\n",
    "Author: Raul A. Flores\n",
    "\"\"\"\n",
    "\n",
    "# | - Import Modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        \"data\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ase_modules.ase_methods import max_force\n",
    "from dft_job_automat.job_analysis import DFT_Jobs_Analysis\n",
    "from oxr_reaction.oxr_methods import df_calc_adsorption_e\n",
    "from energetics.dft_energy import Element_Refs\n",
    "\n",
    "from ase_modules.ase_methods import create_species_element_dict\n",
    "from vasp.vasp_methods import parse_incar\n",
    "\n",
    "from proj_data_irox import (\n",
    "    h2_ref,\n",
    "    h2o_ref,\n",
    "    # h2o_corr,\n",
    "    # h2_corr,\n",
    "    )\n",
    "\n",
    "from proj_data_irox import (\n",
    "    corrections_dict,\n",
    "    IrO2_bulk_e_dft,\n",
    "    IrO3_bulk_e_dft,\n",
    "    IrO3_rutile_like_bulk_e_dft,\n",
    "    IrO3_battery_bulk_e_dft,\n",
    "    )\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Elemental References\n",
    "\n",
    "# For now I'm applying the entire free energy correction to the electronic\n",
    "# adsorption energies, so keep the energies of gas references as only\n",
    "# electronic for now\n",
    "h2o_ref = h2o_ref\n",
    "h2_ref = h2_ref\n",
    "\n",
    "# h2o_ref = h2o_ref + h2o_corr\n",
    "# h2_ref = h2_ref + h2_corr\n",
    "\n",
    "Elem_Refs = Element_Refs(\n",
    "    H2O_dict={\n",
    "        \"gibbs_e\": h2o_ref,\n",
    "        \"electronic_e\": h2o_ref,\n",
    "        },\n",
    "\n",
    "    H2_dict={\n",
    "        \"gibbs_e\": h2_ref,\n",
    "        \"electronic_e\": h2_ref,\n",
    "        },\n",
    "    )\n",
    "\n",
    "oxy_ref, hyd_ref = Elem_Refs.calc_ref_energies()\n",
    "\n",
    "oxy_ref = oxy_ref.gibbs_e\n",
    "hyd_ref = hyd_ref.gibbs_e\n",
    "\n",
    "# print(20 * \"TEMP TEMP TEMP\")\n",
    "print(\"oxy_ref:\", oxy_ref); print(\"hyd_ref:\", hyd_ref)\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_file = False\n",
    "root_dir = \".\"\n",
    "data_dir = \".\"\n",
    "file_name = \"df_master.pickle\"\n",
    "process_df = True\n",
    "filter_early_revisions = True\n",
    "unique_params = [\"facet\", \"coverage_type\", \"bulk_system\", \"surface_type\"]\n",
    "name_list = [\"facet\", \"coverage_type\", \"bulk_system\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/f/Dropbox/01_norskov/PROJECT_DATA/04_IrOx_surfaces_OER/oer_slabs_results/190321_new_job_df'\n",
    "\n",
    "from_file = False\n",
    "root_dir = data_dir\n",
    "data_dir = data_dir\n",
    "file_name = \"df_master.pickle\"\n",
    "process_df=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_df(\n",
    "#     from_file=False,\n",
    "#     root_dir=\".\",\n",
    "#     data_dir=\".\",\n",
    "#     file_name=\"df_master.pickle\",\n",
    "#     process_df=True,\n",
    "#     filter_early_revisions=True,\n",
    "#     unique_params=[\"facet\", \"coverage_type\", \"bulk_system\", \"surface_type\"],\n",
    "#     name_list=[\"facet\", \"coverage_type\", \"bulk_system\"],\n",
    "#     ):\n",
    "\n",
    "\"\"\"Load dataframe and perform some preprocessing.\n",
    "\n",
    "unique_params=[\"facet\", \"coverage_type\", \"bulk_system\"],\n",
    "\n",
    "Usage:\n",
    "\n",
    "df_pourbaix, df_ads, df_surf = load_df(\n",
    "    from_file=False,\n",
    "    root_dir=data_dir,\n",
    "    data_dir=data_dir + \"/190103_new_job_df\",\n",
    "    file_name=\"df_master.pickle\",\n",
    "    process_df=True,\n",
    "    )\n",
    "\n",
    "Args:\n",
    "    from_file:\n",
    "\"\"\"\n",
    "# | - load_df\n",
    "if from_file:\n",
    "\n",
    "    # | - From Saved Pickle File\n",
    "    print(\"Attempting to load df from pickle\")\n",
    "    with open(data_dir + \"/\" + file_name, \"rb\") as fle:\n",
    "        df_master = pickle.load(fle)\n",
    "    # return(df_master)\n",
    "    #__|\n",
    "\n",
    "else:\n",
    "\n",
    "    # | - Process Data Frame\n",
    "    Jobs = DFT_Jobs_Analysis(\n",
    "        update_job_state=False,\n",
    "        job_type_class=None,\n",
    "        load_dataframe=True,\n",
    "        root_dir=root_dir,\n",
    "        working_dir=root_dir,\n",
    "        dataframe_dir=data_dir,\n",
    "        )\n",
    "\n",
    "    if filter_early_revisions:\n",
    "        df_master = Jobs.filter_early_revisions(Jobs.data_frame)\n",
    "    else:\n",
    "        df_master = Jobs.data_frame\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "    import pickle; import os\n",
    "    path_i = os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        \"parse_dft_data/out_data\",\n",
    "        \"df_data_new.pickle\")\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_m_new = pickle.load(fle)\n",
    "    # #########################################################\n",
    "    df_m_new.index = [\"new\"]\n",
    "\n",
    "    df_master = pd.concat([\n",
    "        df_master,\n",
    "        df_m_new\n",
    "        ], axis=0)\n",
    "\n",
    "#     df_master = df_master[\n",
    "#         (df_master.facet == \"111\") & \\\n",
    "#         (df_master.job_type == \"ORR_adsorption\") & \\\n",
    "#         (df_master.coverage_type == \"o_covered\")\n",
    "#         ]\n",
    "\n",
    "    df_master = df_master[\n",
    "        (df_master.bulk_system == \"IrO3_rutile-like\") & \\\n",
    "        (df_master.job_type == \"ORR_adsorption\") & \\\n",
    "        (df_master.coverage_type == \"o_covered\") & \\\n",
    "        (df_master.facet == \"110\")\n",
    "        ]\n",
    "\n",
    "    df_master.index = [str(i) for i in df_master.index.tolist()]\n",
    "\n",
    "    if process_df:\n",
    "\n",
    "        # | - Short Path\n",
    "        # Shorter path\n",
    "        root_dir = \"/global/cscratch1/sd/flores12/IrOx_Project\"\n",
    "\n",
    "        def calc_short_path(row, root_dir):\n",
    "            \"\"\"Remove root path from string and return short path.\"\"\"\n",
    "            short_path = row[\"path\"].replace(root_dir, \"\")[1:]\n",
    "            return(short_path)\n",
    "\n",
    "        df_master[\"path_short\"] = df_master.apply(\n",
    "            calc_short_path,\n",
    "            args=(root_dir,),\n",
    "            axis=1,\n",
    "            )\n",
    "        #__|\n",
    "\n",
    "        # | - Entry Name Column\n",
    "        # System Specific Name (for legends)\n",
    "        df_master[\"name_i\"] = df_master[\"facet\"] + \\\n",
    "            \" | \" + df_master[\"coverage_type\"] + \" | \" + \\\n",
    "            df_master[\"bulk_system\"]\n",
    "\n",
    "        df_master[\"name_i_2\"] = df_master[\"facet\"] + \\\n",
    "            \"_\" + df_master[\"coverage_type\"] + \"_\" + \\\n",
    "            df_master[\"bulk_system\"]\n",
    "\n",
    "\n",
    "        # name_list = [\"coverage_type\", \"bulk_system\"]\n",
    "        df_master[\"name_i_3\"] = \"\"\n",
    "        for i in name_list:\n",
    "            df_master[\"name_i_3\"] += df_master[i]\n",
    "            df_master[\"name_i_3\"] += \", \"\n",
    "        #__|\n",
    "\n",
    "        # | - NEW | 181226 | Updating \"surface_type\" column\n",
    "        # np.nan -> 'NaN'\n",
    "        if \"surface_type\" in list(df_master):\n",
    "            df_master[\"surface_type\"] = df_master[\"surface_type\"].replace(\n",
    "                np.nan,\n",
    "                \"NaN\",\n",
    "                regex=True,\n",
    "                )\n",
    "        #__|\n",
    "\n",
    "        # | - Extract Chemical Formula\n",
    "        def get_chemical_formula(row, index=-1):\n",
    "            \"\"\"Extract chemical formula from atoms object.\n",
    "\n",
    "            Args:\n",
    "                row:\n",
    "                index:\n",
    "            \"\"\"\n",
    "            chem_form = row[\"atoms_object\"][index].get_chemical_formula()\n",
    "\n",
    "            return(chem_form)\n",
    "\n",
    "        # df_master[\"chem_formula\"] = df_master.apply(\n",
    "        #     get_chemical_formula,\n",
    "        #     index=-1,\n",
    "        #     axis=1,\n",
    "        #     )\n",
    "        #__|\n",
    "\n",
    "        # | - Max Force\n",
    "        def get_max_force(row):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - get_max_force\n",
    "            if row[\"atoms_object\"] is not None:\n",
    "                try:\n",
    "                    max_force_tmp = max_force(row[\"atoms_object\"][-1])\n",
    "                    return(max_force_tmp[0])\n",
    "                except:\n",
    "                    return(None)\n",
    "\n",
    "            else:\n",
    "                return(None)\n",
    "            #__|\n",
    "\n",
    "        def get_sum_force(row):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - get_sum_force\n",
    "            if row[\"atoms_object\"] is not None:\n",
    "                try:\n",
    "                    max_force_tmp = max_force(row[\"atoms_object\"][-1])\n",
    "                    return(max_force_tmp[1])\n",
    "\n",
    "                except:\n",
    "                    return(None)\n",
    "\n",
    "            else:\n",
    "                return(None)\n",
    "            #__|\n",
    "\n",
    "        df_master[\"max_force\"] = df_master.apply(\n",
    "            get_max_force,\n",
    "            axis=1,\n",
    "            )\n",
    "\n",
    "        df_master[\"sum_force\"] = df_master.apply(\n",
    "            get_sum_force,\n",
    "            axis=1,\n",
    "            )\n",
    "        #__|\n",
    "\n",
    "        # | - Number of Atoms\n",
    "        def N_atoms(row):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - N_atoms\n",
    "            if row[\"atoms_object\"] is not None:\n",
    "\n",
    "                try:\n",
    "                    atoms_i = row.atoms_object[-1]\n",
    "                    elem_dict = create_species_element_dict(atoms_i)\n",
    "                    N_atoms = int(sum(list(elem_dict.values())))\n",
    "\n",
    "                    return(N_atoms)\n",
    "\n",
    "                except:\n",
    "\n",
    "                    try:\n",
    "                        atoms_i = row.init_atoms\n",
    "                        elem_dict = create_species_element_dict(atoms_i)\n",
    "                        N_atoms = int(sum(list(elem_dict.values())))\n",
    "\n",
    "                        return(N_atoms)\n",
    "\n",
    "                    except:\n",
    "                        return(None)\n",
    "\n",
    "            else:\n",
    "                return(None)\n",
    "            #__|\n",
    "\n",
    "        df_master[\"N_atoms\"] = df_master.apply(\n",
    "            N_atoms,\n",
    "            axis=1,\n",
    "            )\n",
    "        #__|\n",
    "\n",
    "        # | - Element Number Dict\n",
    "        def get_elem_num_dict(row):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - get_elem_num_dict\n",
    "            if row[\"atoms_object\"] is not None:\n",
    "\n",
    "                try:\n",
    "                    atoms_i = row.atoms_object[-1]\n",
    "                    elem_dict = create_species_element_dict(atoms_i)\n",
    "                    # N_atoms = int(sum(list(elem_dict.values())))\n",
    "\n",
    "                    return(elem_dict)\n",
    "\n",
    "                except:\n",
    "\n",
    "                    try:\n",
    "                        atoms_i = row.init_atoms\n",
    "                        elem_dict = create_species_element_dict(atoms_i)\n",
    "                        # N_atoms = int(sum(list(elem_dict.values())))\n",
    "\n",
    "                        return(elem_dict)\n",
    "\n",
    "                    except:\n",
    "                        return(None)\n",
    "\n",
    "            else:\n",
    "                return(None)\n",
    "            #__|\n",
    "\n",
    "        df_master[\"elem_num_dict\"] = df_master.apply(\n",
    "            get_elem_num_dict,\n",
    "            axis=1,\n",
    "            )\n",
    "        #__|\n",
    "\n",
    "        # | - NEW | INCAR Processing\n",
    "        def parse_incar_tmp(row_i):\n",
    "            # | - parse_incar_tmp\n",
    "\n",
    "            # print(row_i.incar)\n",
    "            # print(row_i.path)\n",
    "            # print(\"__(*&__----)\")\n",
    "\n",
    "            if type(row_i.incar) is not list:\n",
    "                if pd.isna(row_i.incar):\n",
    "                    return({})\n",
    "\n",
    "            incar_dict = parse_incar(row_i.incar)\n",
    "\n",
    "            return(incar_dict)\n",
    "            #__|\n",
    "\n",
    "        df_master[\"incar_parsed\"] = df_master.apply(\n",
    "            parse_incar_tmp,\n",
    "            axis=1,\n",
    "            )\n",
    "\n",
    "        def ldipol(row_i):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - ldipol\n",
    "            return(row_i.incar_parsed.get(\"LDIPOL\", np.nan))\n",
    "            #__|\n",
    "\n",
    "        df_master[\"dipole_correction\"] = df_master.apply(\n",
    "            ldipol,\n",
    "            axis=1,\n",
    "            )\n",
    "\n",
    "        def ldau(row_i):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - ldau\n",
    "            return(row_i.incar_parsed.get(\"LDAU\", np.nan))\n",
    "            #__|\n",
    "\n",
    "        df_master[\"u_correction\"] = df_master.apply(\n",
    "            ldau,\n",
    "            axis=1,\n",
    "            )\n",
    "\n",
    "        #__|\n",
    "\n",
    "        # | - NEW | 181107 | Getting magmoms From Atoms Calc Object\n",
    "\n",
    "        def get_final_magmoms(row):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - get_magmoms\n",
    "            atoms_i = row[\"atoms_object\"]\n",
    "            if atoms_i is None:\n",
    "                return(None)\n",
    "\n",
    "\n",
    "            if len(atoms_i) == 0:\n",
    "                return(None)\n",
    "            elif len(atoms_i) > 0:\n",
    "                final_image = atoms_i[-1]\n",
    "                magmoms_i = final_image.get_magnetic_moments()\n",
    "\n",
    "                return(magmoms_i)\n",
    "            #__|\n",
    "\n",
    "        df_master[\"magmoms\"] = df_master.apply(\n",
    "            get_final_magmoms,\n",
    "            axis=1,\n",
    "            )\n",
    "\n",
    "\n",
    "        def total_magmom(row):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - total_magmom\n",
    "\n",
    "            magmoms_i = row[\"magmoms\"]\n",
    "            if magmoms_i is not None:\n",
    "                total_magmom_out = np.sum(magmoms_i)\n",
    "            else:\n",
    "                total_magmom_out = None\n",
    "\n",
    "            return(total_magmom_out)\n",
    "            #__|\n",
    "\n",
    "        df_master[\"total_magmom\"] = df_master.apply(\n",
    "            total_magmom,\n",
    "            axis=1,\n",
    "            )\n",
    "\n",
    "        def abs_magmom(row):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # | - abs_magmom\n",
    "            magmoms_i = row[\"magmoms\"]\n",
    "            if magmoms_i is not None:\n",
    "                abs_magmom_out = np.sum(np.abs(magmoms_i))\n",
    "            else:\n",
    "                abs_magmom_out = None\n",
    "\n",
    "            return(abs_magmom_out)\n",
    "            #__|\n",
    "\n",
    "        df_master[\"abs_magmom\"] = df_master.apply(\n",
    "            abs_magmom,\n",
    "            axis=1,\n",
    "            )\n",
    "\n",
    "        #__|\n",
    "\n",
    "        df_m = df_master\n",
    "\n",
    "        # Drop jobs which have manually been marked as \"not successful\"\n",
    "        if \"success\" in df_m.columns:\n",
    "            df_m = df_m.drop(df_m[df_m[\"success\"] == False].index)\n",
    "\n",
    "            # This doesn't work for some reason\n",
    "            # df_m = df_m.drop(df_m[df_m[\"success\"] is False].index)\n",
    "\n",
    "\n",
    "        df_surf = df_m[df_m[\"job_type\"] == \"surface_energy\"]\n",
    "        df_surf_cov = df_m[df_m[\"job_type\"] == \"surface_coverage_energy\"]\n",
    "\n",
    "        frames = [df_surf, df_surf_cov]\n",
    "        df_surf = pd.concat(frames, sort=False)\n",
    "\n",
    "        # TODO\n",
    "        # Combine df_surf and df_surf_cov into single DF\n",
    "\n",
    "        df_pourbaix = df_m[df_m[\"job_type\"] == \"surface_coverage\"]\n",
    "        df_ads = df_m[df_m[\"job_type\"] == \"ORR_adsorption\"]\n",
    "\n",
    "\n",
    "\n",
    "        # #################################################################\n",
    "        # | - DF Adsorption ************************************************\n",
    "\n",
    "        if not df_ads.empty:\n",
    "\n",
    "            # | - TEMP TEMP TEMP\n",
    "            # print(5 * \"Fixing Elec E Values | \")\n",
    "            # print(5 * \"Fixing Elec E Values | \")\n",
    "            # print(5 * \"Fixing Elec E Values | \")\n",
    "            # print(5 * \"Fixing Elec E Values | \")\n",
    "            #\n",
    "            # df_tmp = df_ads[\n",
    "            #     (df_ads[\"bulk_system\"] == \"IrO2\") & \\\n",
    "            #     (df_ads[\"dopant\"] == \"Cr\") & \\\n",
    "            #     (df_ads[\"facet\"] == \"100\") & \\\n",
    "            #     (df_ads[\"site\"] == \"ir_site\")\n",
    "            #     ]\n",
    "            #\n",
    "            #\n",
    "            # # bare\n",
    "            # df_tmp_bare = df_tmp[(df_tmp[\"adsorbate\"] == \"bare\")]\n",
    "            # ind_bare = df_tmp_bare.index[0]\n",
    "            #\n",
    "            # # -425.344083 is the original number\n",
    "            # # -424.69857736 is with low dipole moment\n",
    "            # df_ads.at[ind_bare, \"elec_energy\"] = -424.69857736\n",
    "            # # df_ads.at[ind_bare, \"elec_energy\"] = -425.344083\n",
    "            #\n",
    "            #\n",
    "            # # # ooh\n",
    "            # # df_tmp_ooh = df_tmp[(df_tmp[\"adsorbate\"] == \"ooh\")]\n",
    "            # # ind_ooh = df_tmp_bare.index[0]\n",
    "            # # df_ads.at[ind_ooh, \"elec_energy\"] = -440.314515  # -440.314515\n",
    "            # #\n",
    "            # # # o\n",
    "            # # df_tmp_o = df_tmp[(df_tmp[\"adsorbate\"] == \"o\")]\n",
    "            # # ind_o = df_tmp_bare.index[0]\n",
    "            # # df_ads.at[ind_o, \"elec_energy\"] = -440.314515  # -440.314515\n",
    "            # #\n",
    "            # # # oh\n",
    "            # # df_tmp_oh = df_tmp[(df_tmp[\"adsorbate\"] == \"oh\")]\n",
    "            # # ind_oh = df_tmp_bare.index[0]\n",
    "            # # df_ads.at[ind_oh, \"elec_energy\"] = -435.784688  # -435.784688\n",
    "            #__|\n",
    "\n",
    "            from proj_data_irox import groupby_props\n",
    "            groupby_props = copy.deepcopy(groupby_props)\n",
    "\n",
    "\n",
    "            df_ads.loc[df_ads[\"coverage_type\"] == \"O-4_OH-0\", \"coverage_type\"] = \"o_covered\"\n",
    "            df_ads.loc[df_ads[\"coverage_type\"] == \"O-2_OH-0\", \"coverage_type\"] = \"o_covered_2\"\n",
    "            df_ads.loc[df_ads[\"coverage_type\"] == \"O-2_OH-2\", \"coverage_type\"] = \"h_covered\"\n",
    "\n",
    "#             groupby_props.append(\"adsorbate\")\n",
    "#             grouped = df_ads.groupby(groupby_props)\n",
    "\n",
    "\n",
    "            groupby_props.append(\"adsorbate\")\n",
    "            grouped = df_ads.groupby(groupby_props)\n",
    "\n",
    "            ignore_indices = np.array([])\n",
    "            for i_ind, (name, group) in enumerate(grouped):\n",
    "                props_i = dict(zip(groupby_props, list(name)))\n",
    "                df_i = group\n",
    "\n",
    "                if len(df_i) > 1:\n",
    "                    # print(\"\"); print(\"_____\")\n",
    "                    # print(\"more than 1 structure here\")\n",
    "                    if props_i[\"adsorbate\"] == \"ooh\":\n",
    "\n",
    "                        if \"new\" in df_i.index.tolist():\n",
    "                            print(df_i)\n",
    "                            df_i_tmp = df_i.copy(deep=True)\n",
    "                            ignore_indices_i = df_i_tmp.drop(\"new\").index.values\n",
    "                            ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "                        else:\n",
    "                            if \"up\" in df_i[\"ooh_direction\"].tolist():\n",
    "\n",
    "                                ignore_indices_i = list(df_i[df_i[\"ooh_direction\"] != \"up\"].index.values)\n",
    "                                ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "                            elif \"sideways\" in df_i[\"ooh_direction\"].tolist():\n",
    "                                ignore_indices_i = list(df_i[df_i[\"ooh_direction\"] != \"sideways\"].index.values)\n",
    "                                ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "                            else:\n",
    "                                tmp = 42\n",
    "\n",
    "                    elif props_i[\"adsorbate\"] == \"bare\":\n",
    "                        df_copy_i = df_i.copy(deep=True)\n",
    "                        min_e_ind = df_copy_i[\"elec_energy\"].idxmin()\n",
    "\n",
    "                        ignore_indices_i = df_copy_i.drop(min_e_ind).index.values\n",
    "                        ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "                    elif props_i[\"adsorbate\"] == \"o\":\n",
    "                        df_copy_i = df_i.copy(deep=True)\n",
    "                        min_e_ind = df_copy_i[\"elec_energy\"].idxmin()\n",
    "\n",
    "                        ignore_indices_i = df_copy_i.drop(min_e_ind).index.values\n",
    "                        ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "                    elif props_i[\"adsorbate\"] == \"oh\":\n",
    "                        df_copy_i = df_i.copy(deep=True)\n",
    "                        min_e_ind = df_copy_i[\"elec_energy\"].idxmin()\n",
    "\n",
    "                        ignore_indices_i = df_copy_i.drop(min_e_ind).index.values\n",
    "                        ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "                    else:\n",
    "                        tmp = 42\n",
    "            df_ads_0 = df_ads.copy(deep=True)\n",
    "            df_ads = df_ads.drop(labels=ignore_indices)\n",
    "            df_ads_1 = df_ads.copy(deep=True)\n",
    "\n",
    "            # | - Calculate Adsorption Energy\n",
    "            def calc_ads_e(group):\n",
    "                \"\"\"Calculate species adsorption energy.\n",
    "\n",
    "                Args:\n",
    "                    group\n",
    "                \"\"\"\n",
    "                # | - calc_ads_e\n",
    "                print(group)\n",
    "\n",
    "                from IPython.display import display\n",
    "                display(group)\n",
    "\n",
    "                df_calc_adsorption_e(\n",
    "                    group,\n",
    "                    oxy_ref,\n",
    "                    hyd_ref,\n",
    "                    group[\n",
    "                        group[\"adsorbate\"] == \"bare\"\n",
    "                        ][\"elec_energy\"].iloc[0],\n",
    "                    corrections_mode=\"corr_dict\",\n",
    "                    #     corrections_column=\"gibbs_correction\",\n",
    "                    corrections_dict=corrections_dict,\n",
    "                    )\n",
    "\n",
    "                return(group)\n",
    "                #__|\n",
    "\n",
    "            def calc_ads_e_2(group):\n",
    "                \"\"\"Calculate species adsorption energy.\n",
    "\n",
    "                Args:\n",
    "                    group\n",
    "                \"\"\"\n",
    "                # | - calc_ads_e\n",
    "                row_i = group[group[\"coverage_type\"] == \"bare\"]\n",
    "                bare_e = row_i[\"elec_energy\"].iloc[0]\n",
    "\n",
    "                df_calc_adsorption_e(\n",
    "                    group,\n",
    "                    oxy_ref,\n",
    "                    hyd_ref,\n",
    "                    bare_e,\n",
    "                    corrections_mode=\"corr_dict\",\n",
    "                    #     corrections_column=\"gibbs_correction\",\n",
    "                    # corrections_dict=corrections_dict,\n",
    "                    )\n",
    "\n",
    "                return(group)\n",
    "                #__|\n",
    "\n",
    "\n",
    "            for param_i in unique_params:\n",
    "                if param_i not in list(df_ads):\n",
    "                    unique_params.remove(param_i)\n",
    "\n",
    "            grouped = df_ads.groupby(unique_params)\n",
    "            df_ads = grouped.apply(calc_ads_e)\n",
    "\n",
    "\n",
    "            # NOTE This will not work with my 'df_calc_adsorption_e' method\n",
    "            # because it relies on there being an 'adsorbate' attribute to\n",
    "            # count the number of O and H atoms necessary\n",
    "\n",
    "            # grouped = df_pourbaix.groupby([\"facet\", \"bulk_system\"])\n",
    "            # df_pourbaix = grouped.apply(calc_ads_e_2)\n",
    "            #__|\n",
    "\n",
    "            # | - Ordering Columns\n",
    "\n",
    "            col_order_list = [\n",
    "                # Main system variables\n",
    "                \"bulk_system\",\n",
    "                \"facet\",\n",
    "                \"adsorbate\",\n",
    "                \"coverage_type\",\n",
    "                \"ooh_direction\",\n",
    "\n",
    "                # Energetics\n",
    "                \"ads_e\",\n",
    "                \"elec_energy\",\n",
    "\n",
    "                # Magnetic Moments\n",
    "                \"magmoms\",\n",
    "                \"total_magmom\",\n",
    "                \"abs_magmom\",\n",
    "\n",
    "                \"path_short\",\n",
    "\n",
    "                \"name_i\",\n",
    "\n",
    "                \"max_force\",\n",
    "                \"sum_force\",\n",
    "                \"elem_num_dict\",\n",
    "\n",
    "                \"incar\",\n",
    "                \"incar_parsed\",\n",
    "\n",
    "                # Atom properties\n",
    "                \"init_atoms\",\n",
    "                \"atoms_object\",\n",
    "                \"N_atoms\",\n",
    "\n",
    "                \"dipole_correction\",\n",
    "                \"u_correction\",\n",
    "\n",
    "                # Low priority\n",
    "                \"job_type\",\n",
    "                \"max_revision\",\n",
    "                \"revision_number\",\n",
    "                \"success\",\n",
    "                \"coverage\",\n",
    "\n",
    "\n",
    "                \"path\",\n",
    "                \"name_i_2\",\n",
    "                \"name_i_3\",\n",
    "\n",
    "\n",
    "                # Not needed columns\n",
    "                \"Job\",\n",
    "                \"layers\",\n",
    "                ]\n",
    "\n",
    "            # TEMP | Made df_reorder into a method\n",
    "            from misc_modules.pandas_methods import reorder_df_columns\n",
    "            df_ads = reorder_df_columns(col_order_list, df_ads)\n",
    "\n",
    "            df_ads = df_ads.drop(\n",
    "                [\n",
    "                    \"magmoms\",\n",
    "                    \"layers\",\n",
    "                    \"Job\",\n",
    "                    \"coverage\",\n",
    "                    \"success\",\n",
    "                    \"revision_number\",\n",
    "                    \"max_revision\",\n",
    "                    \"job_type\",\n",
    "                    \"u_correction\",\n",
    "                    \"incar\",\n",
    "                    ],\n",
    "                axis=1)\n",
    "\n",
    "            #__|\n",
    "\n",
    "            # | - Filtering Out Extra Calculations\n",
    "            \"\"\"\n",
    "            Each OER set (bare, O, OH, OOH) should only have 1 calculation\n",
    "            corresponding to the 4 intermediate structures\n",
    "\n",
    "            If there are more than 1 calculation available, then the \"best\"\n",
    "            one should be selected.\n",
    "\n",
    "            This is often based on the criteria of energy (most stable)\n",
    "            \"\"\"\n",
    "#             from proj_data_irox import groupby_props\n",
    "#             groupby_props = copy.deepcopy(groupby_props)\n",
    "\n",
    "\n",
    "#             df_ads.loc[df_ads[\"coverage_type\"] == \"O-4_OH-0\", \"coverage_type\"] = \"o_covered\"\n",
    "#             df_ads.loc[df_ads[\"coverage_type\"] == \"O-2_OH-0\", \"coverage_type\"] = \"o_covered_2\"\n",
    "#             df_ads.loc[df_ads[\"coverage_type\"] == \"O-2_OH-2\", \"coverage_type\"] = \"h_covered\"\n",
    "\n",
    "\n",
    "\n",
    "#             groupby_props.append(\"adsorbate\")\n",
    "#             grouped = df_ads.groupby(groupby_props)\n",
    "\n",
    "#             ignore_indices = np.array([])\n",
    "#             for i_ind, (name, group) in enumerate(grouped):\n",
    "#                 props_i = dict(zip(groupby_props, list(name)))\n",
    "#                 df_i = group\n",
    "\n",
    "#                 if len(df_i) > 1:\n",
    "#                     # print(\"\"); print(\"_____\")\n",
    "#                     # print(\"more than 1 structure here\")\n",
    "#                     if props_i[\"adsorbate\"] == \"ooh\":\n",
    "\n",
    "#                         if \"new\" in df_i.index.tolist():\n",
    "#                             print(df_i)\n",
    "#                             df_i_tmp = df_i.copy(deep=True)\n",
    "#                             ignore_indices_i = df_i_tmp.drop(\"new\").index.values\n",
    "#                             ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "#                         else:\n",
    "#                             if \"up\" in df_i[\"ooh_direction\"].tolist():\n",
    "\n",
    "#                                 ignore_indices_i = list(df_i[df_i[\"ooh_direction\"] != \"up\"].index.values)\n",
    "#                                 ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "#                             elif \"sideways\" in df_i[\"ooh_direction\"].tolist():\n",
    "#                                 ignore_indices_i = list(df_i[df_i[\"ooh_direction\"] != \"sideways\"].index.values)\n",
    "#                                 ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "#                             else:\n",
    "#                                 tmp = 42\n",
    "\n",
    "#                     elif props_i[\"adsorbate\"] == \"bare\":\n",
    "#                         df_copy_i = df_i.copy(deep=True)\n",
    "#                         min_e_ind = df_copy_i[\"elec_energy\"].idxmin()\n",
    "\n",
    "#                         ignore_indices_i = df_copy_i.drop(min_e_ind).index.values\n",
    "#                         ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "#                     elif props_i[\"adsorbate\"] == \"o\":\n",
    "#                         df_copy_i = df_i.copy(deep=True)\n",
    "#                         min_e_ind = df_copy_i[\"elec_energy\"].idxmin()\n",
    "\n",
    "#                         ignore_indices_i = df_copy_i.drop(min_e_ind).index.values\n",
    "#                         ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "#                     elif props_i[\"adsorbate\"] == \"oh\":\n",
    "#                         df_copy_i = df_i.copy(deep=True)\n",
    "#                         min_e_ind = df_copy_i[\"elec_energy\"].idxmin()\n",
    "\n",
    "#                         ignore_indices_i = df_copy_i.drop(min_e_ind).index.values\n",
    "#                         ignore_indices = np.append(ignore_indices, ignore_indices_i)\n",
    "\n",
    "#                     else:\n",
    "#                         tmp = 42\n",
    "#             df_ads_0 = df_ads.copy(deep=True)\n",
    "#             df_ads = df_ads.drop(labels=ignore_indices)\n",
    "#             df_ads_1 = df_ads.copy(deep=True)\n",
    "            #__|\n",
    "\n",
    "        #__| **************************************************************\n",
    "\n",
    "\n",
    "\n",
    "        # #################################################################\n",
    "        # | - DF Surface Energies ******************************************\n",
    "\n",
    "        if not df_surf.empty:\n",
    "\n",
    "            # | - Slab Area\n",
    "            def slab_area(row):\n",
    "                \"\"\"\n",
    "                \"\"\"\n",
    "                # | - slab_area\n",
    "                if row[\"atoms_object\"] is not None:\n",
    "                    try:\n",
    "                        atoms_i = row.atoms_object[-1]\n",
    "                        cell_i = atoms_i.cell\n",
    "\n",
    "                        cross_prod_i = np.cross(cell_i[0], cell_i[1])\n",
    "                        area_i = np.linalg.norm(cross_prod_i)\n",
    "                        return(area_i)\n",
    "\n",
    "                    except:\n",
    "\n",
    "                        try:\n",
    "                            atoms_i = row.init_atoms\n",
    "                            cell_i = atoms_i.cell\n",
    "\n",
    "                            cross_prod_i = np.cross(cell_i[0], cell_i[1])\n",
    "                            area_i = np.linalg.norm(cross_prod_i)\n",
    "                            return(area_i)\n",
    "\n",
    "                        except:\n",
    "                            return(None)\n",
    "\n",
    "                else:\n",
    "                    return(None)\n",
    "                #__|\n",
    "\n",
    "            df_surf[\"slab_area\"] = df_surf.apply(\n",
    "                slab_area,\n",
    "                axis=1,\n",
    "                )\n",
    "            #__|\n",
    "\n",
    "            # | - Bulk Energy per Atom (DFT)\n",
    "            def bulk_elec_e(row):\n",
    "                if row[\"bulk_system\"] == \"IrO3\":\n",
    "                    return(IrO3_bulk_e_dft)\n",
    "                elif row[\"bulk_system\"] == \"IrO2\":\n",
    "                    return(IrO2_bulk_e_dft)\n",
    "                elif row[\"bulk_system\"] == \"IrO3_rutile-like\":\n",
    "                    return(IrO3_rutile_like_bulk_e_dft)\n",
    "                elif row[\"bulk_system\"] == \"IrO3_battery\":\n",
    "                    return(IrO3_battery_bulk_e_dft)\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        \"Didn't assign reference bulk energy\",\n",
    "                        )\n",
    "\n",
    "            df_surf[\"bulk_e_per_atom_DFT\"] = df_surf.apply(\n",
    "                bulk_elec_e,\n",
    "                axis=1,\n",
    "                )\n",
    "            #__|\n",
    "\n",
    "            # | - Surface Energy (Averaged Bulk Reference State)\n",
    "            # Calculated surface energy using only the bulk phase as a\n",
    "            # reference frame. This scheme does not treat\n",
    "            # non-stoicheometric oxygens, instead just having a\n",
    "            # (Total Energy) / (Total Atoms) term\n",
    "\n",
    "            def surface_e_ave_bulk_ref(row):\n",
    "                surf_e_i = row.elec_energy \\\n",
    "                    - row.N_atoms * row.bulk_e_per_atom_DFT\n",
    "                surf_e_i = surf_e_i / row.slab_area\n",
    "                return(surf_e_i)\n",
    "\n",
    "            df_surf[\"surface_e_ave_bulk_ref\"] = df_surf.apply(\n",
    "                surface_e_ave_bulk_ref,\n",
    "                axis=1,\n",
    "                )\n",
    "            #__|\n",
    "\n",
    "            # | - Nonstoicheometric Oxygen Count\n",
    "            def nonstoich_Os(row_i):\n",
    "                bulk_i = row_i.bulk_system\n",
    "                atoms_i = row_i.init_atoms\n",
    "\n",
    "                if bulk_i == \"IrO2\":\n",
    "                    O_Ir_ratio = 2\n",
    "                elif bulk_i == \"IrO3\":\n",
    "                    O_Ir_ratio = 3\n",
    "                elif bulk_i == \"IrO3_rutile-like\":\n",
    "                    O_Ir_ratio = 3\n",
    "                elif bulk_i == \"IrO3_battery\":\n",
    "                    O_Ir_ratio = 3\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        \"Not expected bulk encountered!\",\n",
    "                        )\n",
    "\n",
    "                    # print(\"Not expected bulk encountered!\")\n",
    "\n",
    "\n",
    "                elems_dict = create_species_element_dict(\n",
    "                    atoms_i,\n",
    "                    include_all_elems=False,\n",
    "                    elems_to_always_include=None,\n",
    "                    )\n",
    "\n",
    "                N_O_stoich = elems_dict[\"Ir\"] * O_Ir_ratio\n",
    "                N_O_nonstoich = elems_dict[\"O\"] - N_O_stoich\n",
    "\n",
    "                return(N_O_nonstoich)\n",
    "\n",
    "            df_surf[\"nonstoich_Os\"] = df_surf.apply(nonstoich_Os, axis=1)\n",
    "            #__|\n",
    "\n",
    "        #__| **************************************************************\n",
    "\n",
    "\n",
    "\n",
    "        # | - Saving Dataframe to Pickle\n",
    "        with open(data_dir + \"/\" + file_name, \"wb\") as fle:\n",
    "            pickle.dump((df_pourbaix, df_ads, df_surf), fle)\n",
    "        #__|\n",
    "\n",
    "\n",
    "        # | - Constructing Output\n",
    "        out_set = ()\n",
    "\n",
    "        if not df_pourbaix.empty:\n",
    "            out_set = out_set + (df_pourbaix,)\n",
    "        else:\n",
    "            out_set = out_set + (None,)\n",
    "\n",
    "        if not df_ads.empty:\n",
    "            out_set = out_set + (df_ads,)\n",
    "        else:\n",
    "            out_set = out_set + (None,)\n",
    "\n",
    "        if not df_surf.empty:\n",
    "            out_set = out_set + (df_surf,)\n",
    "        else:\n",
    "            out_set = out_set + (None,)\n",
    "        #__|\n",
    "\n",
    "\n",
    "        # return(out_set)\n",
    "\n",
    "    # else:\n",
    "    #     return(df_master)\n",
    "\n",
    "#__|\n",
    "\n",
    "#__|"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = df_master[\n",
    "    (df_master.bulk_system == \"IrO3_rutile-like\") & \\\n",
    "    (df_master.job_type == \"ORR_adsorption\") & \\\n",
    "    (df_master.coverage_type == \"o_covered\") & \\\n",
    "    (df_master.facet == \"110\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.job_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads[\n",
    "    (df_ads.facet == \"111\") & \\\n",
    "    # (df_ads.adsorbate == \"ooh\") & \\\n",
    "    (df_ads.coverage_type == \"o_covered\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# ignore_indices\n",
    "\n",
    "# # df_ads.loc[\"26\"]\n",
    "\n",
    "# # df_ads.loc[\"new\"]\n",
    "\n",
    "# df_ads.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # df_m_new.index = [\"new\"]\n",
    "\n",
    "# df_m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # name_i = \"IrO2_100_o_covered_NaN\"\n",
    "# row_old = df_ads[\n",
    "#     (df_ads.facet == \"100\") & \\\n",
    "#     (df_ads.coverage_type == \"o_covered\") & \\\n",
    "#     (df_ads.adsorbate == \"ooh\") & \\\n",
    "#     (df_ads.bulk_system == \"IrO2\")\n",
    "#     ]\n",
    "# row_old\n",
    "\n",
    "# # row_old = row_old.iloc[0]\n",
    "# # row_old.name\n",
    "# # df_ads = df_ads.drop(index=row_old.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
