{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ase.db import connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"FinalStructures_1.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read df_bulk_dft dataframe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_ml_dataframes\n",
    "\n",
    "DF_dict = get_ml_dataframes(names=[\n",
    "    \"df_dft_final_final_path\",\n",
    "    # \"\",\n",
    "    ])\n",
    "\n",
    "df_bulk_dft = DF_dict[\"df_dft_final_final\"]\n",
    "\n",
    "df_i = df_bulk_dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_i = df_i.loc[[\n",
    "#     'vovgximhm2',\n",
    "#     '8dce6kz2vf',\n",
    "#     'vhv39q6e9j',\n",
    "#     '8ymh8qnl6o',\n",
    "#     '6fcdbh9fz2',\n",
    "#     '7qm56wxj8s',\n",
    "#     'mu6omk6k9l',\n",
    "#     '6dzhcimdxs',\n",
    "#     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING: DON\"T RUN THIS AGAIN BECAUSE IT WILL APPEND TO DATABASE\n",
    "\n",
    "I will comment out this code block to avoid issues, uncomment and run only if you're starting from scratch"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # db = connect('out_data/FinalStructures_1.db')\n",
    "# db = connect(os.path.join(\"out_data\", filename))\n",
    "\n",
    "# for i_cnt, row_i in df_i.iterrows():\n",
    "#     atoms = row_i.atoms\n",
    "#     structure_id = row_i.name\n",
    "\n",
    "#     key_value_pairs = dict(\n",
    "#         stoich=row_i.stoich,\n",
    "#         id_old=row_i.id_old,\n",
    "#         structure_id=row_i.name,\n",
    "#         )\n",
    "\n",
    "#     db.write(\n",
    "#         atoms,\n",
    "#         key_value_pairs=key_value_pairs,\n",
    "#         # data={},\n",
    "#         # id=,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = connect('out_data/FinalStructures_1.db')\n",
    "db = connect(os.path.join(\"out_data\", filename))\n",
    "\n",
    "tmp_list = []\n",
    "for row in db.select():\n",
    "    tmp = 42   \n",
    "    id_i = row.key_value_pairs[\"structure_id\"]\n",
    "    tmp_list.append(id_i)\n",
    "\n",
    "print(\"Unique number of ids in database:\", len(set(tmp_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [\n",
    "    'vovgximhm2',\n",
    "    '8dce6kz2vf',\n",
    "    'vhv39q6e9j',\n",
    "    '8ymh8qnl6o',\n",
    "    '6fcdbh9fz2',\n",
    "    '7qm56wxj8s',\n",
    "    'mu6omk6k9l',\n",
    "    '6dzhcimdxs',\n",
    "    ]\n",
    "\n",
    "for id_i in id_list:\n",
    "    print(id_i in tmp_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# db.write?\n",
    "\n",
    "# for row in db.select():\n",
    "#     tmp = 42\n",
    "\n",
    "\n",
    "# row.key_value_pairs\n",
    "\n",
    "# db.write?\n",
    "\n",
    "# for row in db.select(0):\n",
    "#     tmp = 42\n",
    "    \n",
    "# row\n",
    "\n",
    "# import pickle\n",
    "# from pandas.core.internals import managers\n",
    "# data = pickle.load(open('df_bulk_dft.pickle', 'rb'))\n",
    "\n",
    "# indices = df_i.index.values\n",
    "# for i, atoms in enumerate(df_i.atoms.values):\n",
    "#     db.write(atoms, structure_id=indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_i.shape\n",
    "\n",
    "# df_bulk_dft_ab2.shape\n",
    "\n",
    "# df_bulk_dft_ab2.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # #############################################################################\n",
    "# import pickle; import os\n",
    "# path_i = os.path.join(\n",
    "#      os.environ[\"PROJ_irox\"],\n",
    "#      \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures/out_data\",\n",
    "#      \"ids_to_discard__proto_dupl.pickle\")\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     duplicate_ids = pickle.load(fle)\n",
    "# # #############################################################################\n",
    "\n",
    "# len(duplicate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# sys.path.insert(0, os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],    \n",
    "#     \"workflow/ml_modelling\"))\n",
    "\n",
    "# # #####################################\n",
    "# data_dict = get_data_for_al(\n",
    "#     stoich=\"AB2\",\n",
    "#     verbose=True,\n",
    "#     drop_too_many_atoms=True)\n",
    "# df_bulk_dft = data_dict[\"df_bulk_dft\"]\n",
    "# df_bulk_dft_ab2 = df_bulk_dft\n",
    "# df_bulk_dft_ab2 = df_bulk_dft\n",
    "\n",
    "# # #####################################\n",
    "# data_dict = get_data_for_al(\n",
    "#     stoich=\"AB3\",\n",
    "#     verbose=True,\n",
    "#     drop_too_many_atoms=True)\n",
    "# df_bulk_dft = data_dict[\"df_bulk_dft\"]\n",
    "# df_bulk_dft_ab3 = df_bulk_dft\n",
    "\n",
    "\n",
    "# # #############################################################################\n",
    "# df_bulk_dft = pd.concat(\n",
    "#     [\n",
    "#         df_bulk_dft_ab2,\n",
    "#         df_bulk_dft_ab3])\n",
    "\n",
    "# df_bulk_dft = df_bulk_dft[df_bulk_dft.source == \"raul\"]\n",
    "# df_i = df_bulk_dft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
