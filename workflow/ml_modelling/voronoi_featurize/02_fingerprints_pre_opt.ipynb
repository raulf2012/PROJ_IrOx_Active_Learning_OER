{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following system is failing with voro fingerprinting:\n",
    "z39g648rnl"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from protosearch.ml_modelling.fingerprint import (\n",
    "    FingerPrint,\n",
    "    VoronoiFingerprint\n",
    "    )\n",
    "\n",
    "# #############################################################################\n",
    "pd.set_option('display.max_rows', None)\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (\n",
    "    bulk_dft_data_path,\n",
    "    unique_ids_path,\n",
    "    prototypes_data_path,\n",
    "    static_irox_structures_path,\n",
    "    static_irox_structures_kirsten_path,\n",
    "    df_features_pre_opt_path,\n",
    "    df_features_pre_opt_kirsten_path,\n",
    "    df_features_post_opt_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)\n",
    "\n",
    "with open(static_irox_structures_path, \"rb\") as fle:\n",
    "    df_struct = pickle.load(fle)\n",
    "\n",
    "with open(static_irox_structures_kirsten_path, \"rb\") as fle:\n",
    "    df_struct_kirsten = pickle.load(fle)\n",
    "\n",
    "df_ids = pd.read_csv(unique_ids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Current df_features_pre"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "\n",
    "from ml_methods import get_ml_dataframes\n",
    "\n",
    "ml_data_dict = get_ml_dataframes(names=[\"df_features_pre_opt_path\"])\n",
    "\n",
    "df_features_pre_opt = ml_data_dict[\"df_features_pre_opt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_pre_opt.shape\n",
    "\n",
    "df_features_pre_opt.loc[\"6dzhcimdxs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"6dzhcimdxs\" in df_bulk_dft.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove rows with missing atoms objects"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing missing data\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"atoms\"].notnull()]\n",
    "df_struct = df_struct[df_struct[\"atoms\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figuring out which systems have already been processed"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_struct.index.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing pre-opt Fingerprints"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_struct = FingerPrint(**{\n",
    "#     \"feature_methods\": [\"voronoi\"],\n",
    "#     \"input_data\": df_struct,\n",
    "# #     \"input_data\": df_combined,\n",
    "#     \"input_index\": [\"atoms\"]})\n",
    "\n",
    "# FP_struct.generate_fingerprints()\n",
    "# df_features_pre_opt = FP_struct.fingerprints\n",
    "\n",
    "# # #############################################################################\n",
    "# with open(df_features_pre_opt_path, \"wb\") as fle:\n",
    "#     pickle.dump(df_features_pre_opt, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_struct = FingerPrint(**{\n",
    "#     \"feature_methods\": [\"voronoi\"],\n",
    "#     \"input_data\": df_struct_kirsten,\n",
    "# #     \"input_data\": df_combined,\n",
    "#     \"input_index\": [\"atoms\"]})\n",
    "\n",
    "# FP_struct.generate_fingerprints()\n",
    "# df_features_pre_opt = FP_struct.fingerprints\n",
    "\n",
    "# # #############################################################################\n",
    "# with open(df_features_pre_opt_kirsten_path, \"wb\") as fle:\n",
    "#     pickle.dump(df_features_pre_opt, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_features_pre_opt_path, \"rb\") as fle:\n",
    "    df_features_pre_opt = pickle.load(fle)\n",
    "\n",
    "with open(df_features_pre_opt_kirsten_path, \"rb\") as fle:\n",
    "    df_features_pre_opt_kirsten = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_features_post_opt_path, \"rb\") as fle:\n",
    "    df_features_post_opt = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_post_opt[\"data\", \"INDEX_OLD\"] = df_features_post_opt.index\n",
    "df_features_post_opt[\"data\", \"INDEX_NEW\"] = df_features_post_opt[\"data\", \"INDEX_OLD\"] + \"_\" + df_features_post_opt[\"data\"][\"source\"]\n",
    "\n",
    "df_features_post_opt = df_features_post_opt.set_index(df_features_post_opt[\"data\", \"INDEX_NEW\"])\n",
    "df_features_post_opt = df_features_post_opt.drop(labels=[[\"data\", \"INDEX_NEW\"]], axis=1)\n",
    "\n",
    "print(\"df_features_post_opt.shape:\", df_features_post_opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft[\"INDEX_NEW\"] = df_bulk_dft.index + \"_\" + df_bulk_dft[\"source\"]\n",
    "df_bulk_dft[\"INDEX_OLD\"] = df_bulk_dft.index\n",
    "df_bulk_dft = df_bulk_dft.set_index(\"INDEX_NEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_process = [i for i in df_bulk_dft.index if i not in df_features_post_opt.index]\n",
    "df_bulk_dft_not_processed = df_bulk_dft.loc[ids_to_process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_bulk_dft_not_processed.shape:\", df_bulk_dft_not_processed.shape)\n",
    "# df_bulk_dft_not_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bulk_dft[df_bulk_dft[\"stoich\"] == \"AB2\"].sort_values(\"energy_pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_struct = FingerPrint(**{\n",
    "    \"feature_methods\": [\"voronoi\"],\n",
    "    \"input_data\": df_bulk_dft_not_processed,\n",
    "    \"input_index\": [\"atoms\"]})\n",
    "\n",
    "FP_struct.generate_fingerprints()\n",
    "df_features_post_opt_new = FP_struct.fingerprints\n",
    "\n",
    "# Add the 'source' column to features dataframe since there are duplicate ids\n",
    "# due to the fact that Chris and I ran the same structures\n",
    "df_features_post_opt_new[\"data\", \"source\"] = df_bulk_dft_not_processed[\"source\"]\n",
    "df_features_post_opt_new[\"data\", \"INDEX_OLD\"] = df_bulk_dft_not_processed[\"INDEX_OLD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_post_opt_comb = pd.concat([\n",
    "    df_features_post_opt,\n",
    "    df_features_post_opt_new])\n",
    "\n",
    "nan_mask = df_features_post_opt_comb[\"voronoi\"].isnull().any(axis=\"columns\")\n",
    "\n",
    "df_features_post_opt_comb_cpy = copy.deepcopy(df_features_post_opt_comb)\n",
    "\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.loc[~nan_mask]\n",
    "df_nan_in_voro = df_features_post_opt_comb_cpy.loc[nan_mask]\n",
    "\n",
    "print(\n",
    "    \"Does `df_features_post_opt` have any NaN values in it: \",\n",
    "    \"\\n -->\",\n",
    "    df_features_post_opt_comb[\"voronoi\"].isnull().any(axis=\"columns\").any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_indices = df_features_post_opt_comb[\"data\", \"INDEX_OLD\"]\n",
    "\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.set_index(old_indices)\n",
    "# df_features_post_opt_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_renamed = df_features_post_opt_comb.index.rename(\"id_unique\")\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.set_index(index_renamed)\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.drop((\"data\", \"INDEX_OLD\"), axis=1)\n",
    "\n",
    "index_renamed = df_bulk_dft.index.rename(\"id_unique\")\n",
    "df_bulk_dft = df_bulk_dft.set_index(index_renamed)\n",
    "df_bulk_dft = df_bulk_dft.drop((\"INDEX_OLD\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# with open(df_features_post_opt_path, \"wb\") as fle:\n",
    "#     pickle.dump(df_features_post_opt_comb, fle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
