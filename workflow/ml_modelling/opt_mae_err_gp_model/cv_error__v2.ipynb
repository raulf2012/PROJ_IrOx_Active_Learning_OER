{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---\n",
    "\n",
    "A model that predicts the mean (~ -6.05 eV/atom) has a MAE of ~0.3 eV/atom)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "# Python Utils\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# #########################################################\n",
    "# Project Imports\n",
    "\n",
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/190611_new_workflow/02_gaus_proc\"))\n",
    "from gp_methods import (\n",
    "    gp_model_catlearn,\n",
    "    gp_workflow,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# stoich_i = \"AB2\"\n",
    "stoich_i = \"AB3\"\n",
    "\n",
    "# gp_model = gp_model_gpflow\n",
    "gp_model = gp_model_catlearn\n",
    "\n",
    "aqs_bin_size = 5\n",
    "\n",
    "# output_key = \"form_e_chris\"\n",
    "output_key = \"energy_pa\"\n",
    "\n",
    "verbosity_level = 6  # 1-10 scale\n",
    "\n",
    "params_dict = {\n",
    "    \"noise\": [0.0001],\n",
    "    \"sigma_l\": [10.],\n",
    "    \"sigma_f\": [5],\n",
    "    \"alpha\": [0.1],\n",
    "    }\n",
    "\n",
    "c = list(itertools.product(*params_dict.values()))\n",
    "df_gp_params = pd.DataFrame(c, columns=params_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\n",
    "    os.path.join(os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_ml_dataframes\n",
    "\n",
    "DF_dict = get_ml_dataframes(\n",
    "    # names=[\"df_dft_final_final_path\"]\n",
    "    )\n",
    "# list(DF_dict.keys())\n",
    "\n",
    "df_dft = DF_dict[\"df_dft_final_final\"]\n",
    "df_feat_pre = DF_dict[\"df_features_pre_opt\"]\n",
    "df_feat_post = DF_dict[\"df_features_post_opt\"]\n",
    "\n",
    "df_ids = DF_dict['unique_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Dataframes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = df_dft[df_dft.stoich == stoich_i]\n",
    "\n",
    "df_feat_post = df_feat_post[df_feat_post.data.source == \"raul\"]\n",
    "df_feat_post = df_feat_post.drop(columns=[\"data\"])\n",
    "\n",
    "# #########################################################\n",
    "df_feat_post = df_feat_post.loc[df_dft.index]\n",
    "df_feat_pre = df_feat_pre.loc[df_dft.index]\n",
    "\n",
    "# #########################################################\n",
    "df_feat_post = df_feat_post[\"voronoi\"]\n",
    "df_feat_pre = df_feat_pre[\"voronoi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparting CV Folds"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold_cv = 15\n",
    "pca_comp = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(\n",
    "    df_dft=None,\n",
    "    n_fold_cv=None,\n",
    "    pca_comp=None,\n",
    "    ):\n",
    "    \"\"\"Run Cross-validation runs.\"\"\"\n",
    "    \n",
    "    out_dict = dict()\n",
    "\n",
    "    # n_fold_cv = df_dft.shape[0]\n",
    "    # n_fold_cv = 5\n",
    "    # n_fold_cv = 3\n",
    "\n",
    "\n",
    "    fold_size = int(df_dft.shape[0] / n_fold_cv)\n",
    "    # print(\"fold_size:\", fold_size)\n",
    "\n",
    "    # Shuffling training data\n",
    "    df_dft = df_dft.sample(\n",
    "        n=None,\n",
    "        frac=1.,\n",
    "        replace=False,\n",
    "        axis=None)\n",
    "\n",
    "    # print(\"n_fold_cv * fold_size:\", n_fold_cv * fold_size)\n",
    "\n",
    "    ids_0 = df_dft.index[:n_fold_cv * fold_size]\n",
    "    folds = np.split(ids_0, n_fold_cv)\n",
    "\n",
    "    ids_leftover = df_dft.index[n_fold_cv * fold_size:]\n",
    "\n",
    "    if ids_leftover.shape[0] > 0:\n",
    "        folds.append(ids_leftover)\n",
    "    folds = np.array(folds)\n",
    "\n",
    "\n",
    "\n",
    "    data_dict_list = []\n",
    "    for i_cnt, fold_i in enumerate(folds):\n",
    "        data_dict_i = dict()\n",
    "\n",
    "        row_i = df_gp_params.iloc[0]\n",
    "\n",
    "        df_train_dft = df_dft.drop(\n",
    "            labels=fold_i,\n",
    "            axis=0)\n",
    "\n",
    "        df_train_feat = df_feat_post.loc[df_train_dft.index]\n",
    "        df_test_feat = df_feat_post.loc[fold_i]\n",
    "\n",
    "        # #####################################################\n",
    "        # Running GP Model ####################################\n",
    "        gp_params_i = row_i.to_dict()\n",
    "        out = gp_workflow(\n",
    "            df_features_post=df_train_feat, df_test=df_test_feat,\n",
    "            df_bulk_dft=df_train_dft, df_bulk_dft_all=df_dft,\n",
    "\n",
    "            df_ids=df_ids,\n",
    "            gp_model=gp_model_catlearn,\n",
    "            opt_hyperparameters=True,\n",
    "            gp_params=gp_params_i,\n",
    "            y_train_key=\"energy_pa\",\n",
    "\n",
    "\n",
    "            verbose=False,\n",
    "            clean_variance_flag=True, clean_skewness_flag=True,\n",
    "            clean_infinite_flag=True, standardize_data_flag=True,\n",
    "\n",
    "            pca_comp=pca_comp,\n",
    "            # pca_comp=11,\n",
    "            # pca_perc=0.99,\n",
    "            pca_mode=\"num_comp\",\n",
    "            # pca_mode=\"perc\",\n",
    "            )\n",
    "\n",
    "        model_i = out[\"model\"]\n",
    "        model_inst = out[\"model_inst\"]\n",
    "\n",
    "        test_row_i = model_i[model_i[\"prediction\"].notnull()]\n",
    "\n",
    "        mae_i = abs(\n",
    "            test_row_i[\"prediction_unstandardized\"] - test_row_i[\"energy_pa\"]\n",
    "            ).mean()\n",
    "        data_dict_i[\"mae\"] = mae_i\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_list.append(data_dict_i)\n",
    "\n",
    "    # #####################################################\n",
    "    df_cv = pd.DataFrame(data_dict_list)\n",
    "    out_dict[\"df_cv\"] = df_cv\n",
    "\n",
    "    return(out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for pca_comp_i in range(1, 35, 1):\n",
    "    print(\"pca_comp_i:\", pca_comp_i)\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    try:\n",
    "        data_dict_i[\"pca_comp\"] = pca_comp_i\n",
    "\n",
    "        out_dict = run_cv(\n",
    "            df_dft=df_dft,\n",
    "            n_fold_cv=n_fold_cv,\n",
    "            # pca_comp=11,\n",
    "            pca_comp=pca_comp_i,\n",
    "            )\n",
    "        df_cv = out_dict[\"df_cv\"]\n",
    "        mae_cv = df_cv.mae.mean()\n",
    "        data_dict_i[\"mae_cv\"] = mae_cv\n",
    "\n",
    "        data_dict_list.append(data_dict_i)\n",
    "    except:\n",
    "        print(\"Didn't work\")\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "df = pd.DataFrame(data_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"data.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "x_array = df.pca_comp\n",
    "y_array = df.mae_cv\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    )\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# n_fold_cv = df_dft.shape[0]\n",
    "# n_fold_cv = 5\n",
    "n_fold_cv = 3\n",
    "\n",
    "\n",
    "fold_size = int(df_dft.shape[0] / n_fold_cv)\n",
    "print(\"fold_size:\", fold_size)\n",
    "\n",
    "# Shuffling training data\n",
    "df_dft = df_dft.sample(\n",
    "    n=None,\n",
    "    frac=1.,\n",
    "    replace=False,\n",
    "    axis=None)\n",
    "\n",
    "print(\"n_fold_cv * fold_size:\", n_fold_cv * fold_size)\n",
    "\n",
    "ids_0 = df_dft.index[:n_fold_cv * fold_size]\n",
    "folds = np.split(ids_0, n_fold_cv)\n",
    "\n",
    "ids_leftover = df_dft.index[n_fold_cv * fold_size:]\n",
    "\n",
    "if ids_leftover.shape[0] > 0:\n",
    "    folds.append(ids_leftover)\n",
    "\n",
    "folds = np.array(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for i_cnt, fold_i in enumerate(folds):\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    row_i = df_gp_params.iloc[0]\n",
    "\n",
    "    df_train_dft = df_dft.drop(\n",
    "        labels=fold_i,\n",
    "        axis=0)\n",
    "\n",
    "    df_train_feat = df_feat_post.loc[df_train_dft.index]\n",
    "    df_test_feat = df_feat_post.loc[fold_i]\n",
    "\n",
    "    # #####################################################\n",
    "    # Running GP Model ####################################\n",
    "    gp_params_i = row_i.to_dict()\n",
    "    out = gp_workflow(\n",
    "        df_features_post=df_train_feat,\n",
    "        df_test=df_test_feat,\n",
    "        df_bulk_dft=df_train_dft,\n",
    "        df_bulk_dft_all=df_dft,\n",
    "\n",
    "        df_ids=df_ids,\n",
    "        gp_model=gp_model_catlearn,\n",
    "        opt_hyperparameters=True,\n",
    "        gp_params=gp_params_i,\n",
    "        y_train_key=\"energy_pa\",\n",
    "\n",
    "        verbose=False,\n",
    "\n",
    "        clean_variance_flag=True,\n",
    "        clean_skewness_flag=True,\n",
    "        clean_infinite_flag=True,\n",
    "        standardize_data_flag=True,\n",
    "\n",
    "        pca_comp=11,\n",
    "        # pca_comp=11,\n",
    "        pca_perc=0.99,\n",
    "        pca_mode=\"num_comp\",\n",
    "        # pca_mode=\"perc\",\n",
    "        )\n",
    "\n",
    "    model_i = out[\"model\"]\n",
    "    model_inst = out[\"model_inst\"]\n",
    "\n",
    "    test_row_i = model_i[model_i[\"prediction\"].notnull()]\n",
    "\n",
    "    mae_i = abs(\n",
    "        test_row_i[\"prediction_unstandardized\"] - test_row_i[\"energy_pa\"]\n",
    "        ).mean()\n",
    "    data_dict_i[\"mae\"] = mae_i\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
