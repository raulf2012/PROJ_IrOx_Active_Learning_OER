{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---\n",
    "\n",
    "A model that predicts the mean (~ -6.05 eV/atom) has a MAE of ~0.3 eV/atom)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "# Python Utils\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# #########################################################\n",
    "# Project Imports\n",
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/190611_new_workflow/02_gaus_proc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import read_from_PROJ_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"python_classes\"))\n",
    "\n",
    "from active_learning.al_bulkopt import ALBulkOpt\n",
    "from active_learning.active_learning import (\n",
    "    RegressionModel,\n",
    "    FingerPrints,\n",
    "    CandidateSpace,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# stoich_i = \"AB2\"\n",
    "stoich_i = \"AB3\"\n",
    "\n",
    "# gp_model = gp_model_gpflow\n",
    "# gp_model = gp_model_catlearn\n",
    "\n",
    "aqs_bin_size = 5\n",
    "\n",
    "# output_key = \"form_e_chris\"\n",
    "output_key = \"energy_pa\"\n",
    "\n",
    "verbosity_level = 6  # 1-10 scale\n",
    "verbose = True\n",
    "\n",
    "params_dict = {\n",
    "    \"noise\": [0.0001],\n",
    "    \"sigma_l\": [10.],\n",
    "    \"sigma_f\": [5],\n",
    "    \"alpha\": [0.1],\n",
    "    }\n",
    "\n",
    "c = list(itertools.product(*params_dict.values()))\n",
    "df_gp_params = pd.DataFrame(c, columns=params_dict.keys())\n",
    "\n",
    "gp_settings = df_gp_params.iloc[0].to_dict()\n",
    "\n",
    "gp_settings = {\n",
    "    \"noise\": 0.02542,\n",
    "    \"sigma_l\": 1.0049,\n",
    "    \"sigma_f\": 5.19,\n",
    "    \"alpha\": 0.018,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_fold_cv = 15\n",
    "n_fold_cv = 20\n",
    "pca_comp = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\n",
    "    os.path.join(os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_ml_dataframes\n",
    "\n",
    "DF_dict = get_ml_dataframes()\n",
    "\n",
    "df_dft = DF_dict[\"df_dft_final_final\"]\n",
    "df_feat_pre = DF_dict[\"df_features_pre_opt\"]\n",
    "df_feat_post = DF_dict[\"df_features_post_opt\"]\n",
    "\n",
    "df_ids = DF_dict['unique_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Dataframes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = df_dft[df_dft.stoich == stoich_i]\n",
    "\n",
    "df_feat_post = df_feat_post[df_feat_post.data.source == \"raul\"]\n",
    "df_feat_post = df_feat_post.drop(columns=[\"data\"])\n",
    "\n",
    "# #########################################################\n",
    "df_feat_post = df_feat_post.loc[df_dft.index]\n",
    "df_feat_pre = df_feat_pre.loc[df_dft.index]\n",
    "\n",
    "# #########################################################\n",
    "df_feat_post = df_feat_post[\"voronoi\"]\n",
    "df_feat_pre = df_feat_pre[\"voronoi\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_from_PROJ_DATA:\n",
    "    path_i = os.path.join(\n",
    "        os.environ[\"PROJ_DATA\"], \"04_IrOx_surfaces_OER\",\n",
    "        \"PROJECT_COMPUTED_OUT_DATA/PROJ_IrOx_Active_Learning_OER\",\n",
    "        \"workflow/ml_modelling/opt_mae_err_gp_model\",\n",
    "        \"out_data/\" + stoich_i + \"_data.pickle\")\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_m = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not read_from_PROJ_DATA:\n",
    "    data_dict_list = []\n",
    "    for pca_comp_i in range(1, 40, 1):\n",
    "    # for pca_comp_i in range(1, 4, 1):\n",
    "        print(\"pca_comp_i:\", pca_comp_i)\n",
    "        data_dict_j = dict()\n",
    "\n",
    "        data_dict_j[\"pca_comp\"] = pca_comp_i\n",
    "\n",
    "        # #####################################################\n",
    "        fold_size = int(df_dft.shape[0] / n_fold_cv)\n",
    "        # Shuffling training data\n",
    "        df_dft = df_dft.sample(\n",
    "            n=None,\n",
    "            frac=1.,\n",
    "            replace=False,\n",
    "            axis=None)\n",
    "        # print(\"n_fold_cv * fold_size:\", n_fold_cv * fold_size)\n",
    "        ids_0 = df_dft.index[:n_fold_cv * fold_size]\n",
    "        folds = np.split(ids_0, n_fold_cv)\n",
    "        ids_leftover = df_dft.index[n_fold_cv * fold_size:]\n",
    "        if ids_leftover.shape[0] > 0:\n",
    "            folds.append(ids_leftover)\n",
    "        folds = np.array(folds)\n",
    "\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        data_dict_list_j = []\n",
    "        for i_cnt, fold_i in enumerate(folds):\n",
    "            data_dict_i = dict()\n",
    "\n",
    "            row_i = df_gp_params.iloc[0]\n",
    "\n",
    "            df_train_dft = df_dft.drop(\n",
    "                labels=fold_i,\n",
    "                axis=0)\n",
    "\n",
    "            df_train_feat = df_feat_post.loc[df_train_dft.index]\n",
    "            df_test_feat = df_feat_post.loc[fold_i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # #################################################\n",
    "            FP = FingerPrints(\n",
    "                # df_feat_pre,\n",
    "                df_feat_post,\n",
    "                df_features_post=df_feat_post,\n",
    "                pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "                # pca_comp=10,\n",
    "                pca_comp=pca_comp_i,\n",
    "                pca_perc=None,\n",
    "                # verbose=verbose,\n",
    "                verbose=False,\n",
    "                )\n",
    "\n",
    "            CS = CandidateSpace(\n",
    "                Y_data=df_dft,\n",
    "                Y_key=\"dH\",\n",
    "                FingerPrints=FP,\n",
    "                )\n",
    "\n",
    "            # FP.clean_data(df_feat_post, df_feat_post)\n",
    "            FP.clean_data(df_train_feat, df_test_feat)\n",
    "            FP.pca_analysis()\n",
    "\n",
    "            df_train = FP.df_train\n",
    "            df_test = FP.df_test\n",
    "\n",
    "            RM = RegressionModel(\n",
    "                df_train=df_train,\n",
    "                train_targets=df_train_dft.dH,\n",
    "                # train_targets=CS.Y_data_series,\n",
    "                # train_targets=CS.Y_data_series.drop(labels=leave_out_ids),\n",
    "                df_test=df_test,\n",
    "                opt_hyperparameters=True,\n",
    "                gp_settings_dict=gp_settings,\n",
    "                uncertainty_type='regular',\n",
    "                verbose=verbose,\n",
    "                )\n",
    "\n",
    "            RM.run_regression()\n",
    "\n",
    "            model = pd.concat([\n",
    "                CS.Y_data_series,\n",
    "                RM.model,\n",
    "                ], axis=1, sort=False)\n",
    "\n",
    "            model_i = model[~model[\"y\"].isna()]\n",
    "\n",
    "            mae = np.abs(model_i.dH - model_i.y).mean()\n",
    "            print(mae)\n",
    "\n",
    "            data_dict_i[\"mae\"] = mae\n",
    "\n",
    "            data_dict_list_j.append(data_dict_i)\n",
    "\n",
    "        # #####################################################\n",
    "        df_i = pd.DataFrame(data_dict_list_j)\n",
    "        mae_ave = df_i.mae.mean()\n",
    "\n",
    "        data_dict_j[\"mae_ave\"] = mae_ave\n",
    "\n",
    "        data_dict_list.append(data_dict_j)\n",
    "\n",
    "    df_m = pd.DataFrame(data_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, stoich_i + \"_data.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_m, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (Run this cell to plot)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=df_m.pca_comp,\n",
    "    y=df_m.mae_ave,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox]",
   "language": "python",
   "name": "conda-env-PROJ_irox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
