{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---\n",
    "\n",
    "A model that predicts the mean (~ -6.05 eV/atom) has a MAE of ~0.3 eV/atom)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from_PROJ_DATA = False\n",
    "read_from_PROJ_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "# Python Utils\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# #########################################################\n",
    "# Project Imports\n",
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/190611_new_workflow/02_gaus_proc\"))\n",
    "# from gp_methods import (\n",
    "#     gp_model_catlearn,\n",
    "#     gp_workflow,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"python_classes\"))\n",
    "\n",
    "from active_learning.al_bulkopt import ALBulkOpt\n",
    "from active_learning.active_learning import (\n",
    "    RegressionModel,\n",
    "    FingerPrints,\n",
    "    CandidateSpace,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# stoich_i = \"AB2\"\n",
    "stoich_i = \"AB3\"\n",
    "\n",
    "# gp_model = gp_model_gpflow\n",
    "# gp_model = gp_model_catlearn\n",
    "\n",
    "aqs_bin_size = 5\n",
    "\n",
    "# output_key = \"form_e_chris\"\n",
    "output_key = \"energy_pa\"\n",
    "\n",
    "verbosity_level = 6  # 1-10 scale\n",
    "verbose = True\n",
    "\n",
    "params_dict = {\n",
    "    \"noise\": [0.0001],\n",
    "    \"sigma_l\": [10.],\n",
    "    \"sigma_f\": [5],\n",
    "    \"alpha\": [0.1],\n",
    "    }\n",
    "\n",
    "c = list(itertools.product(*params_dict.values()))\n",
    "df_gp_params = pd.DataFrame(c, columns=params_dict.keys())\n",
    "\n",
    "gp_settings = df_gp_params.iloc[0].to_dict()\n",
    "\n",
    "gp_settings = {\n",
    "    \"noise\": 0.02542,\n",
    "    \"sigma_l\": 1.0049,\n",
    "    \"sigma_f\": 5.19,\n",
    "    \"alpha\": 0.018,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_fold_cv = 15\n",
    "n_fold_cv = 20\n",
    "pca_comp = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\n",
    "    os.path.join(os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_ml_dataframes\n",
    "\n",
    "DF_dict = get_ml_dataframes()\n",
    "\n",
    "df_dft = DF_dict[\"df_dft_final_final\"]\n",
    "df_feat_pre = DF_dict[\"df_features_pre_opt\"]\n",
    "df_feat_post = DF_dict[\"df_features_post_opt\"]\n",
    "\n",
    "df_ids = DF_dict['unique_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Dataframes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = df_dft[df_dft.stoich == stoich_i]\n",
    "\n",
    "df_feat_post = df_feat_post[df_feat_post.data.source == \"raul\"]\n",
    "df_feat_post = df_feat_post.drop(columns=[\"data\"])\n",
    "\n",
    "# #########################################################\n",
    "df_feat_post = df_feat_post.loc[df_dft.index]\n",
    "df_feat_pre = df_feat_pre.loc[df_dft.index]\n",
    "\n",
    "# #########################################################\n",
    "df_feat_post = df_feat_post[\"voronoi\"]\n",
    "df_feat_pre = df_feat_pre[\"voronoi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feat_post"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_from_PROJ_DATA:\n",
    "    path_i = os.path.join(\n",
    "        os.environ[\"PROJ_DATA\"], \"04_IrOx_surfaces_OER\",\n",
    "        \"PROJECT_COMPUTED_OUT_DATA/PROJ_IrOx_Active_Learning_OER\",\n",
    "        \"workflow/ml_modelling/opt_mae_err_gp_model\",\n",
    "        \"out_data/\" + stoich_i + \"_data.pickle\")\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_m = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not read_from_PROJ_DATA:\n",
    "    data_dict_list = []\n",
    "    for pca_comp_i in range(1, 40, 1):\n",
    "    # for pca_comp_i in range(1, 4, 1):\n",
    "        print(\"pca_comp_i:\", pca_comp_i)\n",
    "        data_dict_j = dict()\n",
    "\n",
    "        data_dict_j[\"pca_comp\"] = pca_comp_i\n",
    "\n",
    "        # #####################################################\n",
    "        fold_size = int(df_dft.shape[0] / n_fold_cv)\n",
    "        # Shuffling training data\n",
    "        df_dft = df_dft.sample(\n",
    "            n=None,\n",
    "            frac=1.,\n",
    "            replace=False,\n",
    "            axis=None)\n",
    "        # print(\"n_fold_cv * fold_size:\", n_fold_cv * fold_size)\n",
    "        ids_0 = df_dft.index[:n_fold_cv * fold_size]\n",
    "        folds = np.split(ids_0, n_fold_cv)\n",
    "        ids_leftover = df_dft.index[n_fold_cv * fold_size:]\n",
    "        if ids_leftover.shape[0] > 0:\n",
    "            folds.append(ids_leftover)\n",
    "        folds = np.array(folds)\n",
    "\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        data_dict_list_j = []\n",
    "        for i_cnt, fold_i in enumerate(folds):\n",
    "            data_dict_i = dict()\n",
    "\n",
    "            row_i = df_gp_params.iloc[0]\n",
    "\n",
    "            df_train_dft = df_dft.drop(\n",
    "                labels=fold_i,\n",
    "                axis=0)\n",
    "\n",
    "            df_train_feat = df_feat_post.loc[df_train_dft.index]\n",
    "            df_test_feat = df_feat_post.loc[fold_i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # #################################################\n",
    "            FP = FingerPrints(\n",
    "                # df_feat_pre,\n",
    "                df_feat_post,\n",
    "                df_features_post=df_feat_post,\n",
    "                pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "                # pca_comp=10,\n",
    "                pca_comp=pca_comp_i,\n",
    "                pca_perc=None,\n",
    "                # verbose=verbose,\n",
    "                verbose=False,\n",
    "                )\n",
    "\n",
    "            CS = CandidateSpace(\n",
    "                Y_data=df_dft,\n",
    "                Y_key=\"dH\",\n",
    "                FingerPrints=FP,\n",
    "                )\n",
    "\n",
    "            # FP.clean_data(df_feat_post, df_feat_post)\n",
    "            FP.clean_data(df_train_feat, df_test_feat)\n",
    "            FP.pca_analysis()\n",
    "\n",
    "            df_train = FP.df_train\n",
    "            df_test = FP.df_test\n",
    "\n",
    "            RM = RegressionModel(\n",
    "                df_train=df_train,\n",
    "                train_targets=df_train_dft.dH,\n",
    "                # train_targets=CS.Y_data_series,\n",
    "                # train_targets=CS.Y_data_series.drop(labels=leave_out_ids),\n",
    "                df_test=df_test,\n",
    "                opt_hyperparameters=True,\n",
    "                gp_settings_dict=gp_settings,\n",
    "                uncertainty_type='regular',\n",
    "                verbose=verbose,\n",
    "                )\n",
    "\n",
    "            RM.run_regression()\n",
    "\n",
    "            model = pd.concat([\n",
    "                CS.Y_data_series,\n",
    "                RM.model,\n",
    "                ], axis=1, sort=False)\n",
    "\n",
    "            model_i = model[~model[\"y\"].isna()]\n",
    "\n",
    "            mae = np.abs(model_i.dH - model_i.y).mean()\n",
    "            print(mae)\n",
    "\n",
    "            data_dict_i[\"mae\"] = mae\n",
    "\n",
    "            data_dict_list_j.append(data_dict_i)\n",
    "\n",
    "        # #####################################################\n",
    "        df_i = pd.DataFrame(data_dict_list_j)\n",
    "        mae_ave = df_i.mae.mean()\n",
    "\n",
    "        data_dict_j[\"mae_ave\"] = mae_ave\n",
    "\n",
    "        data_dict_list.append(data_dict_j)\n",
    "\n",
    "    df_m = pd.DataFrame(data_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, stoich_i + \"_data.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_m, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (Run this cell to plot)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=df_m.pca_comp,\n",
    "    y=df_m.mae_ave,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# print(\"OIUSDGIOUHSDOIIOHSDGHOIUOSDGOH)*(SD(*(*&SDG(*YSDg80sdy80gh89034t82309h82q49807n8w0h8g809sdgf98sd898809h8923890hasdg98h-897aq23497gvawe987awep9877pwht982qpy9a08sfyus89))))\")\n",
    "# print(\"OIUSDGIOUHSDOIIOHSDGHOIUOSDGOH)*(SD(*(*&SDG(*YSDg80sdy80gh89034t82309h82q49807n8w0h8g809sdgf98sd898809h8923890hasdg98h-897aq23497gvawe987awep9877pwht982qpy9a08sfyus89))))\")\n",
    "# print(\"OIUSDGIOUHSDOIIOHSDGHOIUOSDGOH)*(SD(*(*&SDG(*YSDg80sdy80gh89034t82309h82q49807n8w0h8g809sdgf98sd898809h8923890hasdg98h-897aq23497gvawe987awep9877pwht982qpy9a08sfyus89))))\")\n",
    "# print(\"OIUSDGIOUHSDOIIOHSDGHOIUOSDGOH)*(SD(*(*&SDG(*YSDg80sdy80gh89034t82309h82q49807n8w0h8g809sdgf98sd898809h8923890hasdg98h-897aq23497gvawe987awep9877pwht982qpy9a08sfyus89))))\")\n",
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_train_dft.dH.shape\n",
    "# df_train.shape\n",
    "\n",
    "# df_train\n",
    "\n",
    "# model_i\n",
    "# model\n",
    "# df_test\n",
    "\n",
    "# CS.Y_data_series\n",
    "\n",
    "# RM.model\n",
    "\n",
    "# RM = RegressionModel(\n",
    "#     opt_hyperparameters=True,\n",
    "#     gp_settings_dict=gp_settings,\n",
    "#     verbose=verbose,\n",
    "#     )\n",
    "\n",
    "# FP = FingerPrints(\n",
    "#     df_feat_pre,\n",
    "#     df_features_post=df_feat_post,\n",
    "#     pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "#     pca_comp=10,\n",
    "#     pca_perc=None,\n",
    "#     verbose=verbose,\n",
    "#     )\n",
    "\n",
    "# CS = CandidateSpace(\n",
    "#     Y_data=df_dft,\n",
    "#     Y_key=\"dH\",\n",
    "#     FingerPrints=FP,\n",
    "#     )\n",
    "\n",
    "# # CS = self.CandidateSpace\n",
    "# FP = CS.FingerPrints\n",
    "# completed_ids = self.completed_ids\n",
    "# # #####################################################################\n",
    "\n",
    "# df_mixed = CS.create_mixed_candidate_space(completed_ids)\n",
    "\n",
    "# Y_data_series = CS.Y_data_series\n",
    "# Y_data_series_completed = Y_data_series.loc[completed_ids]\n",
    "\n",
    "# d = {\n",
    "#     \"Y\": pd.DataFrame(Y_data_series_completed),\n",
    "#     \"X\": df_mixed.loc[completed_ids]}\n",
    "# df_train = pd.concat(d.values(), keys=d.keys(), axis=1, sort=False)\n",
    "\n",
    "# df_test = df_mixed\n",
    "# df_test = pd.concat([df_mixed], keys=[\"X\"], axis=1, sort=False)\n",
    "\n",
    "# FP.clean_data(df_train[\"X\"], df_test[\"X\"])\n",
    "# FP.pca_analysis()\n",
    "\n",
    "# df_train = FP.df_train\n",
    "# df_test = FP.df_test\n",
    "\n",
    "\n",
    "# sys.path.insert(0, os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"python_classes\"))\n",
    "# from ccf_similarity.ccf import CCF\n",
    "\n",
    "# d_thresh = 0.02\n",
    "# CCF = CCF(\n",
    "#     df_dij=df_dij,\n",
    "#     d_thresh=d_thresh)\n",
    "\n",
    "# AL = ALBulkOpt(\n",
    "#     CandidateSpace=CS,\n",
    "#     RegressionModel=RM,\n",
    "#     DuplicateFinder=CCF,  # Optional\n",
    "#     duplicate_analysis=duplicate_analysis,\n",
    "#     # num_seed_calcs=11,\n",
    "#     num_seed_calcs=5,\n",
    "#     acquisition_bin=5,\n",
    "#     # stop_mode=\"num_generations\",\n",
    "#     stop_mode=None,\n",
    "#     stop_num_generations=3,\n",
    "#     name=name_i,\n",
    "#     save_dir_extra=save_dir_extra,\n",
    "#     verbose=verbose,\n",
    "#     # acquisition_method=\"gp_ucb\",\n",
    "#     acquisition_method=acquisition_method,\n",
    "#     seed=seed,\n",
    "#     )\n",
    "\n",
    "\n",
    "# RM = RegressionModel(\n",
    "#     df_train=df_feat_post,\n",
    "#     train_targets=df_dft.dH,\n",
    "#     df_test=df_feat_pre,\n",
    "#     opt_hyperparameters=True,\n",
    "#     gp_settings_dict=gp_params,\n",
    "#     uncertainty_type='regular',\n",
    "#     verbose=True,\n",
    "#     )\n",
    "\n",
    "# RM.run_regression()\n",
    "\n",
    "# def run_cv(\n",
    "#     df_dft=None,\n",
    "#     n_fold_cv=None,\n",
    "#     pca_comp=None,\n",
    "#     ):\n",
    "#     \"\"\"Run Cross-validation runs.\"\"\"\n",
    "\n",
    "#     out_dict = dict()\n",
    "\n",
    "#     # n_fold_cv = df_dft.shape[0]\n",
    "#     # n_fold_cv = 5\n",
    "#     # n_fold_cv = 3\n",
    "\n",
    "\n",
    "#     fold_size = int(df_dft.shape[0] / n_fold_cv)\n",
    "#     # print(\"fold_size:\", fold_size)\n",
    "\n",
    "#     # Shuffling training data\n",
    "#     df_dft = df_dft.sample(\n",
    "#         n=None,\n",
    "#         frac=1.,\n",
    "#         replace=False,\n",
    "#         axis=None)\n",
    "\n",
    "#     # print(\"n_fold_cv * fold_size:\", n_fold_cv * fold_size)\n",
    "\n",
    "#     ids_0 = df_dft.index[:n_fold_cv * fold_size]\n",
    "#     folds = np.split(ids_0, n_fold_cv)\n",
    "\n",
    "#     ids_leftover = df_dft.index[n_fold_cv * fold_size:]\n",
    "\n",
    "#     if ids_leftover.shape[0] > 0:\n",
    "#         folds.append(ids_leftover)\n",
    "#     folds = np.array(folds)\n",
    "\n",
    "\n",
    "\n",
    "#     data_dict_list = []\n",
    "#     for i_cnt, fold_i in enumerate(folds):\n",
    "#         data_dict_i = dict()\n",
    "\n",
    "#         row_i = df_gp_params.iloc[0]\n",
    "\n",
    "#         df_train_dft = df_dft.drop(\n",
    "#             labels=fold_i,\n",
    "#             axis=0)\n",
    "\n",
    "#         df_train_feat = df_feat_post.loc[df_train_dft.index]\n",
    "#         df_test_feat = df_feat_post.loc[fold_i]\n",
    "\n",
    "#         # #####################################################\n",
    "#         # Running GP Model ####################################\n",
    "#         gp_params_i = row_i.to_dict()\n",
    "#         out = gp_workflow(\n",
    "#             df_features_post=df_train_feat, df_test=df_test_feat,\n",
    "#             df_bulk_dft=df_train_dft, df_bulk_dft_all=df_dft,\n",
    "\n",
    "#             df_ids=df_ids,\n",
    "#             gp_model=gp_model_catlearn,\n",
    "#             opt_hyperparameters=True,\n",
    "#             gp_params=gp_params_i,\n",
    "#             y_train_key=\"energy_pa\",\n",
    "\n",
    "\n",
    "#             verbose=False,\n",
    "#             clean_variance_flag=True, clean_skewness_flag=True,\n",
    "#             clean_infinite_flag=True, standardize_data_flag=True,\n",
    "\n",
    "#             pca_comp=pca_comp,\n",
    "#             # pca_comp=11,\n",
    "#             # pca_perc=0.99,\n",
    "#             pca_mode=\"num_comp\",\n",
    "#             # pca_mode=\"perc\",\n",
    "#             )\n",
    "\n",
    "#         model_i = out[\"model\"]\n",
    "#         model_inst = out[\"model_inst\"]\n",
    "\n",
    "#         test_row_i = model_i[model_i[\"prediction\"].notnull()]\n",
    "\n",
    "#         mae_i = abs(\n",
    "#             test_row_i[\"prediction_unstandardized\"] - test_row_i[\"energy_pa\"]\n",
    "#             ).mean()\n",
    "#         data_dict_i[\"mae\"] = mae_i\n",
    "\n",
    "#         # #################################################\n",
    "#         data_dict_list.append(data_dict_i)\n",
    "\n",
    "#     # #####################################################\n",
    "#     df_cv = pd.DataFrame(data_dict_list)\n",
    "#     out_dict[\"df_cv\"] = df_cv\n",
    "\n",
    "#     return(out_dict)\n",
    "\n",
    "# data_dict_list = []\n",
    "# for pca_comp_i in range(1, 35, 1):\n",
    "#     print(\"pca_comp_i:\", pca_comp_i)\n",
    "#     data_dict_i = dict()\n",
    "\n",
    "#     try:\n",
    "#         data_dict_i[\"pca_comp\"] = pca_comp_i\n",
    "\n",
    "#         out_dict = run_cv(\n",
    "#             df_dft=df_dft,\n",
    "#             n_fold_cv=n_fold_cv,\n",
    "#             # pca_comp=11,\n",
    "#             pca_comp=pca_comp_i,\n",
    "#             )\n",
    "#         df_cv = out_dict[\"df_cv\"]\n",
    "#         mae_cv = df_cv.mae.mean()\n",
    "#         data_dict_i[\"mae_cv\"] = mae_cv\n",
    "\n",
    "#         data_dict_list.append(data_dict_i)\n",
    "#     except:\n",
    "#         print(\"Didn't work\")\n",
    "\n",
    "#     print(\"\")\n",
    "\n",
    "# df = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# # Pickling data ###########################################\n",
    "# import os; import pickle\n",
    "# directory = \"out_data\"\n",
    "# if not os.path.exists(directory): os.makedirs(directory)\n",
    "# with open(os.path.join(directory, \"data.pickle\"), \"wb\") as fle:\n",
    "#     pickle.dump(df, fle)\n",
    "# # #########################################################\n",
    "\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# x_array = df.pca_comp\n",
    "# y_array = df.mae_cv\n",
    "\n",
    "# trace = go.Scatter(\n",
    "#     x=x_array,\n",
    "#     y=y_array,\n",
    "#     )\n",
    "# data = [trace]\n",
    "\n",
    "# fig = go.Figure(data=data)\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox] *",
   "language": "python",
   "name": "conda-env-PROJ_irox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
