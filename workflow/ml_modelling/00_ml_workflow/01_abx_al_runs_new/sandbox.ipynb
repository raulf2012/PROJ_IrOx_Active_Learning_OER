{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# | - Import Modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gpflow\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# #############################################################################\n",
    "from catlearn.regression.gaussian_process import GaussianProcess\n",
    "from catlearn.preprocess.clean_data import (\n",
    "    clean_infinite,\n",
    "    clean_variance,\n",
    "    clean_skewness)\n",
    "from catlearn.preprocess.scaling import standardize\n",
    "\n",
    "# #############################################################################\n",
    "from active_learning.al_bulkopt import ALBulkOpt\n",
    "from active_learning.active_learning import (\n",
    "    RegressionModel,\n",
    "    FingerPrints,\n",
    "    CandidateSpace,\n",
    "    )\n",
    "from active_learning.al_analysis import ALAnalysis, ALAnimation\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display\n",
    "# -\n",
    "\n",
    "# from inputs import (\n",
    "#     stoich_i,\n",
    "#     verbose,\n",
    "#     gp_settings,\n",
    "#     name_i,\n",
    "#     )\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich_i = \"AB3\"\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_al_i(\n",
    "#     stoich_i=None,\n",
    "#     verbose=None,\n",
    "#     gp_settings=None,\n",
    "#     name_i=None,\n",
    "#     save_dir_extra=None,\n",
    "#     acquisition_method=None,\n",
    "#     duplicate_analysis=None,\n",
    "#     seed=None,\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "\n",
    "# | - run_al_i\n",
    "# # Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "# sys.path.insert(0, os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"workflow/ml_modelling\"))\n",
    "# from ml_methods import get_data_for_al\n",
    "\n",
    "# out_dict = get_data_for_al(\n",
    "#     stoich=stoich_i, verbose=False,\n",
    "#     drop_too_many_atoms=True,\n",
    "# #     drop_too_many_atoms=False,\n",
    "#     )\n",
    "\n",
    "# df_bulk_dft = out_dict[\"df_bulk_dft\"]\n",
    "# df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] == \"raul\"]\n",
    "\n",
    "# # df_bulk_dft = df_bulk_dft[[\"atoms\", \"energy_pa\"]]\n",
    "# df_bulk_dft = df_bulk_dft[[\"atoms\", \"dH\"]]\n",
    "# df_bulk_dft.columns.values[1] = \"y_real\"\n",
    "\n",
    "# df_features_pre = out_dict[\"df_features_pre\"]\n",
    "# df_features_post = out_dict[\"df_features_post\"]\n",
    "\n",
    "# df_ids = out_dict[\"df_ids\"]\n",
    "\n",
    "\n",
    "# df_static_irox = out_dict[\"df_static_irox\"]\n",
    "# df_dij = out_dict[\"df_dij\"]\n",
    "# # -\n",
    "\n",
    "# # # Filter to candidates w/ DFT energy\n",
    "\n",
    "# # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "# ids_w_dft = df_bulk_dft.index\n",
    "\n",
    "# # TEMP | Reduce size of candidate space\n",
    "# # np.random.seed(8)\n",
    "# # ids_w_dft = np.sort(np.random.choice(np.sort(ids_w_dft), size=200))\n",
    "# ids_w_dft = list(set(ids_w_dft))\n",
    "# # print(\"ids_w_dft:\", ids_w_dft)\n",
    "\n",
    "# df_bulk_dft = df_bulk_dft.loc[ids_w_dft]\n",
    "\n",
    "# df_features_pre = df_features_pre.loc[ids_w_dft]\n",
    "# df_features_post = df_features_post.loc[ids_w_dft]\n",
    "\n",
    "# # + {\"active\": \"\"}\n",
    "# #\n",
    "# #\n",
    "# #\n",
    "# #\n",
    "# # -\n",
    "\n",
    "# # # CCF Class\n",
    "\n",
    "# # # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "# # sys.path.insert(0, os.path.join(\n",
    "# #     os.environ[\"PROJ_irox\"],\n",
    "# #     \"python_classes\"))\n",
    "# # from ccf_similarity.ccf import CCF\n",
    "\n",
    "# # d_thresh = 0.02\n",
    "# # CCF = CCF(\n",
    "# #     df_dij=df_dij,\n",
    "# #     d_thresh=d_thresh)\n",
    "\n",
    "# # # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "# # RM = RegressionModel(\n",
    "# #     opt_hyperparameters=True,\n",
    "# #     gp_settings_dict=gp_settings,\n",
    "# #     verbose=verbose,\n",
    "# #     )\n",
    "\n",
    "# # FP = FingerPrints(\n",
    "# #     df_features_pre,\n",
    "# #     df_features_post=df_features_post,\n",
    "# #     pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "# #     pca_comp=10,\n",
    "# #     pca_perc=None,\n",
    "# #     verbose=verbose,\n",
    "# #     )\n",
    "\n",
    "# # CS = CandidateSpace(\n",
    "# #     Y_data=df_bulk_dft,\n",
    "# #     Y_key=\"y_real\",\n",
    "# #     FingerPrints=FP,\n",
    "# #     )\n",
    "\n",
    "# # # +\n",
    "# # AL = ALBulkOpt(\n",
    "# #     CandidateSpace=CS,\n",
    "# #     RegressionModel=RM,\n",
    "# #     DuplicateFinder=CCF,  # Optional\n",
    "# #     duplicate_analysis=duplicate_analysis,\n",
    "# #     # num_seed_calcs=11,\n",
    "# #     num_seed_calcs=5,\n",
    "# #     acquisition_bin=5,\n",
    "# #     # stop_mode=\"num_generations\",\n",
    "# #     stop_mode=None,\n",
    "# #     stop_num_generations=3,\n",
    "# #     name=name_i,\n",
    "# #     save_dir_extra=save_dir_extra,\n",
    "# #     verbose=verbose,\n",
    "# #     # acquisition_method=\"gp_ucb\",\n",
    "# #     acquisition_method=acquisition_method,\n",
    "# #     seed=seed,\n",
    "# #     )\n",
    "\n",
    "# # run_al = True\n",
    "# # if run_al:\n",
    "# #     AL.run_AL()\n",
    "# #     AL.duplicate_system_history_analysis()\n",
    "# #     AL.__save_state__()\n",
    "\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_data_for_al\n",
    "from ml_methods import get_ml_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich = stoich_i\n",
    "verbose = verbose\n",
    "drop_too_many_atoms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data_for_al(\n",
    "# stoich=\"AB2\",\n",
    "# verbose=True,\n",
    "# drop_too_many_atoms=True,\n",
    "# ):\n",
    "# \"\"\"\n",
    "# \"\"\"\n",
    "\n",
    "# | - get_data_for_al\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (ids_to_discard__too_many_atoms_path)\n",
    "\n",
    "# | - Get all necessary dfs\n",
    "df_dict = get_ml_dataframes(\n",
    "    names=[\n",
    "        \"bulk_dft_data_path\",\n",
    "        \"unique_ids_path\",\n",
    "        # \"prototypes_data_path\",\n",
    "        \"static_irox_structures_path\",\n",
    "        # \"static_irox_structures_kirsten_path\",\n",
    "        # \"oqmd_irox_data_path\",\n",
    "        \"df_features_pre_opt_path\",\n",
    "        \"df_features_pre_opt_kirsten_path\",\n",
    "        \"df_features_post_opt_path\",\n",
    "        # \"oer_bulk_structures_path\",\n",
    "        # \"df_ccf_path\",\n",
    "        \"df_dij_path\",\n",
    "        # \"ids_to_discard__too_many_atoms_path\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "df_ids = df_dict.get(\"unique_ids\", None)\n",
    "df_bulk_dft = df_dict.get(\"bulk_dft_data\", None)\n",
    "df_features_pre = df_dict.get(\"df_features_pre_opt\", None)\n",
    "# df_features_pre = df_dict.get(\"df_features_pre_opt_kirsten\", None)\n",
    "df_features_post = df_dict.get(\"df_features_post_opt\", None)\n",
    "\n",
    "df_dij = df_dict.get(\"df_dij\", None)\n",
    "\n",
    "print(\"ISDFIODISFIDS*F*SDF*SDYUGFSODIUFG\")\n",
    "print(\"6fcdbh9fz2 in df_bulk_dft\", \"6fcdbh9fz2\" in df_bulk_dft.index)\n",
    "\n",
    "\n",
    "df_static_irox = df_dict.get(\"static_irox_structures\", None)\n",
    "#__|\n",
    "\n",
    "# | - Filter ids to user specifications\n",
    "df_ids = df_ids[\n",
    "    (df_ids[\"stoich\"] == stoich) & \\\n",
    "    (df_ids[\"source\"] != \"oqmd\") & \\\n",
    "    (df_ids[\"source\"] != \"raul_oer\") & \\\n",
    "    [True for i in range(len(df_ids))]]\n",
    "ids = df_ids[\"unique_ids\"]\n",
    "#__|\n",
    "\n",
    "# #####################################################\n",
    "\n",
    "# | - DFT dataframe\n",
    "df_i = df_bulk_dft\n",
    "\n",
    "# print(\"isidfjisdjifjsidjf8yu2894h90832uy4908tyu98023wht0982quj098gtfujw3e\")\n",
    "# print(df_i.index.shape)\n",
    "# print(df_i.index.unique().shape)\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_i = df_i[df_i.source == \"raul\"]\n",
    "\n",
    "df_bulk_dft = df_i\n",
    "\n",
    "print(\"ISDFIODISFIDS*F*SDF*SDYUGFSODIUFG\")\n",
    "print(\"6fcdbh9fz2 in df_bulk_dft\", \"6fcdbh9fz2\" in df_bulk_dft.index)\n",
    "\n",
    "# print(\"TEMP TEMP TEMP 89ihsjdgf\", \"6dzhcimdxs\" in df_bulk_dft.index)\n",
    "#__|\n",
    "\n",
    "# | - Featurs pre-DFT\n",
    "df_i = df_features_pre\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_features_pre = df_i\n",
    "\n",
    "df_features_pre = df_features_pre[\"voronoi\"]\n",
    "#__|\n",
    "\n",
    "# | - Features post-DFT\n",
    "df_i = df_features_post\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_features_post = df_i\n",
    "\n",
    "# Only use post-DFT features from my data set\n",
    "df_features_post = \\\n",
    "    df_features_post[df_features_post[\"data\"][\"source\"] == \"raul\"]\n",
    "\n",
    "df_features_post = df_features_post[\"voronoi\"]\n",
    "#__|\n",
    "\n",
    "\n",
    "# | - Dropping certain rows\n",
    "all_ids = list(set(\n",
    "    df_bulk_dft.index.tolist() + \\\n",
    "    df_features_pre.index.tolist() + \\\n",
    "    df_features_post.index.tolist() ))\n",
    "\n",
    "\n",
    "ids_to_drop = []\n",
    "\n",
    "# #########################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures/out_data\",\n",
    "    \"ids_to_discard__proto_dupl.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    ids_to_discard__proto_dupl = pickle.load(fle)\n",
    "    # ids_to_drop.extend(ids_to_discard__proto_dupl)\n",
    "# #########################################################################\n",
    "\n",
    "if drop_too_many_atoms:\n",
    "    # #####################################################################\n",
    "    with open(ids_to_discard__too_many_atoms_path, \"rb\") as fle:\n",
    "        ids_to_drop__too_many_atoms = pickle.load(fle)\n",
    "        ids_to_drop.extend(ids_to_drop__too_many_atoms)\n",
    "\n",
    "        # ids_to_drop = ids_to_drop__too_many_atoms\n",
    "        # ids_to_drop = [i for i in ids_to_drop if i in all_ids]\n",
    "    # #####################################################################\n",
    "\n",
    "\n",
    "ids_to_drop = [i for i in ids_to_drop if i in all_ids]\n",
    "\n",
    "# print(\"in ids to drop\", \"6fcdbh9fz2\" in ids_to_drop)\n",
    "\n",
    "df_features_pre = df_features_pre.drop(\n",
    "    labels=ids_to_drop, axis=0)\n",
    "\n",
    "df_i = df_features_post\n",
    "df_features_post = df_i.loc[\n",
    "    df_i.index.intersection(\n",
    "        df_features_pre.index.unique()\n",
    "        ).unique()\n",
    "    ]\n",
    "\n",
    "\n",
    "# print(\"TEMP TEMP TEMP 89ihsjdgf\", \"6dzhcimdxs\" in df_bulk_dft.index)\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.loc[\n",
    "    df_bulk_dft.index.intersection(\n",
    "        df_features_pre.index\n",
    "        ).unique()\n",
    "    ]\n",
    "\n",
    "print(\"ISDFIODISFIDS*F*SDF*SDYUGFSODIUFG\")\n",
    "print(\"6fcdbh9fz2 in df_bulk_dft\", \"6fcdbh9fz2\" in df_bulk_dft.index)\n",
    "\n",
    "# print(\"TEMP TEMP TEMP 89ihsjdgf\", \"6dzhcimdxs\" in df_bulk_dft.index)\n",
    "\n",
    "df_static_irox = df_static_irox.loc[\n",
    "    df_static_irox.index.intersection(\n",
    "        df_features_pre.index\n",
    "        ).unique()\n",
    "    ]\n",
    "\n",
    "ids_static = df_dij.index.intersection(df_static_irox[\"static_id\"])\n",
    "ids_completed_post_dft = \\\n",
    "    df_dij.index.intersection(df_features_pre.index)\n",
    "\n",
    "\n",
    "# print(\"TEMP TEMP TEMP\", \"6fcdbh9fz2\" in df_dij.index)\n",
    "\n",
    "ids_dij = ids_static.tolist() + ids_completed_post_dft.tolist()\n",
    "df_dij = df_dij.loc[ids_dij, ids_dij]\n",
    "\n",
    "# print(\"TEMP TEMP TEMP\", \"6fcdbh9fz2\" in df_dij.index)\n",
    "\n",
    "#__|\n",
    "\n",
    "out_dict = dict()\n",
    "\n",
    "out_dict[\"df_features_post\"] = df_features_post\n",
    "out_dict[\"df_features_pre\"] = df_features_pre\n",
    "out_dict[\"df_bulk_dft\"] = df_bulk_dft\n",
    "\n",
    "# TEMP\n",
    "out_dict[\"df_ids\"] = df_ids\n",
    "out_dict[\"df_dij\"] = df_dij\n",
    "out_dict[\"df_static_irox\"] = df_static_irox\n",
    "\n",
    "\n",
    "# return(out_dict)\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ISDFIODISFIDS*F*SDF*SDYUGFSODIUFG\")\n",
    "# print(\"6fcdbh9fz2 in df_bulk_dft\", \"6fcdbh9fz2\" in df_bulk_dft.index)\n",
    "\n",
    "df_bulk_dft.loc[\"6fcdbh9fz2\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich = \"AB3\"\n",
    "verbose = True\n",
    "drop_too_many_atoms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + {\"jupyter\": {\"source_hidden\": true}}\n",
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_data_for_al\n",
    "\n",
    "out_dict = get_data_for_al(\n",
    "    stoich=stoich_i, verbose=False,\n",
    "    drop_too_many_atoms=True,\n",
    "#     drop_too_many_atoms=False,\n",
    "    )\n",
    "\n",
    "df_bulk_dft = out_dict[\"df_bulk_dft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"6fcdbh9fz2\" in df_bulk_dft.index\n",
    "\n",
    "# df_bulk_dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] == \"raul\"]\n",
    "\n",
    "# # df_bulk_dft = df_bulk_dft[[\"atoms\", \"energy_pa\"]]\n",
    "# df_bulk_dft = df_bulk_dft[[\"atoms\", \"dH\"]]\n",
    "# df_bulk_dft.columns.values[1] = \"y_real\"\n",
    "\n",
    "# df_features_pre = out_dict[\"df_features_pre\"]\n",
    "# df_features_post = out_dict[\"df_features_post\"]\n",
    "\n",
    "# df_ids = out_dict[\"df_ids\"]\n",
    "\n",
    "\n",
    "# df_static_irox = out_dict[\"df_static_irox\"]\n",
    "# df_dij = out_dict[\"df_dij\"]\n",
    "# # -\n",
    "\n",
    "# # # Filter to candidates w/ DFT energy\n",
    "\n",
    "# # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "# ids_w_dft = df_bulk_dft.index\n",
    "\n",
    "# # TEMP | Reduce size of candidate space\n",
    "# # np.random.seed(8)\n",
    "# # ids_w_dft = np.sort(np.random.choice(np.sort(ids_w_dft), size=200))\n",
    "# ids_w_dft = list(set(ids_w_dft))\n",
    "# # print(\"ids_w_dft:\", ids_w_dft)\n",
    "\n",
    "# df_bulk_dft = df_bulk_dft.loc[ids_w_dft]\n",
    "\n",
    "# df_features_pre = df_features_pre.loc[ids_w_dft]\n",
    "# df_features_post = df_features_post.loc[ids_w_dft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_post"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
