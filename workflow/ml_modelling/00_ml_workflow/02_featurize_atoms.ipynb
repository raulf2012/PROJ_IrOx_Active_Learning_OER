{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurize Atoms Object with Voronoi Tesslation\n",
    "---\n",
    "\n",
    "Feature dimension reduction will be performed using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from catlearn.fingerprint.voro import VoronoiFingerprintGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/outdata\",\n",
    "    \"01_irox_data_featurized.pickle\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_i, \"rb\") as fle:\n",
    "    df_m = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Voronoi Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Voronoi fingerprint of 968 structures\n"
     ]
    }
   ],
   "source": [
    "VFG = VoronoiFingerprintGenerator(df_m[\"default_columns\"][\"atoms\"].tolist())\n",
    "df_vor = VFG.generate()\n",
    "test_features = df_vor.values\n",
    "\n",
    "# Setting Voronai index to those in the main dataframe\n",
    "df_vor = df_vor.set_index(\n",
    "    df_m.index.values,\n",
    "    drop=True,\n",
    "    append=False,\n",
    "    inplace=False,\n",
    "    verify_integrity=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Columns of Non-unique Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = []\n",
    "for column in df_vor:\n",
    "    num_unique_vals = len(list(set(df_vor[column].tolist())))\n",
    "    if num_unique_vals == 1:\n",
    "        columns_to_remove.append(column)\n",
    "\n",
    "df_vor = df_vor.drop(columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59202418 0.32869709 0.05278911 0.02406058 0.00240959]\n",
      "[1.43460651e+04 1.06895889e+04 4.28385963e+03 2.89211892e+03\n",
      " 9.15238696e+02 6.90682674e+01 4.19473093e+01 1.32580282e+01\n",
      " 5.46530440e+00 3.31201459e+00 2.45408953e+00 2.00789795e+00\n",
      " 1.39430974e+00 1.26570748e+00 9.92269604e-01 8.38090660e-01\n",
      " 6.21571382e-01 3.94278091e-01 3.62405775e-01 2.31319327e-01]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(\n",
    "    n_components=20,\n",
    "    # n_components=len(df_vor.columns.values),\n",
    "    )\n",
    "\n",
    "pca.fit(df_vor.values)\n",
    "\n",
    "print(pca.explained_variance_ratio_[0:5])\n",
    "print(pca.singular_values_)\n",
    "\n",
    "pca_features = pca.fit_transform(df_vor.values)\n",
    "df_pca_features = pd.DataFrame(pca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5920241809332064\n",
      "0.9207212699897339\n",
      "0.9735103769229374\n",
      "0.9975709598714368\n",
      "0.9999805468020805\n",
      "0.9999942692305316\n",
      "0.9999993307634653\n",
      "0.999999836392175\n",
      "0.999999922313816\n",
      "0.9999999538681003\n",
      "0.9999999711923588\n",
      "0.9999999827896651\n",
      "0.9999999883819897\n",
      "0.9999999929902875\n",
      "0.9999999958225483\n",
      "0.9999999978430343\n",
      "0.9999999989543972\n",
      "0.9999999994015738\n",
      "0.9999999997793756\n",
      "0.9999999999332966\n"
     ]
    }
   ],
   "source": [
    "var_cum = 0.\n",
    "for i in pca.explained_variance_ratio_:\n",
    "    tmp = 42\n",
    "    var_cum += i\n",
    "    print(var_cum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append PCA Features to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_i = [df_m.columns.levels[0][0], df_m.columns.levels[0][1], \"features_pca\"]\n",
    "\n",
    "df_list = [\n",
    "    df_m[df_m.columns.levels[0][0]],\n",
    "    df_m[df_m.columns.levels[0][1]],\n",
    "    df_pca_features,\n",
    "    ]\n",
    "\n",
    "df_m = pd.concat(\n",
    "    df_list,\n",
    "    # [df_m, df_pca_features],\n",
    "    axis=1,\n",
    "    join_axes=[df_m.index],\n",
    "    keys=keys_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Dataframe to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"outdata\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "with open(directory + \"/02_data_featurized.pickle\", \"wb\") as fle:\n",
    "    pickle.dump(df_m, fle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names\n",
    "# levels\n",
    "# codes\n",
    "# nlevels\n",
    "# levshape\n",
    "\n",
    "# df_m.columns.levshape\n",
    "\n",
    "# df_m.columns?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_bare]",
   "language": "python",
   "name": "conda-env-test_bare-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
