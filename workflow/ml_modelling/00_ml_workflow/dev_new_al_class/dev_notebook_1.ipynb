{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gpflow\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from catlearn.regression.gaussian_process import GaussianProcess\n",
    "from catlearn.preprocess.clean_data import (\n",
    "    clean_infinite,\n",
    "    clean_variance,\n",
    "    clean_skewness)\n",
    "from catlearn.preprocess.scaling import standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (ids_to_discard__too_many_atoms_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "\n",
    "stoich_i = \"AB2\"\n",
    "\n",
    "num_gen_stop = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_data_for_al\n",
    "\n",
    "out_dict = get_data_for_al(stoich=\"AB2\", verbose=False)\n",
    "\n",
    "df_bulk_dft = out_dict[\"df_bulk_dft\"]\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] == \"raul\"]\n",
    "df_bulk_dft = df_bulk_dft[[\"atoms\", \"energy_pa\"]]\n",
    "df_bulk_dft.columns.values[1] = \"y_real\"\n",
    "\n",
    "df_features_pre = out_dict[\"df_features_pre\"]\n",
    "df_features_post = out_dict[\"df_features_post\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "with open(ids_to_discard__too_many_atoms_path, \"rb\") as fle:\n",
    "    ids_to_drop__too_many_atoms = pickle.load(fle)\n",
    "    ids_to_drop__too_many_atoms = \\\n",
    "        [i for i in ids_to_drop__too_many_atoms if i in df_features_pre.index]\n",
    "\n",
    "# #############################################################################\n",
    "df_features_pre = df_features_pre.drop(\n",
    "    labels=ids_to_drop__too_many_atoms,\n",
    "    axis=0)\n",
    "\n",
    "# #############################################################################\n",
    "df_features_post = df_features_post.loc[\n",
    "    [i for i in df_features_post.index if i in df_features_pre.index]]\n",
    "\n",
    "# #############################################################################\n",
    "df_bulk_dft = df_bulk_dft.loc[\n",
    "    [i for i in df_bulk_dft.index if i in df_features_pre.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"python_classes/active_learning\"))\n",
    "from active_learning import (\n",
    "    ALBulkOpt,\n",
    "    ALGeneration,\n",
    "    RegressionModel,\n",
    "    FingerPrints,\n",
    "    CandidateSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gp_settings = {\n",
    "    \"noise\": 0.02542,\n",
    "    \"sigma_l\": 1.0049,\n",
    "    \"sigma_f\": 5.19,\n",
    "    \"alpha\": 0.018,\n",
    "    }\n",
    "\n",
    "RM = RegressionModel(\n",
    "    opt_hyperparameters=True,\n",
    "    gp_settings_dict=gp_settings,\n",
    "    verbose=verbose,\n",
    "    )\n",
    "\n",
    "FP = FingerPrints(\n",
    "    df_features_pre,\n",
    "    df_features_post=df_features_post,\n",
    "    pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "    pca_comp=11,\n",
    "    pca_perc=None,\n",
    "    verbose=verbose,\n",
    "    )\n",
    "\n",
    "CS = CandidateSpace(\n",
    "    Y_data=df_bulk_dft,\n",
    "    Y_key=\"y_real\",\n",
    "    FingerPrints=FP,\n",
    "    )\n",
    "\n",
    "\n",
    "name_i = \"AL_\" + stoich_i + \"_\" + str(num_gen_stop).zfill(2)\n",
    "\n",
    "AL = ALBulkOpt(\n",
    "    CandidateSpace=CS,\n",
    "    RegressionModel=RM,\n",
    "    num_seed_calcs=11,\n",
    "    acquisition_bin=40,\n",
    "    stop_mode=\"num_generations\",\n",
    "    stop_num_generations=num_gen_stop,\n",
    "    name=name_i,\n",
    "    verbose=verbose,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000  | init  |  ****************************************************************\n",
      "000  | final |  ****************************************************************\n",
      "\n",
      "001  | init  |  ****************************************************************\n",
      "001  | final |  ****************************************************************\n",
      "\n",
      "002  | init  |  ****************************************************************\n",
      "002  | final |  ****************************************************************\n",
      "\n",
      "003  | init  |  ****************************************************************\n",
      "003  | final |  ****************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AL.run_AL()\n",
    "\n",
    "AL.__save_state__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###############################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"temp_\" + name_i), \"wb\") as fle:\n",
    "    pickle.dump(AL, fle)\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = AL.al_gen_dict[0]\n",
    "with open(os.path.join(directory, \"temp_single_gen.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(temp_data, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(directory, \"df_bulk_dft.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_bulk_dft, fle)\n",
    "\n",
    "with open(os.path.join(directory, \"df_features_post.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_features_post, fle)\n",
    "\n",
    "with open(os.path.join(directory, \"df_features_pre.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_features_pre, fle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING | TEMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ALBulkOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "self = AL\n",
    "\n",
    "# #############################################################################\n",
    "CandidateSpace = self.CandidateSpace\n",
    "acquisition_bin = self.acquisition_bin\n",
    "al_gen = self.al_gen\n",
    "al_gen_dict = self.al_gen_dict\n",
    "completed_ids = self.completed_ids\n",
    "get_seed_ids = self.get_seed_ids\n",
    "mode = self.mode\n",
    "num_seed_calcs = self.num_seed_calcs\n",
    "run_AL = self.run_AL\n",
    "seed_ids = self.seed_ids\n",
    "verbose = self.verbose\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ALGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "AL_i = AL.al_gen_dict[3]\n",
    "self = AL_i\n",
    "\n",
    "# #############################################################################\n",
    "completed_ids = self.completed_ids\n",
    "CandidateSpace = self.CandidateSpace\n",
    "verbose = self.verbose\n",
    "df_train = self.df_train\n",
    "df_test = self.df_test\n",
    "verbose = self.verbose\n",
    "acquisition_bin = self.acquisition_bin\n",
    "RegressionModel = self.RegressionModel\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing CandidateSpace"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# acquisition_method=\"gp_ucb\"  # 'gp_ucb' or 'random'\n",
    "# # #####################################################################\n",
    "# acquisition_bin = self.acquisition_bin\n",
    "# model = self.model\n",
    "# # #####################################################################\n",
    "# if acquisition_method == \"gp_ucb\":\n",
    "#     acquisition_ids_ordered = self.acquisition_gp_ucb(model, kappa=1.)\n",
    "# elif acquisition_method == \"random\":\n",
    "#     acquisition_ids_ordered = self.acquisition_random(model)\n",
    "\n",
    "\n",
    "# # Model ordered based on acquisition function\n",
    "# model_tmp = model.loc[acquisition_ids_ordered]\n",
    "\n",
    "# # Remove rows for which DFT data is not available\n",
    "# model_data_avail = model_tmp[~model_tmp[\"y_real\"].isna()]\n",
    "\n",
    "# # Remove rows which have already been acquired\n",
    "# # Only acquire what hasn't already been acquired\n",
    "# model_data_avail = model_data_avail[model_data_avail[\"acquired\"] == False]\n",
    "\n",
    "# new_acquis_ids = model_data_avail.index[0:acquisition_bin].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickling data ###############################################################\n",
    "# import os; import pickle\n",
    "# directory = \"out_data\"\n",
    "# if not os.path.exists(directory): os.makedirs(directory)\n",
    "# with open(os.path.join(directory, \"AL_ab2.pickle\"), \"wb\") as fle:\n",
    "#     pickle.dump(AL, fle)\n",
    "# # #############################################################################"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:research-new]",
   "language": "python",
   "name": "conda-env-research-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
