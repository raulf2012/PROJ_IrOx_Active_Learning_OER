{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from ccf_similarity.ccf import CCF\n",
    "\n",
    "from active_learning.al_analysis import ALPerformance\n",
    "\n",
    "from plotting.my_plotly import my_plotly_plot\n",
    "\n",
    "# #########################################################\n",
    "# Local Import ############################################\n",
    "from layout import layout\n",
    "from inputs import stoich_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing command line options for stoich_i"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_arg = sys.argv[-1]\n",
    "\n",
    "print(last_arg)\n",
    "\n",
    "if last_arg == \"AB2\" or last_arg == \"AB3\":\n",
    "    stoich_i = last_arg\n",
    "    \n",
    "print(\"stoich_i:\", stoich_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow\"))\n",
    "from al_data import al_data_files_dict\n",
    "\n",
    "files_list_gp_ucb = al_data_files_dict[stoich_i][\"files_list_gp_ucb\"]\n",
    "files_list_random = al_data_files_dict[stoich_i][\"files_list_random\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if stoich_i == \"AB2\":\n",
    "#     files_list_gp_ucb = al_data_files_dict[stoich_i][\"files_list_ab2_gp_ucb\"]\n",
    "#     files_list_random = al_data_files_dict[stoich_i][\"files_list_ab2_random\"]\n",
    "# elif stoich_i == \"AB3\":\n",
    "#     files_list_gp_ucb = al_data_files_dict[stoich_i][\"files_list_ab3_gp_ucb\"]\n",
    "#     files_list_random = al_data_files_dict[stoich_i][\"files_list_ab3_random\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list_random[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "perc_of_structs = 2.5\n",
    "\n",
    "num_disc = 7\n",
    "\n",
    "subdirs_list = [\"gp_ucb\", \"random\"]\n",
    "\n",
    "shared_scatter_props = dict(\n",
    "    mode=\"lines\",\n",
    "    )\n",
    "\n",
    "data_path_root = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow\",\n",
    "    \"191102_new_workflow/00_abx_al_runs/out_data\",\n",
    "    stoich_i,\n",
    "    # \"gp_ucb_False\",\n",
    "    )\n",
    "\n",
    "\n",
    "from inputs import top_ids_to_track_ab2, top_ids_to_track_ab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_guidlines = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if stoich_i == \"AB2\":\n",
    "    top_ids_to_track = top_ids_to_track_ab2\n",
    "elif stoich_i == \"AB3\":\n",
    "    top_ids_to_track = top_ids_to_track_ab3\n",
    "else:\n",
    "    print(\"ISDJIFSDJI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def process_data(\n",
    "    subdir=None,\n",
    "    shared_scatter_props=None,\n",
    "    unique_scatter_props=None,\n",
    "    ALPerf_account_duplicates=True,\n",
    "    top_ids_to_track=None,\n",
    "    files_list=None,\n",
    "    color2=None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # | - process_data\n",
    "    out_data_dict = dict()\n",
    "\n",
    "    # #############################################################################\n",
    "    if files_list is not None:\n",
    "        tmp = 42\n",
    "    else:\n",
    "        files_list = os.listdir(\n",
    "            os.path.join(\n",
    "                # dir_i,\n",
    "                data_path_root,\n",
    "                # \"out_data\",\n",
    "                subdir))\n",
    "        files_list = [i for i in files_list if \"pickle\" in i]\n",
    "        files_list = [i for i in files_list if \"AL_\" in i]\n",
    "\n",
    "    # print(files_list)\n",
    "\n",
    "    data_dict = dict()\n",
    "    for file_i in files_list:\n",
    "        # #########################################################################\n",
    "        num = file_i.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "        file_path_i =os.path.join(\n",
    "            data_path_root, subdir, file_i)\n",
    "        # COMBAK\n",
    "        # with open(file_path_i, \"rb\") as fle:\n",
    "        with open(file_i, \"rb\") as fle:\n",
    "            AL_i = pickle.load(fle)\n",
    "\n",
    "        data_dict[num] = AL_i\n",
    "    out_data_dict[\"AL_dict\"] = data_dict\n",
    "\n",
    "    # #############################################################################\n",
    "    df_list = []\n",
    "    for num, AL in data_dict.items():\n",
    "        ALPerf = ALPerformance(\n",
    "            ALBulkOpt=AL,\n",
    "            verbose=False)\n",
    "        ALPerf.num_sys_discovered(\n",
    "            # perc_of_structs=perc_of_structs,\n",
    "            # account_duplicates=ALPerf_account_duplicates,\n",
    "\n",
    "            mode=\"user_specified\",  # 'perc' or 'num'\n",
    "            # mode=\"perc\",  # 'perc' or 'num'\n",
    "            perc_of_structs=perc_of_structs,\n",
    "            num_structs=None,\n",
    "            ids_to_track=top_ids_to_track,\n",
    "            account_duplicates=ALPerf_account_duplicates,\n",
    "\n",
    "            )\n",
    "\n",
    "        # #########################################################################\n",
    "        df = ALPerf.num_sys_discovered_df\n",
    "        df_list.append(df)\n",
    "\n",
    "\n",
    "    df_m = pd.concat(\n",
    "        df_list,\n",
    "        axis=1,\n",
    "        keys=data_dict.keys(),\n",
    "        )\n",
    "\n",
    "    # Checking that the x-axis series are all the same\n",
    "    # Necessary if the different runs are to be averaged\n",
    "    x_axis_series_list = []\n",
    "    for i in data_dict.keys():\n",
    "        x_axis_series = df_m[i][\"num_dft\"].tolist()\n",
    "        x_axis_series_list.append(x_axis_series)\n",
    "    all_x_axis_the_same = all(x_axis_series_list)\n",
    "    assert all_x_axis_the_same is True, \"ISFIDSIFJISDIfj\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #############################################################################\n",
    "    # df_m.index = df_m[0, \"num_dft\"].tolist()\n",
    "    df_m.index = x_axis_series\n",
    "\n",
    "\n",
    "    # #############################################################################\n",
    "    for i in data_dict.keys():\n",
    "        del df_m[i, \"num_dft\"]\n",
    "\n",
    "        \n",
    "    # TEMP\n",
    "    # out_data_dict[\"df_perf\"] = df_m\n",
    "    # return(out_data_dict)\n",
    "    \n",
    "    \n",
    "    columns_list = list(df_m.columns.levels[0])\n",
    "    col = df_m.loc[: , columns_list[0]:columns_list[-1]]\n",
    " \n",
    "    # col = df_m.loc[: , 0:list(df_m.columns.levels[0])[-1]]\n",
    "\n",
    "    y_mean = col.mean(axis=1)\n",
    "    y_std = col.std(axis=1)\n",
    "\n",
    "    df_ave = pd.DataFrame()\n",
    "    df_ave[\"y_mean\"] = y_mean\n",
    "    df_ave[\"y_std\"] = y_std\n",
    "    df_ave.index = df_m.index\n",
    "\n",
    "    # Adding 0 to trace\n",
    "    df_ave.loc[0] = [0, 0]\n",
    "    df_ave = df_ave.sort_index()\n",
    "\n",
    "    dx = df_ave.index.values[-1] - df_ave.index.values[-2]\n",
    "    # last_data_point_ind = df_ave.index.values[-1] + dx\n",
    "    last_data_point_ind = df_ave.index.values[-1] + 50\n",
    "    df_ave.loc[last_data_point_ind] = [10, 0]\n",
    "\n",
    "    # df_ave.loc[260] = [10, 0]\n",
    "    df_ave = df_ave.sort_index()\n",
    "\n",
    "\n",
    "    out_data_dict[\"df_perf\"] = df_m\n",
    "\n",
    "    traces = []\n",
    "    # #############################################################################\n",
    "    trace = go.Scatter(\n",
    "        x=df_ave.index.tolist(),\n",
    "        y=df_ave[\"y_mean\"],\n",
    "        line=dict(\n",
    "            width=1.,\n",
    "            ),\n",
    "        )\n",
    "    trace.update(**shared_scatter_props)\n",
    "    trace.update(**unique_scatter_props)\n",
    "    traces.append(trace)\n",
    "    # #########################################################################\n",
    "    trace = go.Scatter(\n",
    "        x=df_ave.index.tolist(),\n",
    "        y=df_ave[\"y_mean\"] + df_ave[\"y_std\"],\n",
    "        line=dict(\n",
    "            width=0.5,\n",
    "            ),\n",
    "        )\n",
    "    trace.update(**shared_scatter_props)\n",
    "    trace.update(**unique_scatter_props)\n",
    "    traces.append(trace)\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x=df_ave.index.tolist(),\n",
    "        y=df_ave[\"y_mean\"] - df_ave[\"y_std\"],\n",
    "        fill=\"tonexty\",\n",
    "        line=dict(\n",
    "            width=0.5,\n",
    "            # color=\"red\",\n",
    "            ),\n",
    "        )\n",
    "    trace.update(**shared_scatter_props)\n",
    "    trace.update(**unique_scatter_props)\n",
    "    traces.append(trace)\n",
    "    # #########################################################################\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x=df_ave.index.tolist(),\n",
    "        y=df_ave[\"y_mean\"] - df_ave[\"y_std\"],\n",
    "        line=dict(\n",
    "            width=0.5,\n",
    "            color=color2,\n",
    "            ),\n",
    "        )\n",
    "    trace.update(**shared_scatter_props)\n",
    "    trace.update(**unique_scatter_props)\n",
    "    traces.append(trace)\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x=df_ave.index.tolist(),\n",
    "        y=df_ave[\"y_mean\"] + df_ave[\"y_std\"],\n",
    "        line=dict(\n",
    "            width=0.5,\n",
    "            color=color2,\n",
    "            ),\n",
    "        )\n",
    "    trace.update(**shared_scatter_props)\n",
    "    trace.update(**unique_scatter_props)\n",
    "    traces.append(trace)\n",
    "\n",
    "    # out_data_dict[\"trace\"] = trace\n",
    "    out_data_dict[\"trace\"] = traces\n",
    "    out_data_dict[\"df_ave\"] = df_ave\n",
    "\n",
    "    return(out_data_dict)\n",
    "    #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Random | w/ Duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "color_i = \"rgb(100,100,100,0.5)\"\n",
    "out_data_dict_i = process_data(\n",
    "    # files_list=files_list,\n",
    "    files_list=files_list_random,\n",
    "\n",
    "    # from inputs import files_list_gp_ucb, files_list_random\n",
    "\n",
    "    subdir=\"random_True\",\n",
    "    unique_scatter_props=dict(\n",
    "        name=\"random w/ dupl\",\n",
    "        marker=dict(color=color_i),\n",
    "        error_y=dict(\n",
    "            # color=color_i,\n",
    "            # color=\"red\",\n",
    "            ),\n",
    "        ),\n",
    "    shared_scatter_props=shared_scatter_props,\n",
    "    ALPerf_account_duplicates=True,\n",
    "    top_ids_to_track=top_ids_to_track,\n",
    "    color2=\"rgb(100,100,100,1.)\",\n",
    "    )\n",
    "trace_i = out_data_dict_i[\"trace\"]\n",
    "data.extend(trace_i)\n",
    "\n",
    "df_perf_random = out_data_dict_i[\"df_perf\"]\n",
    "# df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num of runs random:\", \"\\n\", df_perf_random.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave = out_data_dict_i[\"df_ave\"]\n",
    "\n",
    "x_interc0 = np.interp(\n",
    "    num_disc,\n",
    "    df_ave.y_mean.tolist(),\n",
    "    df_ave.index.tolist(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Random | w/o Duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # #############################################################################\n",
    "# # color_i = \"grey\"\n",
    "# color_i = \"rgb(60,120,100,0.5)\"\n",
    "# out_data_dict_i = process_data(\n",
    "#     subdir=\"random_False\",\n",
    "#     unique_scatter_props=dict(\n",
    "#         name=\"random w/o dupl\",\n",
    "#         marker=dict(color=color_i),\n",
    "#         error_y=dict(\n",
    "#             color=color_i,\n",
    "#             ),\n",
    "#         ),\n",
    "#     shared_scatter_props=shared_scatter_props,\n",
    "#     ALPerf_account_duplicates=False,\n",
    "#     top_ids_to_track=top_ids_to_track,\n",
    "#     )\n",
    "# trace_i = out_data_dict_i[\"trace\"]\n",
    "# # data.append(trace_i)\n",
    "# data.extend(trace_i)\n",
    "\n",
    "# df_perf = out_data_dict_i[\"df_perf\"]\n",
    "# # df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# GP-UCB | w/ Duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# color_i = \"red\"\n",
    "color_i = \"rgba(0,100,255,0.5)\"\n",
    "\n",
    "out_data_dict_i = process_data(\n",
    "    # files_list=files_list,\n",
    "    files_list=files_list_gp_ucb,\n",
    "    subdir=\"gp_ucb_True/01_attempt\",\n",
    "    unique_scatter_props=dict(\n",
    "        name=\"gp_ucb w/ dupl\",\n",
    "        marker=dict(color=color_i),\n",
    "        error_y=dict(\n",
    "            color=color_i,\n",
    "            ),\n",
    "        ),\n",
    "    shared_scatter_props=shared_scatter_props,\n",
    "    ALPerf_account_duplicates=True,\n",
    "    top_ids_to_track=top_ids_to_track,\n",
    "    # color_i = \"rgba(0,100,255,0.5)\"\n",
    "    color2=\"rgba(0,100,255,1.)\",\n",
    "    )\n",
    "trace_i = out_data_dict_i[\"trace\"]\n",
    "data.extend(trace_i)\n",
    "\n",
    "df_perf_gpucb = out_data_dict_i[\"df_perf\"]\n",
    "# df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num of runs GP-UCB:\", \"\\n\", df_perf_gpucb.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave = out_data_dict_i[\"df_ave\"]\n",
    "\n",
    "x_interc1 = np.interp(\n",
    "    num_disc,\n",
    "    df_ave.y_mean.tolist(),\n",
    "    df_ave.index.tolist(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# GP-UCB | w/o Duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # #############################################################################\n",
    "# color_i = \"orange\"\n",
    "# out_data_dict_i = process_data(\n",
    "#     subdir=\"gp_ucb_False\",\n",
    "#     unique_scatter_props=dict(\n",
    "#         name=\"gp_ucb w/o dupl\",\n",
    "#         marker=dict(color=color_i),\n",
    "#         error_y=dict(\n",
    "#             color=color_i,\n",
    "#             ),\n",
    "#         ),\n",
    "#     shared_scatter_props=shared_scatter_props,\n",
    "#     ALPerf_account_duplicates=True,\n",
    "#     top_ids_to_track=top_ids_to_track,\n",
    "#     )\n",
    "# trace_i = out_data_dict_i[\"trace\"]\n",
    "# # data.append(trace_i)\n",
    "# data.extend(trace_i)\n",
    "\n",
    "# df_perf = out_data_dict_i[\"df_perf\"]\n",
    "# # df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red guide-lines"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shared_shape_dict = dict(\n",
    "    xref=\"x\", yref=\"y\",\n",
    "    type=\"line\",\n",
    "    line=dict(\n",
    "        color=\"red\",\n",
    "        width=1.5,\n",
    "        dash=\"dot\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "shapes = tuple([\n",
    "\n",
    "    go.layout.Shape(\n",
    "        x0=x_interc1,  y0=-1,\n",
    "        x1=x_interc1, y1=num_disc,\n",
    "        **shared_shape_dict),\n",
    "\n",
    "    go.layout.Shape(\n",
    "        x0=0,  y0=num_disc,\n",
    "        x1=x_interc1, y1=num_disc,\n",
    "        **shared_shape_dict),\n",
    "\n",
    "\n",
    "    go.layout.Shape(\n",
    "        x0=x_interc0,  y0=-1,\n",
    "        x1=x_interc0, y1=num_disc,\n",
    "        **shared_shape_dict),\n",
    "\n",
    "    go.layout.Shape(\n",
    "        x0=0,  y0=num_disc,\n",
    "        x1=x_interc0, y1=num_disc,\n",
    "        **shared_shape_dict),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Plotting"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "layout[\"height\"] = 37.795275591 * 7.12\n",
    "layout[\"width\"] = 37.795275591 * 6.3\n",
    "\n",
    "layout[\"paper_bgcolor\"] = \"rgba(0,0,0,0)\"\n",
    "layout[\"plot_bgcolor\"] = \"rgba(0,0,0,0)\"\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "if stoich_i == \"AB2\":\n",
    "    x_range = [-0.8, 470]\n",
    "    y_range = [-0.3, 10.6]\n",
    "elif stoich_i == \"AB3\":\n",
    "    x_range = [-0.8, 250]\n",
    "    y_range = [-0.3, 10.6]\n",
    "\n",
    "if plot_guidlines:\n",
    "    shapes = shapes\n",
    "else:\n",
    "    shapes = None\n",
    "\n",
    "fig.layout.update(\n",
    "    shapes=shapes,\n",
    "    # xaxis=dict(range=[-0.8, 250]),\n",
    "    # yaxis=dict(range=[-0.3, 10.6]),\n",
    "    xaxis=dict(range=x_range),\n",
    "    yaxis=dict(range=y_range),\n",
    "    )\n",
    "\n",
    "# fig = my_plotly_plot(\n",
    "my_plotly_plot(\n",
    "    figure=fig,\n",
    "    plot_name=stoich_i + \"_\" + \"al_performance\",\n",
    "    write_html=True,\n",
    "    write_png=False,\n",
    "    png_scale=6.0,\n",
    "    write_pdf=True,\n",
    "    write_svg=False,\n",
    "    try_orca_write=True,\n",
    "    )\n",
    "\n",
    "\n",
    "fig.layout.update(paper_bgcolor=\"white\")\n",
    "# fig.show()\n",
    "\n",
    "tmp = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.layout.update(dict(\n",
    "#     height=500,\n",
    "#     width=600,\n",
    "#     showlegend=True,\n",
    "#     ))\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Pickling data ######################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# #####################################################################\n",
    "with open(os.path.join(directory, stoich_i + \"_\" + \"fig_al_perf.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(fig, fle)\n",
    "# #####################################################################\n",
    "\n",
    "# #####################################################################\n",
    "with open(os.path.join(directory, stoich_i + \"_\" + \"df_random.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_perf_random, fle)\n",
    "with open(os.path.join(directory, stoich_i + \"_\" + \"df_gbucb.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_perf_gpucb, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_random"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# data_i = []\n",
    "# df_i = df_perf_gpucb\n",
    "# for i_cnt, col_i in enumerate(df_i.columns):\n",
    "#     trace_i = go.Scatter(\n",
    "#         x=df_i[col_i].index,\n",
    "#         y=df_i[col_i].values,\n",
    "#         # name=names_list[i_cnt],\n",
    "#         name=col_i[0],\n",
    "#         )\n",
    "#     data_i.append(trace_i)\n",
    "    \n",
    "# fig = go.Figure(data=data_i)\n",
    "# # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# data_i = []\n",
    "# df_i = df_perf_random\n",
    "# for i_cnt, col_i in enumerate(df_i.columns):\n",
    "#     name_i = col_i[0]\n",
    "\n",
    "#     trace_i = go.Scatter(\n",
    "#         x=df_i[col_i].index,\n",
    "#         y=df_i[col_i].values,\n",
    "#         # name=col_i[0],\n",
    "#         name=name_i,\n",
    "#         )\n",
    "#     data_i.append(trace_i)\n",
    "\n",
    "# fig = go.Figure(data=data_i)\n",
    "# # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # df_ave\n",
    "\n",
    "# df_ave.loc[0] = [0, 0]\n",
    "# df_ave = df_ave.sort_index()\n",
    "\n",
    "# df_ave\n",
    "\n",
    "\n",
    "# df_perf\n",
    "# pifehohu\n",
    "# geheneva\n",
    "# nisoponi\n",
    "\n",
    "# if stoich_i == \"AB3\":\n",
    "#     path_i = os.path.join(\n",
    "#         os.environ[\"PROJ_irox\"],\n",
    "#         \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow/00_abx_al_runs/out_data/AB3/gp_ucb_True\",\n",
    "\n",
    "#         # \"01_attempt/AL_geheneva.pickle\",\n",
    "#         # \"01_attempt/AL_pifehohu.pickle\",\n",
    "        \n",
    "#         # NEW RUNS\n",
    "#         # \"TEST_AL_2_fugunefo.pickle\",\n",
    "#         \"TEST_AL_2_seruladi.pickle\",\n",
    "#         )\n",
    "\n",
    "# pre_path = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow/00_abx_al_runs/out_data/AB3/gp_ucb_True\",\n",
    "#     )\n",
    "\n",
    "# files_list = [\n",
    "#     pre_path + \"/01_attempt/AL_geheneva.pickle\",\n",
    "#     pre_path + \"/01_attempt/AL_nisoponi.pickle\",\n",
    "#     pre_path + \"/01_attempt/AL_pifehohu.pickle\",\n",
    "#     pre_path + \"/01_attempt/AL_suturomo.pickle\",\n",
    "#     pre_path + \"/01_attempt/AL_vobifoko.pickle\",\n",
    "#     pre_path + \"/TEST_AL_masahiti.pickle\",\n",
    "\n",
    "#     # pre_path + \"/TEST_AL_2_devehowo.pickle\",  # Not a good run for some reason\n",
    "#     pre_path + \"/TEST_AL_2_fugunefo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_2_hilerika.pickle\",\n",
    "#     pre_path + \"/TEST_AL_2_pomogobu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_2_seruladi.pickle\",\n",
    "\n",
    "    \n",
    "#     pre_path + \"/TEST_AL_3_bikufupi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_dakubiku.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_duloputo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_fahovara.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_fulomoto.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_laburike.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_libapidi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_nikimido.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_raluduhu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_supemono.pickle\",\n",
    "\n",
    "#     pre_path + \"/TEST_AL_4beradeka.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4buruduwe.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4degekoku.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4deromeru.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4forafago.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4hefehepa.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4kaveboma.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4kihalage.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4lidirope.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4mebetige.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4megimodi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4mohomato.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4moponuso.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4mukigapa.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4nekumuno.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4nipagula.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4nupetofi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4rifibume.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4somageho.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4wolewoba.pickle\",\n",
    "\n",
    "#     pre_path + \"/TEST_AL_5bofufada.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5delepaku.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5derohebi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5dotesiga.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5dumokeru.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5fapehudo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5fenumanu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5gomememu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5gulumobu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5huwihime.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5kanototo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5kibapeto.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5kifomimi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5rukeraku.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5sipeteni.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5sokepefo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5vikowagu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5volibavo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5wigidipu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_5wolowewu.pickle\",\n",
    "    \n",
    "#     pre_path + \"/TEST_AL_6_dodemuho.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_fisopova.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_gelabere.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_gelenuni.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_haligagu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_higusare.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_kagesinu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_liwuderu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_lopukipu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_nubinada.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_pitumimi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_pudapepi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_rividisi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_rovomama.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_sovawafo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_takoliwo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_tehileme.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_tibuduka.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_warusiha.pickle\",\n",
    "#     pre_path + \"/TEST_AL_6_wevuwofu.pickle\",\n",
    "\n",
    "#     ]\n",
    "\n",
    "# pre_path = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow/00_abx_al_runs/out_data/AB3/random_True\",\n",
    "#     # \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow/00_abx_al_runs/out_data/AB3/gp_ucb_True\",\n",
    "#     )\n",
    "\n",
    "# files_list = [\n",
    "#     pre_path + \"/AL_duhakiro.pickle\",\n",
    "#     pre_path + \"/AL_firegohi.pickle\",\n",
    "#     pre_path + \"/AL_givohegu.pickle\",\n",
    "#     pre_path + \"/AL_tiweluku.pickle\",\n",
    "#     pre_path + \"/AL_vevenuwa.pickle\",\n",
    "#     pre_path + \"/TEST_AL_2_fibataha.pickle\",\n",
    "#     pre_path + \"/TEST_AL_2_kitagego.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_bafigika.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_bafomepo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_besurogi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_dotupibu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_fuliguso.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_gosirinu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_gowutoga.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_hiroguwe.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_kavasaki.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_mutefoti.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_nivalula.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_pasimuha.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_sukiwalo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_temonofo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_vesudewa.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_vuwugupi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_walipebi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_wetipotu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_wusabupa.pickle\",\n",
    "#     pre_path + \"/TEST_AL_3_wutonovi.pickle\",\n",
    "\n",
    "#     pre_path + \"/TEST_AL_4_benegeka.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_dehebiko.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_dinisefa.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_fefefigi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_fefesama.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_fivokito.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_fuwasufi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_gekuporu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_gepapeba.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_gerisiwe.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_goderiwo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_hofavasi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_kavadosu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_kudadega.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_masufika.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_menireve.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_metekovo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_mibunova.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_milesumi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_nepubene.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_nuvopeki.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_petosuso.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_pokikugi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_ragifipa.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_rodadibi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_rovukuma.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_sanaruri.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_sapaveme.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_sawuhewe.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_sifisulu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_sifobuwe.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_suhegope.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_teruwufo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_tikeluvi.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_vabesipo.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_visisese.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_wemawumu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_wibemafu.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_wobumone.pickle\",\n",
    "#     pre_path + \"/TEST_AL_4_wohaguha.pickle\",\n",
    "\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_perf_random\n",
    "\n",
    "\n",
    "# # Simple Plotly Plot\n",
    "# import plotly.graph_objs as go\n",
    "# trace = go.Scatter(\n",
    "#     x=df_ave.index.values,\n",
    "#     y=df_ave.y_mean)\n",
    "# data = [trace]\n",
    "# fig = go.Figure(data=data)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_ave[\n",
    "#     (df_ave.index.values < 300) & \\\n",
    "#     (df_ave.index.values > 200)\n",
    "#     ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
