{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_Active_Learning_OER/workflow/ml_modelling/00_ml_workflow/parity_plots\n",
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/misc.py:25: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/misc.py:25: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/training/tensorflow_optimizer.py:157: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/training/tensorflow_optimizer.py:157: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raul_desktop/anaconda3/envs/PROJ_IrOx_Active_Learning_OER/lib/python3.6/site-packages/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new init2!\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gpflow\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# #############################################################################\n",
    "from catlearn.regression.gaussian_process import GaussianProcess\n",
    "from catlearn.preprocess.clean_data import (\n",
    "    clean_infinite,\n",
    "    clean_variance,\n",
    "    clean_skewness)\n",
    "from catlearn.preprocess.scaling import standardize\n",
    "\n",
    "# #############################################################################\n",
    "from active_learning.al_bulkopt import ALBulkOpt\n",
    "from active_learning.active_learning import (\n",
    "    RegressionModel,\n",
    "    FingerPrints,\n",
    "    CandidateSpace,\n",
    "    )\n",
    "from active_learning.al_analysis import ALAnalysis, ALAnimation\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich_i = \"AB3\"\n",
    "# stoich_i = \"AB2\"\n",
    "verbose = True\n",
    "name_i = \"TEMP\"\n",
    "save_dir_extra=None\n",
    "acquisition_method=None\n",
    "duplicate_analysis=None\n",
    "seed=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoich_i: AB3\n"
     ]
    }
   ],
   "source": [
    "if sys.argv[-1] == \"AB2\" or sys.argv[-1] == \"AB3\":\n",
    "    stoich_i = sys.argv[-1]\n",
    "    \n",
    "print(\"stoich_i:\", stoich_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISDFIODISFIDS*F*SDF*SDYUGFSODIUFG\n",
      "6fcdbh9fz2 in df_bulk_dft True\n",
      "ISDFIODISFIDS*F*SDF*SDYUGFSODIUFG\n",
      "6fcdbh9fz2 in df_bulk_dft True\n",
      "ISDFIODISFIDS*F*SDF*SDYUGFSODIUFG\n",
      "6fcdbh9fz2 in df_bulk_dft True\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_data_for_al\n",
    "\n",
    "out_dict = get_data_for_al(\n",
    "    stoich=stoich_i, verbose=False,\n",
    "    drop_too_many_atoms=True,\n",
    "#     drop_too_many_atoms=False,\n",
    "    )\n",
    "\n",
    "df_bulk_dft = out_dict[\"df_bulk_dft\"]\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] == \"raul\"]\n",
    "\n",
    "# df_bulk_dft = df_bulk_dft[[\"atoms\", \"energy_pa\"]]\n",
    "df_bulk_dft = df_bulk_dft[[\"atoms\", \"dH\"]]\n",
    "df_bulk_dft.columns.values[1] = \"y_real\"\n",
    "\n",
    "df_features_pre = out_dict[\"df_features_pre\"]\n",
    "df_features_post = out_dict[\"df_features_post\"]\n",
    "\n",
    "df_ids = out_dict[\"df_ids\"]\n",
    "\n",
    "\n",
    "df_static_irox = out_dict[\"df_static_irox\"]\n",
    "df_dij = out_dict[\"df_dij\"]\n",
    "\n",
    "# -\n",
    "\n",
    "# # Filter to candidates w/ DFT energy\n",
    "\n",
    "# + {\"jupyter\": {\"source_hidden\": true}}\n",
    "ids_w_dft = df_bulk_dft.index\n",
    "\n",
    "# TEMP | Reduce size of candidate space\n",
    "# np.random.seed(8)\n",
    "# ids_w_dft = np.sort(np.random.choice(np.sort(ids_w_dft), size=200))\n",
    "ids_w_dft = list(set(ids_w_dft))\n",
    "# print(\"ids_w_dft:\", ids_w_dft)\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.loc[ids_w_dft]\n",
    "\n",
    "df_features_pre = df_features_pre.loc[ids_w_dft]\n",
    "df_features_post = df_features_post.loc[ids_w_dft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning variance:\n",
      "train_data.shape: (208, 271)\n",
      "df_train.shape: (208, 101)\n",
      "\n",
      "Cleaning skewness:\n",
      "train_data.shape: (208, 101)\n",
      "train_data.shape: (208, 83)\n",
      "\n",
      "Cleaning infinite:\n",
      "train_data.shape: (208, 83)\n",
      "train_data.shape: (208, 83)\n",
      "\n",
      "num_pca_comp:  10\n",
      "(208, 83)\n",
      "(208, 10)\n",
      "This if is True\n",
      "Cleaning variance:\n",
      "train_data.shape: (208, 271)\n",
      "df_train.shape: (208, 101)\n",
      "\n",
      "Cleaning skewness:\n",
      "train_data.shape: (208, 101)\n",
      "train_data.shape: (208, 84)\n",
      "\n",
      "Cleaning infinite:\n",
      "train_data.shape: (208, 84)\n",
      "train_data.shape: (208, 84)\n",
      "\n",
      "num_pca_comp:  10\n",
      "(208, 84)\n",
      "(208, 10)\n",
      "This if is True\n",
      "Cleaning variance:\n",
      "train_data.shape: (208, 271)\n",
      "df_train.shape: (208, 101)\n",
      "\n",
      "Cleaning skewness:\n",
      "train_data.shape: (208, 101)\n",
      "train_data.shape: (208, 83)\n",
      "\n",
      "Cleaning infinite:\n",
      "train_data.shape: (208, 83)\n",
      "train_data.shape: (208, 83)\n",
      "\n",
      "num_pca_comp:  10\n",
      "(208, 83)\n",
      "(208, 10)\n",
      "This if is True\n",
      "Cleaning variance:\n",
      "train_data.shape: (208, 271)\n",
      "df_train.shape: (208, 101)\n",
      "\n",
      "Cleaning skewness:\n",
      "train_data.shape: (208, 101)\n",
      "train_data.shape: (208, 83)\n",
      "\n",
      "Cleaning infinite:\n",
      "train_data.shape: (208, 83)\n",
      "train_data.shape: (208, 83)\n",
      "\n",
      "num_pca_comp:  10\n",
      "(208, 83)\n",
      "(208, 10)\n",
      "This if is True\n",
      "Cleaning variance:\n",
      "train_data.shape: (208, 271)\n",
      "df_train.shape: (208, 101)\n",
      "\n",
      "Cleaning skewness:\n",
      "train_data.shape: (208, 101)\n",
      "train_data.shape: (208, 84)\n",
      "\n",
      "Cleaning infinite:\n",
      "train_data.shape: (208, 84)\n",
      "train_data.shape: (208, 84)\n",
      "\n",
      "num_pca_comp:  10\n",
      "(208, 84)\n",
      "(208, 10)\n",
      "This if is True\n",
      "Cleaning variance:\n",
      "train_data.shape: (208, 271)\n",
      "df_train.shape: (208, 101)\n",
      "\n",
      "Cleaning skewness:\n",
      "train_data.shape: (208, 101)\n",
      "train_data.shape: (208, 66)\n",
      "\n",
      "Cleaning infinite:\n",
      "train_data.shape: (208, 66)\n",
      "train_data.shape: (208, 66)\n",
      "\n",
      "num_pca_comp:  10\n",
      "(208, 66)\n",
      "(208, 10)\n",
      "This if is True\n",
      "Cleaning variance:\n",
      "train_data.shape: (240, 271)\n",
      "df_train.shape: (240, 101)\n",
      "\n",
      "Cleaning skewness:\n",
      "train_data.shape: (240, 101)\n",
      "train_data.shape: (240, 83)\n",
      "\n",
      "Cleaning infinite:\n",
      "train_data.shape: (240, 83)\n",
      "train_data.shape: (240, 83)\n",
      "\n",
      "num_pca_comp:  10\n",
      "(240, 83)\n",
      "(240, 10)\n",
      "This if is True\n"
     ]
    }
   ],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield(l[i:i + n])\n",
    "\n",
    "models_list = []\n",
    "for i_cnt, i in enumerate(chunks(ids_w_dft, 40)):\n",
    "    \n",
    "    leave_out_ids = i\n",
    "    \n",
    "\n",
    "    # df_post_i = df_features_post.drop(labels=leave_out_ids)\n",
    "    # df_features_post\n",
    "    # leave_out_ids\n",
    "\n",
    "    FP = FingerPrints(\n",
    "        df_features_pre,\n",
    "        df_features_post=df_features_post,\n",
    "        pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "        pca_comp=10,\n",
    "        pca_perc=None,\n",
    "        verbose=verbose,\n",
    "        )\n",
    "\n",
    "    CS = CandidateSpace(\n",
    "        Y_data=df_bulk_dft,\n",
    "        Y_key=\"y_real\",\n",
    "        FingerPrints=FP,\n",
    "        )\n",
    "\n",
    "    df_train = CS.FingerPrints.df_post.drop(labels=leave_out_ids)\n",
    "    df_test = CS.FingerPrints.df_post.loc[leave_out_ids]\n",
    "    # df_test = CS.FingerPrints.df_pre\n",
    "\n",
    "    FP.clean_data(df_train, df_test)\n",
    "    FP.pca_analysis()\n",
    "\n",
    "    df_train = FP.df_train\n",
    "    df_test = FP.df_test\n",
    "\n",
    "\n",
    "\n",
    "    gp_settings = {\n",
    "        \"noise\": 0.02542,\n",
    "        \"sigma_l\": 1.0049,\n",
    "        \"sigma_f\": 5.19,\n",
    "        \"alpha\": 0.018,\n",
    "        }\n",
    "\n",
    "    RM = RegressionModel(\n",
    "        df_train=df_train,\n",
    "        # train_targets=CS.Y_data_series,\n",
    "        train_targets=CS.Y_data_series.drop(labels=leave_out_ids),\n",
    "        df_test=df_test,\n",
    "        opt_hyperparameters=True,\n",
    "        gp_settings_dict=gp_settings,\n",
    "        uncertainty_type='regular',\n",
    "        verbose=verbose,\n",
    "        )\n",
    "\n",
    "    RM.run_regression()\n",
    "\n",
    "    model = pd.concat([\n",
    "        CS.Y_data_series,\n",
    "        RM.model,\n",
    "        ], axis=1, sort=False)\n",
    "\n",
    "    model_i = model[~model[\"y\"].isna()]\n",
    "\n",
    "\n",
    "    models_list.append(model_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_real</th>\n",
       "      <th>y</th>\n",
       "      <th>err</th>\n",
       "      <th>acquired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mfme9lbtxq</th>\n",
       "      <td>-0.545940</td>\n",
       "      <td>-0.520372</td>\n",
       "      <td>0.102613</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8ivkxwnhva</th>\n",
       "      <td>-0.645877</td>\n",
       "      <td>-0.642378</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9ez1cpzj7k</th>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.480881</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71ndci8rx3</th>\n",
       "      <td>-0.274663</td>\n",
       "      <td>-0.110264</td>\n",
       "      <td>0.156877</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7f7svsnpvg</th>\n",
       "      <td>-0.265672</td>\n",
       "      <td>-0.229150</td>\n",
       "      <td>0.216904</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y_real         y       err  acquired\n",
       "mfme9lbtxq -0.545940 -0.520372  0.102613     False\n",
       "8ivkxwnhva -0.645877 -0.642378  0.001458     False\n",
       "9ez1cpzj7k  0.481013  0.480881  0.003234     False\n",
       "71ndci8rx3 -0.274663 -0.110264  0.156877     False\n",
       "7f7svsnpvg -0.265672 -0.229150  0.216904     False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_master = pd.concat(models_list, axis=0, sort=False)\n",
    "\n",
    "model_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Formation Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import os\n",
    "\n",
    "x_array = model_master.y\n",
    "y_array = model_master.y_real\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "\n",
    "    marker=dict(\n",
    "        symbol=\"circle\",\n",
    "        color='blue',\n",
    "\n",
    "        # color=z,\n",
    "        # colorscale='Viridis',\n",
    "        # colorbar=dict(thickness=20),\n",
    "\n",
    "        size=4,\n",
    "        line=dict(\n",
    "            color='black',\n",
    "            width=1,\n",
    "            )\n",
    "        ),\n",
    "\n",
    "    # line=dict(\n",
    "    #     color=\"firebrick\",\n",
    "    #     width=2,\n",
    "    #     dash=\"dot\",\n",
    "    #     ),\n",
    "\n",
    "    # error_y={\n",
    "    #     \"type\": 'data',\n",
    "    #     \"array\": [0.4, 0.9, 0.3, 1.1],\n",
    "    #     \"visible\": True,\n",
    "    #     },\n",
    "\n",
    "    )\n",
    "trace_xy = go.Scatter(x=[-3, 5], y=[-3, 5], mode=\"lines\")\n",
    "data = [trace, trace_xy]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(range=[-3.5, 6]),\n",
    "    yaxis=dict(range=[-3.5, 6])\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master[\"err_pred_real\"] = np.abs(model_master[\"y_real\"] - model_master[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ######################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, stoich_i + \"_\" + \"post_dft_cv_data.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(model_master, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7808a1103591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\"# # \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "assert False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
