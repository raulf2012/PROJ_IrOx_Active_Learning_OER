{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gpflow\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# #############################################################################\n",
    "from catlearn.regression.gaussian_process import GaussianProcess\n",
    "from catlearn.preprocess.clean_data import (\n",
    "    clean_infinite,\n",
    "    clean_variance,\n",
    "    clean_skewness)\n",
    "from catlearn.preprocess.scaling import standardize\n",
    "\n",
    "# #############################################################################\n",
    "from active_learning.al_bulkopt import ALBulkOpt\n",
    "from active_learning.active_learning import (\n",
    "    RegressionModel,\n",
    "    FingerPrints,\n",
    "    CandidateSpace,\n",
    "    )\n",
    "from active_learning.al_analysis import ALAnalysis, ALAnimation\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoich_i = \"AB3\"\n",
    "stoich_i = \"AB2\"\n",
    "verbose = True\n",
    "name_i = \"TEMP\"\n",
    "save_dir_extra=None\n",
    "acquisition_method=None\n",
    "duplicate_analysis=None\n",
    "seed=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_data_for_al\n",
    "\n",
    "out_dict = get_data_for_al(\n",
    "    stoich=stoich_i, verbose=False,\n",
    "    drop_too_many_atoms=True,\n",
    "#     drop_too_many_atoms=False,\n",
    "    )\n",
    "\n",
    "df_bulk_dft = out_dict[\"df_bulk_dft\"]\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] == \"raul\"]\n",
    "\n",
    "# df_bulk_dft = df_bulk_dft[[\"atoms\", \"energy_pa\"]]\n",
    "df_bulk_dft = df_bulk_dft[[\"atoms\", \"dH\"]]\n",
    "df_bulk_dft.columns.values[1] = \"y_real\"\n",
    "\n",
    "df_features_pre = out_dict[\"df_features_pre\"]\n",
    "df_features_post = out_dict[\"df_features_post\"]\n",
    "\n",
    "df_ids = out_dict[\"df_ids\"]\n",
    "\n",
    "\n",
    "df_static_irox = out_dict[\"df_static_irox\"]\n",
    "df_dij = out_dict[\"df_dij\"]\n",
    "\n",
    "# -\n",
    "\n",
    "# # Filter to candidates w/ DFT energy\n",
    "\n",
    "# + {\"jupyter\": {\"source_hidden\": true}}\n",
    "ids_w_dft = df_bulk_dft.index\n",
    "\n",
    "# TEMP | Reduce size of candidate space\n",
    "# np.random.seed(8)\n",
    "# ids_w_dft = np.sort(np.random.choice(np.sort(ids_w_dft), size=200))\n",
    "ids_w_dft = list(set(ids_w_dft))\n",
    "# print(\"ids_w_dft:\", ids_w_dft)\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.loc[ids_w_dft]\n",
    "\n",
    "df_features_pre = df_features_pre.loc[ids_w_dft]\n",
    "df_features_post = df_features_post.loc[ids_w_dft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunks(l, n):\n",
    "#     \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "#     for i in range(0, len(l), n):\n",
    "#         yield(l[i:i + n])\n",
    "\n",
    "# models_list = []\n",
    "# for i_cnt, i in enumerate(chunks(ids_w_dft, 100)):\n",
    "    \n",
    "# leave_out_ids = i\n",
    "\n",
    "\n",
    "# df_post_i = df_features_post.drop(labels=leave_out_ids)\n",
    "# df_features_post\n",
    "# leave_out_ids\n",
    "\n",
    "FP = FingerPrints(\n",
    "    df_features_pre,\n",
    "    df_features_post=df_features_post,\n",
    "    pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "    pca_comp=10,\n",
    "    pca_perc=None,\n",
    "    verbose=verbose,\n",
    "    )\n",
    "\n",
    "CS = CandidateSpace(\n",
    "    Y_data=df_bulk_dft,\n",
    "    Y_key=\"y_real\",\n",
    "    FingerPrints=FP,\n",
    "    )\n",
    "\n",
    "df_train = CS.FingerPrints.df_post\n",
    "# .drop(labels=leave_out_ids)\n",
    "#     df_test = CS.FingerPrints.df_post.loc[leave_out_ids]\n",
    "df_test = CS.FingerPrints.df_pre\n",
    "\n",
    "FP.clean_data(df_train, df_test)\n",
    "FP.pca_analysis()\n",
    "\n",
    "df_train = FP.df_train\n",
    "df_test = FP.df_test\n",
    "\n",
    "\n",
    "\n",
    "gp_settings = {\n",
    "    \"noise\": 0.02542,\n",
    "    \"sigma_l\": 1.0049,\n",
    "    \"sigma_f\": 5.19,\n",
    "    \"alpha\": 0.018,\n",
    "    }\n",
    "\n",
    "RM = RegressionModel(\n",
    "    df_train=df_train,\n",
    "    train_targets=CS.Y_data_series,\n",
    "    # train_targets=CS.Y_data_series.drop(labels=leave_out_ids),\n",
    "    df_test=df_test,\n",
    "    opt_hyperparameters=True,\n",
    "    gp_settings_dict=gp_settings,\n",
    "    uncertainty_type='regular',\n",
    "    verbose=verbose,\n",
    "    )\n",
    "\n",
    "RM.run_regression()\n",
    "\n",
    "model = pd.concat([\n",
    "    CS.Y_data_series,\n",
    "    RM.model,\n",
    "    ], axis=1, sort=False)\n",
    "\n",
    "model_i = model[~model[\"y\"].isna()]\n",
    "\n",
    "\n",
    "# models_list.append(model_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_list[0]\n",
    "\n",
    "# model_master = pd.concat(models_list, axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import os\n",
    "\n",
    "x_array = model.y\n",
    "y_array = model.y_real\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "\n",
    "    marker=dict(\n",
    "        symbol=\"circle\",\n",
    "        color='blue',\n",
    "\n",
    "        # color=z,\n",
    "        # colorscale='Viridis',\n",
    "        # colorbar=dict(thickness=20),\n",
    "\n",
    "        size=4,\n",
    "        line=dict(\n",
    "            color='black',\n",
    "            width=1,\n",
    "            )\n",
    "        ),\n",
    "\n",
    "    # line=dict(\n",
    "    #     color=\"firebrick\",\n",
    "    #     width=2,\n",
    "    #     dash=\"dot\",\n",
    "    #     ),\n",
    "\n",
    "    # error_y={\n",
    "    #     \"type\": 'data',\n",
    "    #     \"array\": [0.4, 0.9, 0.3, 1.1],\n",
    "    #     \"visible\": True,\n",
    "    #     },\n",
    "\n",
    "    )\n",
    "trace_xy = go.Scatter(x=[-3, 5], y=[-3, 5], mode=\"lines\")\n",
    "data = [trace, trace_xy]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(range=[-3.5, 6]),\n",
    "    yaxis=dict(range=[-3.5, 6])\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master = model\n",
    "model_master[\"err_pred_real\"] = np.abs(model_master[\"y_real\"] - model_master[\"y\"])\n",
    "model_master[\"err_pred_real\"].mean()\n",
    "\n",
    "# model_master\n",
    "# -1.658857 - -1.784430\t\n",
    "# 0.12557299999999993"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.20012585885222797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ######################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, stoich_i + \"_\" + \"pre_dft_cv_data.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(model, fle)\n",
    "# #####################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
