{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab2_file_list = [\n",
    "    \"AL_bapihato.pickle\",\n",
    "    \"AL_piritapo.pickle\",\n",
    "    \"AL_tifotogi.pickle\",\n",
    "    \"AL_bavapive.pickle\",\n",
    "    \"AL_ralusubi.pickle\",\n",
    "    ]\n",
    "\n",
    "ab3_file_list = [\n",
    "    \"AL_geheneva.pickle\",\n",
    "    \"AL_pifehohu.pickle\",\n",
    "    \"AL_vobifoko.pickle\",\n",
    "    \"AL_nisoponi.pickle\",\n",
    "    \"AL_suturomo.pickle\",\n",
    "    ]\n",
    "\n",
    "file_list_dict = dict(\n",
    "    AB2=ab2_file_list,\n",
    "    AB3=ab3_file_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = file_list[0]\n",
    "root_data_dir = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow\",\n",
    "    \"00_abx_al_runs/out_data\")\n",
    "path_i = os.path.join(\n",
    "    root_data_dir,\n",
    "    \"AB3/gp_ucb_True\",\n",
    "    \"AL_geheneva.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    AL = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# AL.duplicate_system_history_analysis\n",
    "\n",
    "AL_i = AL.al_gen_dict[49]\n",
    "\n",
    "# AL_i.DuplicateFinder.i_all_similar\n",
    "DuplicateFinder = AL_i.DuplicateFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nudusosi_51', 'hipugusu_53', 'lubepata_68', 'dudebino_86',\n",
       "       'bufukepo_12', 'dudiwibe_42', 'dohudehu_88', 'tahohibu_47',\n",
       "       'wobikafi_29', 'pofokage_60',\n",
       "       ...\n",
       "       'mkvpml8q9e', '7ex5numq8u', '9gcdxhzemj', '8l919k6s7p', 'zqzi9oxozd',\n",
       "       '71ndxsch8y', 'x57yxezkxl', 'bgcpc2vabf', '6tmjv4myvg', 'binlzubqnp'],\n",
       "      dtype='object', name='index', length=504)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DuplicateFinder.i_j_similar(\"64cg6j9any\", \"b46enqnq8e\")\n",
    "\n",
    "# DuplicateFinder.df_dij.index\n",
    "\n",
    "\n",
    "\n",
    "# '64cg6j9any', 'b46enqnq8e', '9yz2mt8hbh'\n",
    "# simil_dict = DuplicateFinder.i_all_similar(\n",
    "#     index_i, filter_ids=filter_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "def get_duplicates_list(stoich_i, file_list_dict=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    file_list = file_list_dict[stoich_i]\n",
    "\n",
    "    duplicates_lists = []\n",
    "    for file in file_list:\n",
    "\n",
    "        # Read Data\n",
    "        root_data_dir = os.path.join(\n",
    "            os.environ[\"PROJ_irox\"],\n",
    "            \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow\",\n",
    "            \"00_abx_al_runs/out_data\")\n",
    "        path_i = os.path.join(\n",
    "            root_data_dir,\n",
    "            \"AB3/gp_ucb_True\",\n",
    "            \"AL_geheneva.pickle\")\n",
    "        with open(path_i, \"rb\") as fle:\n",
    "            AL = pickle.load(fle)\n",
    "\n",
    "\n",
    "        last_gen = list(AL.al_gen_dict.keys())[-1]\n",
    "        AL_i = AL.al_gen_dict[last_gen]\n",
    "\n",
    "        model = AL_i.model\n",
    "        model.sort_values(\"y_real\")\n",
    "\n",
    "        duplicates_i = model[model.duplicate == True].index.tolist()\n",
    "        # print(len(duplicates_i))\n",
    "\n",
    "        duplicates_lists.append(duplicates_i)\n",
    "\n",
    "    # #########################################################################\n",
    "    # Checking that all duplicates lists are the same #########################\n",
    "    duplicates_are_the_same_list = []\n",
    "    for duplicates_i in duplicates_lists:\n",
    "        for duplicates_j in duplicates_lists:\n",
    "            duplicates_are_the_same = duplicates_j == duplicates_i\n",
    "            duplicates_are_the_same_list.append(duplicates_are_the_same)\n",
    "    duplicates_are_the_same_final = all(duplicates_are_the_same_list)\n",
    "    assert duplicates_are_the_same_final, \"IJDSFIISD\"\n",
    "\n",
    "    \n",
    "    return(duplicates_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_ab2 = get_duplicates_list(\"AB2\", file_list_dict=file_list_dict)\n",
    "duplicates_ab3 = get_duplicates_list(\"AB3\", file_list_dict=file_list_dict)\n",
    "\n",
    "duplicates_dict = dict(\n",
    "    AB2=duplicates_ab2,\n",
    "    AB3=duplicates_ab3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ######################################################\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"duplicates.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(duplicates_dict, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing old and new duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_2\"],\n",
    "    \"FIGS_IrOx_Active_Learning_OER/01_figures/00_main_publ_figs/03_E_vs_V_coord/scripts\",\n",
    "    \"old.duplicates.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    duplicates_dict_old = pickle.load(fle)\n",
    "# #############################################################################\n",
    "\n",
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_2\"],\n",
    "    \"FIGS_IrOx_Active_Learning_OER/01_figures/00_main_publ_figs/03_E_vs_V_coord/scripts\",\n",
    "    \"new.duplicates.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    duplicates_dict_new = pickle.load(fle)\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "duplicates_dict_new[\"AB2\"] == duplicates_dict_old[\"AB2\"]\n",
    "\n",
    "print(len(duplicates_dict_new[\"AB2\"]))\n",
    "print(len(duplicates_dict_old[\"AB2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in duplicates_dict_old[\"AB2\"]:\n",
    "#     if id not in duplicates_dict_new[\"AB2\"]:\n",
    "#         print(id)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# AL_geheneva.pickle  AL_pifehohu.pickle  AL_vobifoko.pickle     \n",
    "# AL_nisoponi.pickle  AL_suturomo.pickle  TEST_AL_gehinowi.pickle\n",
    "\n",
    "# # pwd/mnt/f/Dropbox/01_norskov/00_git_repos/\n",
    "# # PROJ_IrOx_Active_Learning_OER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # #############################################################################\n",
    "# root_data_dir = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow\",\n",
    "#     \"00_abx_al_runs/out_data\")\n",
    "\n",
    "# # path_i = os.path.join(\n",
    "# #     root_data_dir,\n",
    "# #     \"AB3/gp_ucb_True\",\n",
    "# #     \"AL_geheneva.pickle\")\n",
    "\n",
    "# path_i = os.path.join(\n",
    "#     root_data_dir,\n",
    "#     \"AB2/gp_ucb_True\",\n",
    "#     \"AL_bapihato.pickle\")\n",
    "\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     AL = pickle.load(fle)\n",
    "# # #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# duplicates_are_the_same_list = []\n",
    "# for duplicates_i in duplicates_lists:\n",
    "#     for duplicates_j in duplicates_lists:\n",
    "#         duplicates_are_the_same = duplicates_j == duplicates_i\n",
    "#         duplicates_are_the_same_list.append(duplicates_are_the_same)\n",
    "# duplicates_are_the_same_final = all(duplicates_are_the_same_list)\n",
    "# assert duplicates_are_the_same_final, \"IJDSFIISD\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
