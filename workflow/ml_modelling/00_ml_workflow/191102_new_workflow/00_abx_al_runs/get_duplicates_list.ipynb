{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Input"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich_i = \"AB3\"\n",
    "\n",
    "ab2_file_list = [\n",
    "\n",
    "    \"gp_ucb_True/AL_bavapive.pickle\",\n",
    "    # \"gp_ucb_True/AL_tifotogi.pickle\",\n",
    "    # \"gp_ucb_True/TEST_AL_muvasubu.pickle\",\n",
    "\n",
    "    # \"AL_bapihato.pickle\",\n",
    "    # \"AL_piritapo.pickle\",\n",
    "    # \"AL_tifotogi.pickle\",\n",
    "    # \"AL_bavapive.pickle\",\n",
    "    # \"AL_ralusubi.pickle\",\n",
    "    ]\n",
    "\n",
    "ab3_file_list = [\n",
    "    \"gp_ucb_True/TEST_AL_2_pomogobu.pickle\",\n",
    "    # \"gp_ucb_True/TEST_AL_3_supemono.pickle\",\n",
    "    # \"gp_ucb_True/TEST_AL_5_gurifigi.pickle\",\n",
    "\n",
    "    # \"AL_geheneva.pickle\",\n",
    "    # \"AL_pifehohu.pickle\",\n",
    "    # \"AL_vobifoko.pickle\",\n",
    "    # \"AL_nisoponi.pickle\",\n",
    "    # \"AL_suturomo.pickle\",\n",
    "    ]\n",
    "\n",
    "file_list_dict = dict(\n",
    "    AB2=ab2_file_list,\n",
    "    AB3=ab3_file_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file = file_list[0]\n",
    "# root_data_dir = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow\",\n",
    "#     \"00_abx_al_runs/out_data\")\n",
    "# path_i = os.path.join(\n",
    "#     root_data_dir,\n",
    "#     \"AB3/gp_ucb_True\",\n",
    "#     \"AL_geheneva.pickle\")\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     AL = pickle.load(fle)\n",
    "\n",
    "# # #############################################################################\n",
    "\n",
    "# # AL.duplicate_system_history_analysis\n",
    "\n",
    "# AL_i = AL.al_gen_dict[49]\n",
    "\n",
    "# # AL_i.DuplicateFinder.i_all_similar\n",
    "# DuplicateFinder = AL_i.DuplicateFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DuplicateFinder.i_j_similar(\"64cg6j9any\", \"b46enqnq8e\")\n",
    "\n",
    "# DuplicateFinder.df_dij.index\n",
    "\n",
    "\n",
    "\n",
    "# '64cg6j9any', 'b46enqnq8e', '9yz2mt8hbh'\n",
    "# simil_dict = DuplicateFinder.i_all_similar(\n",
    "#     index_i, filter_ids=filter_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "def get_duplicates_list(stoich_i, file_list_dict=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    file_list = file_list_dict[stoich_i]\n",
    "\n",
    "    duplicates_lists = []\n",
    "    for file in file_list:\n",
    "\n",
    "        # Read Data\n",
    "        root_data_dir = os.path.join(\n",
    "            os.environ[\"PROJ_irox\"],\n",
    "            \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow\",\n",
    "            \"00_abx_al_runs/out_data\")\n",
    "        path_i = os.path.join(\n",
    "            root_data_dir,\n",
    "            stoich_i,\n",
    "            file)\n",
    "\n",
    "            # \"AB3/gp_ucb_True\",\n",
    "            # \"AL_geheneva.pickle\")\n",
    "\n",
    "        print(path_i)\n",
    "\n",
    "        with open(path_i, \"rb\") as fle:\n",
    "            AL = pickle.load(fle)\n",
    "\n",
    "\n",
    "        last_gen = list(AL.al_gen_dict.keys())[-1]\n",
    "        AL_i = AL.al_gen_dict[last_gen]\n",
    "\n",
    "        model = AL_i.model\n",
    "        model.sort_values(\"y_real\")\n",
    "\n",
    "        duplicates_i = model[model.duplicate == True].index.tolist()\n",
    "        # print(len(duplicates_i))\n",
    "\n",
    "        duplicates_lists.append(duplicates_i)\n",
    "\n",
    "    # #########################################################################\n",
    "    # Checking that all duplicates lists are the same #########################\n",
    "    duplicates_are_the_same_list = []\n",
    "    for duplicates_i in duplicates_lists:\n",
    "        for duplicates_j in duplicates_lists:\n",
    "            duplicates_are_the_same = duplicates_j == duplicates_i\n",
    "            duplicates_are_the_same_list.append(duplicates_are_the_same)\n",
    "    duplicates_are_the_same_final = all(duplicates_are_the_same_list)\n",
    "    assert duplicates_are_the_same_final, \"IJDSFIISD\"\n",
    "\n",
    "\n",
    "    return(duplicates_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_ab2 = get_duplicates_list(\"AB2\", file_list_dict=file_list_dict)\n",
    "duplicates_ab3 = get_duplicates_list(\"AB3\", file_list_dict=file_list_dict)\n",
    "\n",
    "duplicates_dict = dict(\n",
    "    AB2=duplicates_ab2,\n",
    "    AB3=duplicates_ab3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ######################################################\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"duplicates.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(duplicates_dict, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing old and new duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_2\"],\n",
    "    \"FIGS_IrOx_Active_Learning_OER/01_figures/00_main_publ_figs/03_E_vs_V_coord/scripts\",\n",
    "    \"old.duplicates.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    duplicates_dict_old = pickle.load(fle)\n",
    "# #############################################################################\n",
    "\n",
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_2\"],\n",
    "    \"FIGS_IrOx_Active_Learning_OER/01_figures/00_main_publ_figs/03_E_vs_V_coord/scripts\",\n",
    "    \"new.duplicates.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    duplicates_dict_new = pickle.load(fle)\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_dict_new[\"AB2\"] == duplicates_dict_old[\"AB2\"]\n",
    "\n",
    "print(len(duplicates_dict_new[\"AB2\"]))\n",
    "print(len(duplicates_dict_old[\"AB2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in duplicates_dict_old[\"AB2\"]:\n",
    "#     if id not in duplicates_dict_new[\"AB2\"]:\n",
    "#         print(id)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# AL_geheneva.pickle  AL_pifehohu.pickle  AL_vobifoko.pickle     \n",
    "# AL_nisoponi.pickle  AL_suturomo.pickle  TEST_AL_gehinowi.pickle\n",
    "\n",
    "# # pwd/mnt/f/Dropbox/01_norskov/00_git_repos/\n",
    "# # PROJ_IrOx_Active_Learning_OER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # #############################################################################\n",
    "# root_data_dir = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow\",\n",
    "#     \"00_abx_al_runs/out_data\")\n",
    "\n",
    "# # path_i = os.path.join(\n",
    "# #     root_data_dir,\n",
    "# #     \"AB3/gp_ucb_True\",\n",
    "# #     \"AL_geheneva.pickle\")\n",
    "\n",
    "# path_i = os.path.join(\n",
    "#     root_data_dir,\n",
    "#     \"AB2/gp_ucb_True\",\n",
    "#     \"AL_bapihato.pickle\")\n",
    "\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     AL = pickle.load(fle)\n",
    "# # #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# duplicates_are_the_same_list = []\n",
    "# for duplicates_i in duplicates_lists:\n",
    "#     for duplicates_j in duplicates_lists:\n",
    "#         duplicates_are_the_same = duplicates_j == duplicates_i\n",
    "#         duplicates_are_the_same_list.append(duplicates_are_the_same)\n",
    "# duplicates_are_the_same_final = all(duplicates_are_the_same_list)\n",
    "# assert duplicates_are_the_same_final, \"IJDSFIISD\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
