{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gpflow\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# #############################################################################\n",
    "from catlearn.regression.gaussian_process import GaussianProcess\n",
    "from catlearn.preprocess.clean_data import (\n",
    "    clean_infinite,\n",
    "    clean_variance,\n",
    "    clean_skewness)\n",
    "from catlearn.preprocess.scaling import standardize\n",
    "\n",
    "# #############################################################################\n",
    "from active_learning.al_bulkopt import ALBulkOpt\n",
    "from active_learning.active_learning import (\n",
    "    RegressionModel,\n",
    "    FingerPrints,\n",
    "    CandidateSpace,\n",
    "    )\n",
    "from active_learning.al_analysis import ALAnalysis, ALAnimation\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich_i = \"AB3\"\n",
    "verbose = True\n",
    "name_i = \"TEMP\"\n",
    "save_dir_extra=None\n",
    "acquisition_method=None\n",
    "duplicate_analysis=None\n",
    "seed=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_data_for_al\n",
    "\n",
    "out_dict = get_data_for_al(\n",
    "    stoich=stoich_i, verbose=False,\n",
    "    drop_too_many_atoms=True,\n",
    "#     drop_too_many_atoms=False,\n",
    "    )\n",
    "\n",
    "df_bulk_dft = out_dict[\"df_bulk_dft\"]\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] == \"raul\"]\n",
    "\n",
    "# df_bulk_dft = df_bulk_dft[[\"atoms\", \"energy_pa\"]]\n",
    "df_bulk_dft = df_bulk_dft[[\"atoms\", \"dH\"]]\n",
    "df_bulk_dft.columns.values[1] = \"y_real\"\n",
    "\n",
    "df_features_pre = out_dict[\"df_features_pre\"]\n",
    "df_features_post = out_dict[\"df_features_post\"]\n",
    "\n",
    "df_ids = out_dict[\"df_ids\"]\n",
    "\n",
    "\n",
    "df_static_irox = out_dict[\"df_static_irox\"]\n",
    "df_dij = out_dict[\"df_dij\"]\n",
    "\n",
    "# -\n",
    "\n",
    "# # Filter to candidates w/ DFT energy\n",
    "\n",
    "# + {\"jupyter\": {\"source_hidden\": true}}\n",
    "ids_w_dft = df_bulk_dft.index\n",
    "\n",
    "# TEMP | Reduce size of candidate space\n",
    "# np.random.seed(8)\n",
    "# ids_w_dft = np.sort(np.random.choice(np.sort(ids_w_dft), size=200))\n",
    "ids_w_dft = list(set(ids_w_dft))\n",
    "# print(\"ids_w_dft:\", ids_w_dft)\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.loc[ids_w_dft]\n",
    "\n",
    "df_features_pre = df_features_pre.loc[ids_w_dft]\n",
    "df_features_post = df_features_post.loc[ids_w_dft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.loc[\"8p8evt9pcg\"]\n",
    "\n",
    "df_bulk_dft.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield(l[i:i + n])\n",
    "\n",
    "models_list = []\n",
    "for i_cnt, i in enumerate(chunks(ids_w_dft, 40)):\n",
    "    \n",
    "    leave_out_ids = i\n",
    "    \n",
    "\n",
    "    # df_post_i = df_features_post.drop(labels=leave_out_ids)\n",
    "    # df_features_post\n",
    "    # leave_out_ids\n",
    "\n",
    "    FP = FingerPrints(\n",
    "        df_features_pre,\n",
    "        df_features_post=df_features_post,\n",
    "        pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "        pca_comp=10,\n",
    "        pca_perc=None,\n",
    "        verbose=verbose,\n",
    "        )\n",
    "\n",
    "    CS = CandidateSpace(\n",
    "        Y_data=df_bulk_dft,\n",
    "        Y_key=\"y_real\",\n",
    "        FingerPrints=FP,\n",
    "        )\n",
    "\n",
    "    df_train = CS.FingerPrints.df_post.drop(labels=leave_out_ids)\n",
    "    df_test = CS.FingerPrints.df_post.loc[leave_out_ids]\n",
    "    # df_test = CS.FingerPrints.df_pre\n",
    "\n",
    "    FP.clean_data(df_train, df_test)\n",
    "    FP.pca_analysis()\n",
    "\n",
    "    df_train = FP.df_train\n",
    "    df_test = FP.df_test\n",
    "\n",
    "\n",
    "\n",
    "    gp_settings = {\n",
    "        \"noise\": 0.02542,\n",
    "        \"sigma_l\": 1.0049,\n",
    "        \"sigma_f\": 5.19,\n",
    "        \"alpha\": 0.018,\n",
    "        }\n",
    "\n",
    "    RM = RegressionModel(\n",
    "        df_train=df_train,\n",
    "        # train_targets=CS.Y_data_series,\n",
    "        train_targets=CS.Y_data_series.drop(labels=leave_out_ids),\n",
    "        df_test=df_test,\n",
    "        opt_hyperparameters=True,\n",
    "        gp_settings_dict=gp_settings,\n",
    "        uncertainty_type='regular',\n",
    "        verbose=verbose,\n",
    "        )\n",
    "\n",
    "    RM.run_regression()\n",
    "\n",
    "    model = pd.concat([\n",
    "        CS.Y_data_series,\n",
    "        RM.model,\n",
    "        ], axis=1, sort=False)\n",
    "\n",
    "    model_i = model[~model[\"y\"].isna()]\n",
    "\n",
    "\n",
    "    models_list.append(model_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_master = pd.concat(models_list, axis=0, sort=False)\n",
    "\n",
    "model_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Formation Energy"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i.sort_values(\"y_real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "# from proj_data_irox import calc_dH\n",
    "\n",
    "\n",
    "# model_i = model_master\n",
    "\n",
    "\n",
    "\n",
    "# def method(row_i, stoich_i=None):\n",
    "#     row_i = model_i.iloc[0]\n",
    "\n",
    "#     y_real = row_i[\"y_real\"]\n",
    "#     y = row_i[\"y\"]\n",
    "#     err = row_i[\"err\"]\n",
    "\n",
    "\n",
    "\n",
    "#     y_real_new = calc_dH(\n",
    "#         y_real,\n",
    "#         stoich=stoich_i)\n",
    "\n",
    "#     y_new = calc_dH(\n",
    "#         y,\n",
    "#         stoich=stoich_i)\n",
    "\n",
    "#     row_i[\"y_real\"] = y_real_new\n",
    "#     row_i[\"y\"] = y_new\n",
    "\n",
    "#     return(row_i)\n",
    "\n",
    "# # arg1 = \"TEMP_0\"\n",
    "# df_i = model_i\n",
    "# # df_i[\"column_name\"] = \n",
    "\n",
    "# df_i.apply(\n",
    "#     method,\n",
    "#     axis=1,\n",
    "#     # args=(arg1, ),\n",
    "#     stoich_i=stoich_i,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import os\n",
    "\n",
    "x_array = model_master.y\n",
    "y_array = model_master.y_real\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "\n",
    "    marker=dict(\n",
    "        symbol=\"circle\",\n",
    "        color='blue',\n",
    "\n",
    "        # color=z,\n",
    "        # colorscale='Viridis',\n",
    "        # colorbar=dict(thickness=20),\n",
    "\n",
    "        size=4,\n",
    "        line=dict(\n",
    "            color='black',\n",
    "            width=1,\n",
    "            )\n",
    "        ),\n",
    "\n",
    "    # line=dict(\n",
    "    #     color=\"firebrick\",\n",
    "    #     width=2,\n",
    "    #     dash=\"dot\",\n",
    "    #     ),\n",
    "\n",
    "    # error_y={\n",
    "    #     \"type\": 'data',\n",
    "    #     \"array\": [0.4, 0.9, 0.3, 1.1],\n",
    "    #     \"visible\": True,\n",
    "    #     },\n",
    "\n",
    "    )\n",
    "trace_xy = go.Scatter(x=[-3, 5], y=[-3, 5], mode=\"lines\")\n",
    "data = [trace, trace_xy]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(range=[-3.5, 6]),\n",
    "    yaxis=dict(range=[-3.5, 6])\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master[\"err_pred_real\"] = np.abs(model_master[\"y_real\"] - model_master[\"y\"])\n",
    "model_master[\"err_pred_real\"].mean()\n",
    "\n",
    "\n",
    "# model_master\n",
    "# -1.658857 - -1.784430\t\n",
    "# 0.12557299999999993"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.20012585885222797"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ######################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, stoich_i + \"_\" + \"post_dft_cv_data.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(model_master, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "# sys.path.insert(0, os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"python_classes\"))\n",
    "# from ccf_similarity.ccf import CCF\n",
    "\n",
    "# d_thresh = 0.02\n",
    "# CCF = CCF(\n",
    "#     df_dij=df_dij,\n",
    "#     d_thresh=d_thresh)\n",
    "\n",
    "# # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "# RM = RegressionModel(\n",
    "#     opt_hyperparameters=True,\n",
    "#     gp_settings_dict=gp_settings,\n",
    "#     verbose=verbose,\n",
    "#     )\n",
    "\n",
    "# FP = FingerPrints(\n",
    "#     df_features_pre,\n",
    "#     df_features_post=df_features_post,\n",
    "#     pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "#     pca_comp=10,\n",
    "#     pca_perc=None,\n",
    "#     verbose=verbose,\n",
    "#     )\n",
    "\n",
    "# CS = CandidateSpace(\n",
    "#     Y_data=df_bulk_dft,\n",
    "#     Y_key=\"y_real\",\n",
    "#     FingerPrints=FP,\n",
    "#     )\n",
    "\n",
    "# # +\n",
    "# AL = ALBulkOpt(\n",
    "#     CandidateSpace=CS,\n",
    "#     RegressionModel=RM,\n",
    "#     DuplicateFinder=CCF,  # Optional\n",
    "#     duplicate_analysis=duplicate_analysis,\n",
    "#     # num_seed_calcs=11,\n",
    "#     num_seed_calcs=5,\n",
    "#     acquisition_bin=5,\n",
    "#     # stop_mode=\"num_generations\",\n",
    "#     stop_mode=None,\n",
    "#     stop_num_generations=3,\n",
    "#     name=name_i,\n",
    "#     save_dir_extra=save_dir_extra,\n",
    "#     verbose=verbose,\n",
    "#     # acquisition_method=\"gp_ucb\",\n",
    "#     acquisition_method=acquisition_method,\n",
    "#     seed=seed,\n",
    "#     )\n",
    "\n",
    "# run_al = False\n",
    "# if run_al:\n",
    "#     AL.run_AL()\n",
    "#     AL.duplicate_system_history_analysis()\n",
    "#     AL.__save_state__()\n",
    "\n",
    "# #__|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
