{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "# #############################################################################\n",
    "from methods import run_al_i\n",
    "from misc_modules.misc_methods import GetFriendlyID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inputs import (\n",
    "    stoich_i,\n",
    "    verbose,\n",
    "    gp_settings,\n",
    "    runs_list,\n",
    "    acquisition_methods,\n",
    "    duplicate_analysis,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "variables_dict = dict(\n",
    "    stoich_i=stoich_i,\n",
    "    # acquisition_method=acquisition_method,\n",
    "    # duplicate_analysis=duplicate_analysis,\n",
    "    verbose=verbose,\n",
    "    gp_settings=gp_settings,\n",
    "    )\n",
    "\n",
    "# def run_al_meth(\n",
    "#     input_dict,\n",
    "#     stoich_i=None,\n",
    "#     # acquisition_method=None,\n",
    "#     verbose=None,\n",
    "#     gp_settings=None,\n",
    "#     name_i=None,\n",
    "#     save_dir=None,\n",
    "#     # duplicate_analysis=None,\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     i = input_dict['i']\n",
    "#     acquisition_method = input_dict['acquisition_method']\n",
    "#     duplicate_analysis = input_dict['duplicate_analysis' ]\n",
    "#     seed = input_dict['seed']\n",
    "\n",
    "#     # #########################################################################\n",
    "#     i_str = str(i).zfill(2)\n",
    "\n",
    "    \n",
    "#     print(80 * \"#\")\n",
    "#     print(i_str, 77 * \"#\")\n",
    "\n",
    "#     # name_i = \"TEST_AL_7_\" + GetFriendlyID()\n",
    "#     name_i = \"TEST_AL_6_\" + GetFriendlyID()\n",
    "\n",
    "#     print(\"****\")\n",
    "#     print(\"name_i: \", name_i)\n",
    "#     print(\"****\")\n",
    "\n",
    "#     save_dir = stoich_i + \"/\" + acquisition_method + \"_\" + str(duplicate_analysis)\n",
    "#     run_al_i(\n",
    "#         stoich_i=stoich_i,\n",
    "#         verbose=verbose,\n",
    "#         gp_settings=gp_settings,\n",
    "#         name_i=name_i,\n",
    "#         save_dir_extra=save_dir,\n",
    "#         acquisition_method=acquisition_method,\n",
    "#         duplicate_analysis=duplicate_analysis,\n",
    "#         seed=seed,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "input_list = []\n",
    "for i in itertools.product(acquisition_methods, duplicate_analysis, runs_list):\n",
    "    data_dict_i = dict(\n",
    "        acquisition_method=i[0],\n",
    "        duplicate_analysis=i[1],\n",
    "        i=i[2],\n",
    "        seed=np.random.randint(0, 1000)\n",
    "        )\n",
    "    input_list.append(data_dict_i)\n",
    "    \n",
    "# input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = input_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_al_meth(\n",
    "\n",
    "# input_dict,\n",
    "# stoich_i=None\n",
    "# # acquisition_method=None,\n",
    "# verbose=None\n",
    "# gp_settings=None\n",
    "# name_i=None\n",
    "# save_dir=None\n",
    "\n",
    "# duplicate_analysis=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_al_meth(\n",
    "# input_dict,\n",
    "# stoich_i=None,\n",
    "# # acquisition_method=None,\n",
    "# verbose=None,\n",
    "# gp_settings=None,\n",
    "# name_i=None,\n",
    "# save_dir=None,\n",
    "# # duplicate_analysis=None,\n",
    "# ):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "i = input_dict['i']\n",
    "acquisition_method = input_dict['acquisition_method']\n",
    "duplicate_analysis = input_dict['duplicate_analysis' ]\n",
    "seed = input_dict['seed']\n",
    "\n",
    "# #########################################################################\n",
    "i_str = str(i).zfill(2)\n",
    "\n",
    "\n",
    "print(80 * \"#\")\n",
    "print(i_str, 77 * \"#\")\n",
    "\n",
    "# name_i = \"TEST_AL_7_\" + GetFriendlyID()\n",
    "name_i = \"TEST_AL_6_\" + GetFriendlyID()\n",
    "\n",
    "print(\"****\")\n",
    "print(\"name_i: \", name_i)\n",
    "print(\"****\")\n",
    "\n",
    "save_dir = stoich_i + \"/\" + acquisition_method + \"_\" + str(duplicate_analysis)\n",
    "\n",
    "# run_al_i(\n",
    "#     stoich_i=stoich_i,\n",
    "#     verbose=verbose,\n",
    "#     gp_settings=gp_settings,\n",
    "#     name_i=name_i,\n",
    "#     save_dir_extra=save_dir,\n",
    "#     acquisition_method=acquisition_method,\n",
    "#     duplicate_analysis=duplicate_analysis,\n",
    "#     seed=seed,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_al_i(\n",
    "#     stoich_i=None,\n",
    "#     verbose=None,\n",
    "#     gp_settings=None,\n",
    "#     name_i=None,\n",
    "#     save_dir_extra=None,\n",
    "#     acquisition_method=None,\n",
    "#     duplicate_analysis=None,\n",
    "#     seed=None,\n",
    "#     ):\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# | - run_al_i\n",
    "# # Read Data\n",
    "\n",
    "# + {\"jupyter\": {\"source_hidden\": true}}\n",
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\"))\n",
    "from ml_methods import get_data_for_al\n",
    "\n",
    "out_dict = get_data_for_al(\n",
    "    stoich=stoich_i, verbose=False,\n",
    "    drop_too_many_atoms=True,\n",
    "#     drop_too_many_atoms=False,\n",
    "    )\n",
    "\n",
    "df_bulk_dft = out_dict[\"df_bulk_dft\"]\n",
    "print(\"df_bulk_dft.shape:\", df_bulk_dft.shape)\n",
    "\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] == \"raul\"]\n",
    "print(\"df_bulk_dft.shape:\", df_bulk_dft.shape)\n",
    "\n",
    "# df_bulk_dft = df_bulk_dft[[\"atoms\", \"energy_pa\"]]\n",
    "df_bulk_dft = df_bulk_dft[[\"atoms\", \"dH\"]]\n",
    "df_bulk_dft.columns.values[1] = \"y_real\"\n",
    "\n",
    "df_features_pre = out_dict[\"df_features_pre\"]\n",
    "df_features_post = out_dict[\"df_features_post\"]\n",
    "\n",
    "df_ids = out_dict[\"df_ids\"]\n",
    "\n",
    "\n",
    "df_static_irox = out_dict[\"df_static_irox\"]\n",
    "df_dij = out_dict[\"df_dij\"]\n",
    "# -\n",
    "\n",
    "# # Filter to candidates w/ DFT energy\n",
    "\n",
    "# + {\"jupyter\": {\"source_hidden\": true}}\n",
    "ids_w_dft = df_bulk_dft.index\n",
    "\n",
    "# TEMP | Reduce size of candidate space\n",
    "# np.random.seed(8)\n",
    "# ids_w_dft = np.sort(np.random.choice(np.sort(ids_w_dft), size=200))\n",
    "ids_w_dft = list(set(ids_w_dft))\n",
    "# print(\"ids_w_dft:\", ids_w_dft)\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.loc[ids_w_dft]\n",
    "print(\"df_bulk_dft.shape:\", df_bulk_dft.shape)\n",
    "\n",
    "df_features_pre = df_features_pre.loc[ids_w_dft]\n",
    "df_features_post = df_features_post.loc[ids_w_dft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + {\"active\": \"\"}\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# -\n",
    "\n",
    "# # CCF Class\n",
    "\n",
    "#  # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "#  sys.path.insert(0, os.path.join(\n",
    "#      os.environ[\"PROJ_irox\"],\n",
    "#      \"python_classes\"))\n",
    "#  from ccf_similarity.ccf import CCF\n",
    "#\n",
    "#  d_thresh = 0.02\n",
    "#  CCF = CCF(\n",
    "#      df_dij=df_dij,\n",
    "#      d_thresh=d_thresh)\n",
    "#\n",
    "#  # + {\"jupyter\": {\"source_hidden\": true}}\n",
    "#  RM = RegressionModel(\n",
    "#      opt_hyperparameters=True,\n",
    "#      gp_settings_dict=gp_settings,\n",
    "#      verbose=verbose,\n",
    "#      )\n",
    "#\n",
    "#  FP = FingerPrints(\n",
    "#      df_features_pre,\n",
    "#      df_features_post=df_features_post,\n",
    "#      pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "#      pca_comp=10,\n",
    "#      pca_perc=None,\n",
    "#      verbose=verbose,\n",
    "#      )\n",
    "#\n",
    "#  CS = CandidateSpace(\n",
    "#      Y_data=df_bulk_dft,\n",
    "#      Y_key=\"y_real\",\n",
    "#      FingerPrints=FP,\n",
    "#      )\n",
    "#\n",
    "#  # +\n",
    "#  AL = ALBulkOpt(\n",
    "#      CandidateSpace=CS,\n",
    "#      RegressionModel=RM,\n",
    "#      DuplicateFinder=CCF,  # Optional\n",
    "#      duplicate_analysis=duplicate_analysis,\n",
    "#      # num_seed_calcs=11,\n",
    "#      num_seed_calcs=5,\n",
    "#      acquisition_bin=5,\n",
    "#      # stop_mode=\"num_generations\",\n",
    "#      stop_mode=None,\n",
    "#      stop_num_generations=3,\n",
    "#      name=name_i,\n",
    "#      save_dir_extra=save_dir_extra,\n",
    "#      verbose=verbose,\n",
    "#      # acquisition_method=\"gp_ucb\",\n",
    "#      acquisition_method=acquisition_method,\n",
    "#      seed=seed,\n",
    "#      )\n",
    "#\n",
    "#  run_al = True\n",
    "#  if run_al:\n",
    "#      AL.run_AL()\n",
    "#      AL.duplicate_system_history_analysis()\n",
    "#      AL.__save_state__()\n",
    "\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# for i in range(num_runs):\n",
    "#     run_al_meth(i, **variables_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# traces_all = Pool().map(\n",
    "#     partial(\n",
    "#         run_al_meth,  # METHOD\n",
    "#         **variables_dict,  # KWARGS\n",
    "#         ),\n",
    "#     input_list,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"Notebook runtime (s):\", time.time() - t0)\n",
    "print(\"Notebook runtime (min):\", (time.time() - t0) / 60)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# stoich_i = \"AB3\"\n",
    "# verbose = False\n",
    "\n",
    "# gp_settings = {\n",
    "#     \"noise\": 0.02542,\n",
    "#     \"sigma_l\": 1.0049,\n",
    "#     \"sigma_f\": 5.19,\n",
    "#     \"alpha\": 0.018,\n",
    "#     }\n",
    "\n",
    "# # duplicate_analysis = False\n",
    "# # acquisition_method = \"gp_ucb\"\n",
    "# # acquisition_method = \"random\"\n",
    "\n",
    "# # #############################################################################\n",
    "# runs_list = list(range(5))\n",
    "# acquisition_methods = [\"gp_ucb\", \"random\"]\n",
    "# duplicate_analysis = [True, False]\n",
    "\n",
    "# # TEST SETTINGS # #############################################################\n",
    "# runs_list = list(range(1))\n",
    "# acquisition_methods = [\"gp_ucb\"]\n",
    "# duplicate_analysis = [True]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
