{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following system is failing with voro fingerprinting:\n",
    "z39g648rnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from protosearch.ml_modelling.fingerprint import (\n",
    "    FingerPrint,\n",
    "    VoronoiFingerprint\n",
    "    )\n",
    "\n",
    "# #############################################################################\n",
    "pd.set_option('display.max_rows', None)\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "# from proj_data_irox import (\n",
    "# #     df_features_path,\n",
    "# #     df_features_cleaned_path,\n",
    "# #     df_features_cleaned_pca_path,\n",
    "#     )\n",
    "\n",
    "from proj_data_irox import (\n",
    "    bulk_dft_data_path,\n",
    "    unique_ids_path,\n",
    "    prototypes_data_path,\n",
    "    static_irox_structures_path,\n",
    "    static_irox_structures_kirsten_path,\n",
    "#     oqmd_irox_data_path,\n",
    "    \n",
    "    df_features_pre_opt_path,\n",
    "    df_features_pre_opt_kirsten_path,\n",
    "    df_features_post_opt_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)\n",
    "\n",
    "with open(static_irox_structures_path, \"rb\") as fle:\n",
    "    df_struct = pickle.load(fle)\n",
    "\n",
    "\n",
    "with open(static_irox_structures_kirsten_path, \"rb\") as fle:\n",
    "    df_struct_kirsten = pickle.load(fle)\n",
    "\n",
    "df_ids = pd.read_csv(unique_ids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove rows with missing atoms objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing missing data\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"atoms\"].notnull()]\n",
    "df_struct = df_struct[df_struct[\"atoms\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_old', 'atoms', 'stoich', 'path', 'source', 'static_id'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_struct.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing pre-opt Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_struct = FingerPrint(**{\n",
    "#     \"feature_methods\": [\"voronoi\"],\n",
    "#     \"input_data\": df_struct,\n",
    "# #     \"input_data\": df_combined,\n",
    "#     \"input_index\": [\"atoms\"]})\n",
    "\n",
    "# FP_struct.generate_fingerprints()\n",
    "# df_features_pre_opt = FP_struct.fingerprints\n",
    "\n",
    "# # #############################################################################\n",
    "# with open(df_features_pre_opt_path, \"wb\") as fle:\n",
    "#     pickle.dump(df_features_pre_opt, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_struct = FingerPrint(**{\n",
    "#     \"feature_methods\": [\"voronoi\"],\n",
    "#     \"input_data\": df_struct_kirsten,\n",
    "# #     \"input_data\": df_combined,\n",
    "#     \"input_index\": [\"atoms\"]})\n",
    "\n",
    "# FP_struct.generate_fingerprints()\n",
    "# df_features_pre_opt = FP_struct.fingerprints\n",
    "\n",
    "# # #############################################################################\n",
    "# with open(df_features_pre_opt_kirsten_path, \"wb\") as fle:\n",
    "#     pickle.dump(df_features_pre_opt, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_features_pre_opt_path, \"rb\") as fle:\n",
    "    df_features_pre_opt = pickle.load(fle)\n",
    "\n",
    "with open(df_features_pre_opt_kirsten_path, \"rb\") as fle:\n",
    "    df_features_pre_opt_kirsten = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_features_post_opt_path, \"rb\") as fle:\n",
    "    df_features_post_opt = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_features_post_opt.shape: (836, 273)\n"
     ]
    }
   ],
   "source": [
    "df_features_post_opt[\"data\", \"INDEX_OLD\"] = df_features_post_opt.index\n",
    "df_features_post_opt[\"data\", \"INDEX_NEW\"] = df_features_post_opt[\"data\", \"INDEX_OLD\"] + \"_\" + df_features_post_opt[\"data\"][\"source\"]\n",
    "\n",
    "df_features_post_opt = df_features_post_opt.set_index(df_features_post_opt[\"data\", \"INDEX_NEW\"])\n",
    "df_features_post_opt = df_features_post_opt.drop(labels=[[\"data\", \"INDEX_NEW\"]], axis=1)\n",
    "\n",
    "print(\"df_features_post_opt.shape:\", df_features_post_opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft[\"INDEX_NEW\"] = df_bulk_dft.index + \"_\" + df_bulk_dft[\"source\"]\n",
    "df_bulk_dft[\"INDEX_OLD\"] = df_bulk_dft.index\n",
    "df_bulk_dft = df_bulk_dft.set_index(\"INDEX_NEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_process = [i for i in df_bulk_dft.index if i not in df_features_post_opt.index]\n",
    "df_bulk_dft_not_processed = df_bulk_dft.loc[ids_to_process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_bulk_dft_not_processed.shape: (3, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_bulk_dft_not_processed.shape:\", df_bulk_dft_not_processed.shape)\n",
    "# df_bulk_dft_not_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bulk_dft[df_bulk_dft[\"stoich\"] == \"AB2\"].sort_values(\"energy_pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Voronoi fingerprint of 3 structures\n"
     ]
    }
   ],
   "source": [
    "FP_struct = FingerPrint(**{\n",
    "    \"feature_methods\": [\"voronoi\"],\n",
    "    \"input_data\": df_bulk_dft_not_processed,\n",
    "    \"input_index\": [\"atoms\"]})\n",
    "\n",
    "FP_struct.generate_fingerprints()\n",
    "df_features_post_opt_new = FP_struct.fingerprints\n",
    "\n",
    "# Add the 'source' column to features dataframe since there are duplicate ids\n",
    "# due to the fact that Chris and I ran the same structures\n",
    "df_features_post_opt_new[\"data\", \"source\"] = df_bulk_dft_not_processed[\"source\"]\n",
    "df_features_post_opt_new[\"data\", \"INDEX_OLD\"] = df_bulk_dft_not_processed[\"INDEX_OLD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `df_features_post_opt` have any NaN values in it:  \n",
      " --> False\n"
     ]
    }
   ],
   "source": [
    "df_features_post_opt_comb = pd.concat([\n",
    "    df_features_post_opt,\n",
    "    df_features_post_opt_new])\n",
    "\n",
    "nan_mask = df_features_post_opt_comb[\"voronoi\"].isnull().any(axis=\"columns\")\n",
    "\n",
    "df_features_post_opt_comb_cpy = copy.deepcopy(df_features_post_opt_comb)\n",
    "\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.loc[~nan_mask]\n",
    "df_nan_in_voro = df_features_post_opt_comb_cpy.loc[nan_mask]\n",
    "\n",
    "print(\n",
    "    \"Does `df_features_post_opt` have any NaN values in it: \",\n",
    "    \"\\n -->\",\n",
    "    df_features_post_opt_comb[\"voronoi\"].isnull().any(axis=\"columns\").any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_indices = df_features_post_opt_comb[\"data\", \"INDEX_OLD\"]\n",
    "\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.set_index(old_indices)\n",
    "# df_features_post_opt_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_renamed = df_features_post_opt_comb.index.rename(\"id_unique\")\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.set_index(index_renamed)\n",
    "df_features_post_opt_comb = df_features_post_opt_comb.drop((\"data\", \"INDEX_OLD\"), axis=1)\n",
    "\n",
    "index_renamed = df_bulk_dft.index.rename(\"id_unique\")\n",
    "df_bulk_dft = df_bulk_dft.set_index(index_renamed)\n",
    "df_bulk_dft = df_bulk_dft.drop((\"INDEX_OLD\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "with open(df_features_post_opt_path, \"wb\") as fle:\n",
    "    pickle.dump(df_features_post_opt_comb, fle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul_desktop/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_features_pre_opt.shape: (967, 271)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul_desktop/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(967, 170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul_desktop/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "ab2_ids = df_ids[df_ids[\"stoich\"] == \"AB2\"][\"unique_ids\"]\n",
    "\n",
    "tmp = df_features_pre_opt.loc[ab2_ids].describe().loc[\"std\"].tolist()\n",
    "print(\"df_features_pre_opt.shape:\", df_features_pre_opt.shape)\n",
    "\n",
    "len([i for i in tmp if i < 0.00000000001])\n",
    "\n",
    "print(df_features_pre_opt.loc[:, df_features_pre_opt.loc[ab2_ids].describe().loc[\"std\"] < 0.00001].shape)\n",
    "tmpa = df_features_pre_opt.loc[:, df_features_pre_opt.loc[ab2_ids].describe().loc[\"std\"] < 0.00001]\n",
    "\n",
    "tmpa = [i[1] for i in tmpa.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul_desktop/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_features_pre_opt.shape: (967, 271)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul_desktop/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(967, 170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul_desktop/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "ab2_ids = df_ids[df_ids[\"stoich\"] == \"AB3\"][\"unique_ids\"]\n",
    "\n",
    "tmp = df_features_pre_opt.loc[ab2_ids].describe().loc[\"std\"].tolist()\n",
    "print(\"df_features_pre_opt.shape:\", df_features_pre_opt.shape)\n",
    "\n",
    "len([i for i in tmp if i < 0.00000000001])\n",
    "\n",
    "print(df_features_pre_opt.loc[:, df_features_pre_opt.loc[ab2_ids].describe().loc[\"std\"] < 0.00001].shape)\n",
    "tmpb = df_features_pre_opt.loc[:, df_features_pre_opt.loc[ab2_ids].describe().loc[\"std\"] < 0.00001]\n",
    "\n",
    "tmpb = [i[1] for i in tmpb.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmpa\n",
    "\n",
    "[i for i in tmpa if i not in tmpb]\n",
    "\n",
    "len(set(tmpa) & set(tmpb))\n",
    "\n",
    "len(tmpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "271 - 170\n",
    "\n",
    "# 125 - 102"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "125 columns of no info for IrO2 and IrO3\n",
    "102/101 columns of no info for IrO2/3"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
