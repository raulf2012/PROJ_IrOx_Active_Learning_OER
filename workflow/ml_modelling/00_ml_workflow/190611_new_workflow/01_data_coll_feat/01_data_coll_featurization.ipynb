{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following system is failing with voro fingerprinting:\n",
    "z39g648rnl\n",
    "\n",
    "df_train\n",
    "df_struct\n",
    "df_proto\n",
    "df_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from protosearch.ml_modelling.fingerprint import (\n",
    "    FingerPrint,\n",
    "    VoronoiFingerprint\n",
    "    )\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/parsing_chris_dft_data\",\n",
    "    \"df_dft_calcs.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_dft_calcs = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\",\n",
    "    \"df_oqmd_data.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_oqmd_data = pickle.load(fle)\n",
    "\n",
    "df_train = pd.concat([df_oqmd_data, df_dft_calcs], sort=False)\n",
    "# Removing missing data\n",
    "df_train = df_train[df_train[\"atoms\"].notnull()]\n",
    "\n",
    "# #############################################################################\n",
    "# #############################################################################\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"chris_prototypes_structures\",\n",
    "    \"data_structures.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_struct = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"chris_prototypes_structures\",\n",
    "    \"data_prototypes.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_proto = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"data/ml_irox_data\",\n",
    "    \"unique_ids.csv\")\n",
    "df_ids = pd.read_csv(path_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Static, OQMD, and DFT Calculated Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = []\n",
    "for i_cnt, row_i in df_ids.iterrows():\n",
    "    id_i = row_i[\"unique_ids\"] \n",
    "\n",
    "    if id_i in df_struct.index.values: id_in_structs = True\n",
    "    else: id_in_structs = False\n",
    "    # #############################################################################\n",
    "    if id_i in df_train.index.values: id_in_trains = True\n",
    "    else: id_in_trains = False\n",
    "\n",
    "    # #############################################################################\n",
    "    # #############################################################################\n",
    "\n",
    "    # The DFT optimized z39g648rnl structure isn't yielding NaN's from\n",
    "    # the Voronoi tesselation\n",
    "    # For now, ignore the DFT structure and use the regular one\n",
    "    # COMBAK | TEMP\n",
    "    if id_i == \"z39g648rnl\":\n",
    "        id_in_trains = False\n",
    "        id_in_structs = True\n",
    "\n",
    "\n",
    "    if id_in_trains: row_j = df_train.loc[id_i]\n",
    "    elif id_in_structs: row_j = df_struct.loc[id_i]\n",
    "    else: row_j = None; print(\"NOOOOOOOOOOOOOOOOO NOT GOOD | No \")\n",
    "\n",
    "    master_data.append(row_j)\n",
    "\n",
    "df_combined = pd.DataFrame(master_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Voronoi fingerprint of 967 structures\n",
      "No null values in the voro fingerprint\n"
     ]
    }
   ],
   "source": [
    "FP = FingerPrint(**{\n",
    "    \"feature_methods\": [\"voronoi\"],\n",
    "    \"input_data\": df_combined,\n",
    "#     \"input_data\": df_combined,\n",
    "    \"input_index\": [\"atoms\"]})\n",
    "\n",
    "FP.generate_fingerprints()\n",
    "FP.clean_features()\n",
    "# FP.join_input_to_fingerprints()\n",
    "\n",
    "df_features = FP.fingerprints[\"voronoi\"]\n",
    "\n",
    "if all(list(df_features.isnull().sum().to_dict().values())) == 0:\n",
    "    print(\"No null values in the voro fingerprint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "\n",
    "pca_features = pca.fit_transform(df_features)\n",
    "\n",
    "df_features_pca = pd.DataFrame(\n",
    "    pca_features,\n",
    "    columns=['PCA%i' % i for i in range(pca.n_components)],\n",
    "    index=df_features.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save features to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/\"\n",
    "    \"190611_new_workflow/data/\"\n",
    "    \"df_features_pca.pickle\")\n",
    "\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_features_pca, fle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
