{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following system is failing with voro fingerprinting:\n",
    "z39g648rnl\n",
    "\n",
    "df_train\n",
    "df_struct\n",
    "df_proto\n",
    "df_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from protosearch.ml_modelling.fingerprint import (\n",
    "    FingerPrint,\n",
    "    VoronoiFingerprint\n",
    "    )\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/parsing_chris_dft_data\",\n",
    "    \"df_dft_calcs.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_dft_calcs = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\",\n",
    "    \"df_oqmd_data.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_oqmd_data = pickle.load(fle)\n",
    "\n",
    "df_train = pd.concat([df_oqmd_data, df_dft_calcs], sort=False)\n",
    "# Removing missing data\n",
    "df_train = df_train[df_train[\"atoms\"].notnull()]\n",
    "\n",
    "# #############################################################################\n",
    "# #############################################################################\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"chris_prototypes_structures\",\n",
    "    \"data_structures.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_struct = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"chris_prototypes_structures\",\n",
    "    \"data_prototypes.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_proto = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"data/ml_irox_data\",\n",
    "    \"unique_ids.csv\")\n",
    "df_ids = pd.read_csv(path_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Static, OQMD, and DFT Calculated Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = []\n",
    "for i_cnt, row_i in df_ids.iterrows():\n",
    "    id_i = row_i[\"unique_ids\"] \n",
    "\n",
    "    if id_i in df_struct.index.values: id_in_structs = True\n",
    "    else: id_in_structs = False\n",
    "    # #############################################################################\n",
    "    if id_i in df_train.index.values: id_in_trains = True\n",
    "    else: id_in_trains = False\n",
    "\n",
    "    # #############################################################################\n",
    "    # #############################################################################\n",
    "\n",
    "    # The DFT optimized z39g648rnl structure isn't yielding NaN's from\n",
    "    # the Voronoi tesselation\n",
    "    # For now, ignore the DFT structure and use the regular one\n",
    "    # COMBAK | TEMP\n",
    "    if id_i == \"z39g648rnl\":\n",
    "        id_in_trains = False\n",
    "        id_in_structs = True\n",
    "\n",
    "\n",
    "    if id_in_trains: row_j = df_train.loc[id_i]\n",
    "    elif id_in_structs: row_j = df_struct.loc[id_i]\n",
    "    else: row_j = None; print(\"NOOOOOOOOOOOOOOOOO NOT GOOD | No \")\n",
    "\n",
    "    master_data.append(row_j)\n",
    "\n",
    "df_combined = pd.DataFrame(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.iloc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Voronoi fingerprint of 1 structures\n",
      "ijisjdfis8yufyty78923ty987wyf\n",
      "[]\n",
      "ijisjdfis8yufyty78923ty987wyf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-043ce5d9818d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_fingerprints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mFP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# FP.join_input_to_fingerprints()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/f/Dropbox/01_norskov/00_git_repos/protosearch/protosearch/ml_modelling/fingerprint.py\u001b[0m in \u001b[0;36mclean_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         df_features_cleaned = pd.DataFrame(\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0;31m# columns=output[\"labels\"],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 424\u001b[0;31m                                    copy=copy)\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must pass 2-d input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "FP = FingerPrint(**{\n",
    "    \"feature_methods\": [\"voronoi\"],\n",
    "    \"input_data\": df_combined,\n",
    "#     \"input_data\": df_combined,\n",
    "    \"input_index\": [\"atoms\"]})\n",
    "\n",
    "FP.generate_fingerprints()\n",
    "FP.clean_features()\n",
    "# FP.join_input_to_fingerprints()\n",
    "\n",
    "df_features = FP.fingerprints[\"voronoi\"]\n",
    "\n",
    "if all(list(df_features.isnull().sum().to_dict().values())) == 0:\n",
    "    print(\"No null values in the voro fingerprint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "\n",
    "pca_features = pca.fit_transform(df_features)\n",
    "\n",
    "df_features_pca = pd.DataFrame(\n",
    "    pca_features,\n",
    "    columns=['PCA%i' % i for i in range(pca.n_components)],\n",
    "    index=df_features.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save features to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/\"\n",
    "    \"190611_new_workflow/data/\"\n",
    "    \"df_features_pca.pickle\")\n",
    "\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_features_pca, fle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
