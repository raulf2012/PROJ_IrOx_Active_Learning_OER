{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Similarity Matrix for IrOx Systems Post-DFT\n",
    "---\n",
    "\n",
    "Systems that have the same d but different energies\n",
    "\n",
    "list_0 = [\n",
    " '8481z1n1na',\n",
    " 'zr9ic2zaz5',\n",
    " '8h9snabqca',\n",
    " '7f8pm5mhnu',\n",
    " 'cgx3mkzhmd',\n",
    " 'vwxfn3blxi',\n",
    " '9obw8dbrvy',\n",
    " 'bpvynr7p9w',\n",
    " '8gnovr727t',\n",
    "\n",
    "\n",
    " '9pb4c1927h',\n",
    " '8i63m2b5ve',\n",
    "\n",
    "\n",
    " 'vlxp9abd6h',\n",
    " 'z2nh817ene',\n",
    " 'xu6ivyvfvf',\n",
    " ]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# #############################################################################\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# #############################################################################\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (\n",
    "    static_irox_structures_path,\n",
    "    bulk_dft_data_path,\n",
    "    df_dij_path)\n",
    "\n",
    "from methods import plot_dij_matrix_heatmap\n",
    "from plotting.my_plotly import my_plotly_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_thresh = 0.075\n",
    "\n",
    "# d_thresh = 0.01\n",
    "d_thresh = 0.02\n",
    "# d_thresh = 0.03\n",
    "# d_thresh = 0.04\n",
    "# d_thresh = 0.05\n",
    "# d_thresh = 0.06\n",
    "# d_thresh = 0.07\n",
    "# d_thresh = 0.08\n",
    "# d_thresh = 0.09\n",
    "# d_thresh = 0.10\n",
    "# d_thresh = 0.20\n",
    "# d_thresh = 0.30\n",
    "# d_thresh = 0.40\n",
    "# d_thresh = 0.70\n",
    "\n",
    "\n",
    "e_thresh = 0.01\n",
    "\n",
    "create_plot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dij_path_tmp = df_dij_path[0:-18] + \"df_d_ij_all_temp.pickle\"\n",
    "with open(df_dij_path, \"rb\") as fle:\n",
    "# with open(df_dij_path_tmp, \"rb\") as fle:\n",
    "    df_dij_dft = pickle.load(fle)\n",
    "    print(\"df_dij_dft.shape:\", df_dij_dft.shape)\n",
    "\n",
    "with open(static_irox_structures_path, \"rb\") as fle:\n",
    "    df_static_irox = pickle.load(fle)\n",
    "\n",
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\",\n",
    "    \"ccf_similarity_analysis/out_data\",\n",
    "    \"all_ids_to_elim_1.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    ids_to_drop_prev = pickle.load(fle)\n",
    "\n",
    "ids_to_drop_prev = ids_to_drop_prev[\"AB2\"] + ids_to_drop_prev[\"AB3\"]\n",
    "\n",
    "# sys.path.insert(0, \"../04_final_ml_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dij_dft.loc[\"8p8evt9pcg\", \"9lmkmh8s8r\"]\n",
    "\n",
    "\n",
    "df_dij_dft.loc[\n",
    "\n",
    "    \"64cg6j9any\",\n",
    "    \"b46enqnq8e\",\n",
    "    \"9yz2mt8hbh\",\n",
    "\n",
    "#     \"6avov5cy64\"\n",
    "    \n",
    "#     \"clc2b1mavs\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Static Structure from D_ij"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_ids = df_static_irox[\"static_id\"].tolist()\n",
    "static_ids_in_dij = [i for i in static_ids if i in df_dij_dft.index]\n",
    "\n",
    "df_dij_dft = df_dij_dft.drop(labels=static_ids_in_dij, axis=0)\n",
    "df_dij_dft = df_dij_dft.drop(labels=static_ids_in_dij, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering data to needed systems"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft = df_bulk_dft[\n",
    "    (df_bulk_dft[\"source\"] != \"chris\") &\n",
    "    (df_bulk_dft[\"source\"] != \"oqmd\") &\n",
    "    [True for i in range(len(df_bulk_dft))]\n",
    "    ]\n",
    "\n",
    "print(\"df_bulk_dft.shape:\", \"\\n\", df_bulk_dft.shape)\n",
    "print(\"df_bulk_dft.index.unique().shape:\", \"\\n\",\n",
    "    df_bulk_dft.index.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorder index by Stoicheomtry first and then by energy"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab2_indices = df_bulk_dft[df_bulk_dft[\"stoich\"] == \"AB2\"].sort_values(\n",
    "    \"energy_pa\").index.tolist()\n",
    "ab3_indices = df_bulk_dft[df_bulk_dft[\"stoich\"] == \"AB3\"].sort_values(\n",
    "    \"energy_pa\").index.tolist()\n",
    "\n",
    "ab2_indices_not_in_dij = [i for i in ab2_indices if i not in df_dij_dft.index]\n",
    "\n",
    "new_ind_order = ab2_indices + ab3_indices\n",
    "new_index_order_filtered = [i for i in new_ind_order if i in df_dij_dft.index]\n",
    "\n",
    "df_dij_dft = df_dij_dft.reindex(new_index_order_filtered)\n",
    "df_dij_dft = df_dij_dft[new_index_order_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(ab2_indices):\", len(ab2_indices))\n",
    "print(\"len(ab3_indices):\", len(ab3_indices))\n",
    "print(\"\")\n",
    "print(\"df_dij_dft.shape:\", df_dij_dft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorder index to put OER bulk systems first"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oer_sys_ids = ['IrO3_rutile-like', 'IrO3', 'IrO3_battery', 'IrO2']\n",
    "\n",
    "non_oer_ids = df_dij_dft.index.drop(oer_sys_ids)\n",
    "new_index_order = oer_sys_ids + non_oer_ids.tolist()\n",
    "\n",
    "df_dij_dft = df_dij_dft.reindex(new_index_order)\n",
    "df_dij_dft = df_dij_dft[new_index_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop ids that were identified to be redundant"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dij_dft = df_dij_dft.drop(labels=ids_to_drop_prev, axis=0)\n",
    "# df_dij_dft = df_dij_dft.drop(labels=ids_to_drop_prev, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create D_ij Matrix Plot"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_plot:\n",
    "    data = plot_dij_matrix_heatmap(\n",
    "        df_dij_dft,\n",
    "        d_thresh,\n",
    "        e_thresh)\n",
    "\n",
    "    layout = go.Layout(width=1100, height=1100)\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    fig = my_plotly_plot(\n",
    "        figure=fig,\n",
    "        plot_name='irox_dij_heatmap',\n",
    "        # write_pdf_svg=True,\n",
    "        write_html=True,\n",
    "        write_png=True,\n",
    "        write_pdf=False,\n",
    "        write_svg=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing systems that are duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dij_ab2 = df_dij_dft.loc[ab2_indices, ab2_indices]\n",
    "df_dij_ab3 = df_dij_dft.loc[ab3_indices, ab3_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_elim(df_dij):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    index_to_eliminate = []\n",
    "    for i_cnt, (name_i, row_i) in enumerate(df_dij.iterrows()):\n",
    "        cols_below_thresh = row_i[row_i < d_thresh]\n",
    "        if cols_below_thresh.shape[0] > 1:\n",
    "            df_i = df_bulk_dft.loc[cols_below_thresh.index]\n",
    "            index_to_eliminate += df_i.iloc[1:].index.tolist()\n",
    "\n",
    "    index_to_eliminate = list(set(index_to_eliminate))\n",
    "\n",
    "    return(index_to_eliminate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_elim_ab2 = ids_to_elim(df_dij_ab2)\n",
    "ids_to_elim_ab3 = ids_to_elim(df_dij_ab3)\n",
    "\n",
    "all_ids_to_elim = {\n",
    "    \"AB2\": ids_to_elim_ab2,\n",
    "    \"AB3\": ids_to_elim_ab3,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"len(ids_to_elim_ab2):\", len(ids_to_elim_ab2))\n",
    "print(\"len(ids_to_elim_ab3):\", len(ids_to_elim_ab3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(ids_to_elim_ab2): 43\n",
    "len(ids_to_elim_ab3): 69\n",
    "\n",
    "len(ids_to_elim_ab2): 92\n",
    "len(ids_to_elim_ab3): 103"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving ids of systmes that are duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ######################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "\n",
    "# TODO | Don't create this one anymore\n",
    "with open(os.path.join(directory, \"all_ids_to_elim_1.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(all_ids_to_elim, fle)\n",
    "\n",
    "with open(os.path.join(directory, \"all_ids_to_elim.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(all_ids_to_elim, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dij_ab3.loc[\"8p8evt9pcg\", \"zimixdvdxd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST | TEST | TEST"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dij_dft.loc[\"7h7yns937p\"]\n",
    "df_dij_dft.shape\n",
    "\n",
    "\"7h7yns937p\" in df_dij_dft.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "ids_to_elim_ab3 = all_ids_to_elim[\"AB3\"]\n",
    "\n",
    "print(len(ab3_indices))\n",
    "\n",
    "unique_ids_ab3 = [i for i in ab3_indices if i not in ids_to_elim_ab3]\n",
    "\n",
    "data_dict_list = []\n",
    "for id_i in unique_ids_ab3:\n",
    "    if id_i in df_dij_dft.index:\n",
    "        num_duplicates = len(df_dij_dft.loc[id_i][df_dij_dft.loc[id_i] < d_thresh]) - 1,\n",
    "        dict_i = {\n",
    "            \"id_unique\": id_i,\n",
    "            \"num_duplicates\": num_duplicates[0],\n",
    "            }\n",
    "        data_dict_list.append(dict_i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "df_tmp = pd.DataFrame(data_dict_list)\n",
    "\n",
    "df_tmp.sort_values(\"num_duplicates\", ascending=False)\n",
    "# data_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "# df_dij_dft = df_dij_dft.loc[all_ids_to_elim, all_ids_to_elim]\n",
    "\n",
    "\n",
    "ids_dict_master = {}\n",
    "for i_cnt, (name_i, row_i) in enumerate(df_dij_dft.iterrows()):\n",
    "    # tmp = row_i[row_i < d_thresh]\n",
    "    tmp = row_i[row_i < d_thresh].drop(name_i)\n",
    "    df_i = df_bulk_dft.loc[tmp.index]\n",
    "\n",
    "    # ids_dict_list_i = {i_cnt: df_i.index.sort_values().tolist()}\n",
    "    # ids_dict_lists.append(ids_dict_list_i)\n",
    "    if len(df_i) > 0:\n",
    "        equiv_ids_list = df_i.index.sort_values().tolist()\n",
    "        id_joined_str = \"_\".join(equiv_ids_list)\n",
    "\n",
    "        # ids_dict_master[i_cnt] = df_i.index.sort_values().tolist()\n",
    "        ids_dict_master[name_i] = {\n",
    "            \"id_joined_str\": id_joined_str,\n",
    "            \"equiv_ids_list\": equiv_ids_list,\n",
    "            }\n",
    "\n",
    "# #############################################################################\n",
    "# df_i.index.sort_values().tolist()\n",
    "\n",
    "df_test = pd.DataFrame(ids_dict_master,\n",
    "#     index=ids_dict_master.keys()\n",
    "#     index=[\"id_str_joined\"],\n",
    "    ).T\n",
    "\n",
    "\n",
    "# df_test[\"id_str_joined\"].unique().shape\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dij_dft.loc[\"8p8evt9pcg\", \"zimixdvdxd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_dict_master\n",
    "# tmp_list = []\n",
    "# for key_i, val_i in ids_dict_master.items():\n",
    "#     for key_j, val_j in ids_dict_master.items():\n",
    "\n",
    "#         if key_i == key_j:\n",
    "#             continue\n",
    "\n",
    "#         print(key_i, key_j)\n",
    "\n",
    "#         if val_j == val_i:\n",
    "#         else:\n",
    "#             tmp_list.append(key_i)\n",
    "\n",
    "# ids_dict_master\n",
    "\n",
    "# if val_j == val_i:\n",
    "\n",
    "# len(all_ids_to_elim)\n",
    "\n",
    "\n",
    "# print(len([i for i in all_ids_to_elim if i in ab2_indices]))\n",
    "# print(len([i for i in all_ids_to_elim if i in ab3_indices]))\n",
    "\n",
    "# # np.fill_diagonal(df_dij_dft.values, np.nan)\n",
    "# # e_thresh = 0.01\n",
    "# use_energy_simil = False\n",
    "\n",
    "# trouble_ids_list = []\n",
    "\n",
    "# unique_id_list = []\n",
    "# all_ids_to_elim = []\n",
    "# for i_cnt, (name_i, row_i) in enumerate(df_dij_dft.iterrows()):\n",
    "#     tmp = row_i[row_i < d_thresh]\n",
    "\n",
    "#     # if len(tmp) > 1:\n",
    "#     #     break\n",
    "\n",
    "#     if tmp.shape[0] == 1:\n",
    "#         mess = \"No other structures close to this one\"\n",
    "#         # print(mess)\n",
    "#         unique_id_list.append(tmp.index[0])\n",
    "#     else:\n",
    "#         df_i = df_bulk_dft.loc[tmp.index]\n",
    "\n",
    "#         # if \"8k7expx2bp\" in df_i.index.tolist():\n",
    "#         # if \"6s648e8s6p\" in df_i.index.tolist():\n",
    "#         # if \"b5cgvsb16w\" in df_i.index.tolist():\n",
    "#         #     display(df_i)\n",
    "\n",
    "#         e_range = abs(df_i[\"energy_pa\"].min() - df_i[\"energy_pa\"].max())\n",
    "#         e_thresh_u = df_i.loc[name_i][\"energy_pa\"] + e_thresh\n",
    "#         e_thresh_l = df_i.loc[name_i][\"energy_pa\"] - e_thresh\n",
    "\n",
    "#         # Using enery similarity criteria\n",
    "#         if use_energy_simil:\n",
    "#             df_j = df_i[\n",
    "#                 (df_i[\"energy_pa\"] < e_thresh_u) &\n",
    "#                 (df_i[\"energy_pa\"] > e_thresh_l)]\n",
    "#             index_to_keep_i = df_j.sort_values(\"energy_pa\").iloc[0].name\n",
    "#             index_to_eliminate = df_j.iloc[1:].index.tolist()\n",
    "#         else:\n",
    "#             index_to_keep_i = df_i.sort_values(\"energy_pa\").iloc[0].name\n",
    "#             index_to_eliminate = df_i.iloc[1:].index.tolist()\n",
    "\n",
    "\n",
    "#         all_ids_to_elim += index_to_eliminate\n",
    "\n",
    "#         if e_range > e_thresh:\n",
    "#             # display(df_i)\n",
    "#             df_i_tmp = df_i\n",
    "\n",
    "#             ids_tmp = df_i_tmp.index.tolist()\n",
    "#             trouble_ids_list += ids_tmp\n",
    "\n",
    "#             # print(\"Energies span greater range than 'e_thresh'\")\n",
    "#             # print(e_range)\n",
    "#             # print(\"\")\n",
    "\n",
    "# all_ids_to_elim = list(set(all_ids_to_elim))\n",
    "\n",
    "# trouble_ids_list = list(set(trouble_ids_list))\n",
    "\n",
    "# #############################################################################\n",
    "# Drop ab2 stoicheomtry\n",
    "\n",
    "# df_dij_dft = df_dij_dft.drop(labels=ab2_indices, axis=0)\n",
    "# df_dij_dft = df_dij_dft.drop(labels=ab2_indices, axis=1)\n",
    "\n",
    "# dft_indices = ab2_indices + ab3_indices\n",
    "# non_dft_indices = [i for i in df_dij_dft.index if i not in dft_indices]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:research-new]",
   "language": "python",
   "name": "conda-env-research-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
