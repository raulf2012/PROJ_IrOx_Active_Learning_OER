{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ase.visualize import view\n",
    "\n",
    "# Plotly\n",
    "import chart_studio.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# from StructurePrototypeAnalysisPackage.ccf import (\n",
    "from spap.ccf import (\n",
    "    struc2ccf,\n",
    "    cal_ccf_d,\n",
    "    cal_inter_atomic_d,\n",
    "    d2ccf,\n",
    "    weight_f,\n",
    "    pearson_cc,\n",
    "    gaussian_f,\n",
    "    element_tag,\n",
    "    cell_range,\n",
    "    count_atoms_dict,\n",
    "    )\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (\n",
    "    static_irox_structures_path,\n",
    "    bulk_dft_data_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "r_cut_off = 10.\n",
    "\n",
    "r_vector = np.arange(1, 10, 0.02)\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# with open(\"out_data/df_ccf_test.pickle\", \"rb\") as fle:\n",
    "with open(\"out_data/df_ccf.pickle\", \"rb\") as fle:\n",
    "    df_ccf = pickle.load(fle)\n",
    "# df_ccf = df_ccf[0:40]\n",
    "\n",
    "# #############################################################################\n",
    "try:\n",
    "    with open(\"out_data/df_d_ij_all.pickle\", \"rb\") as fle:\n",
    "    # with open(\"out_data/df_d_ij_all_temp.pickle\", \"rb\") as fle:\n",
    "        df_d_comp_prev = pickle.load(fle)\n",
    "except:\n",
    "    df_d_comp_prev = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# df_d_comp_prev.loc[\"6fcdbh9fz2\"]\n",
    "\n",
    "df_tmp = df_d_comp_prev\n",
    "\"6fcdbh9fz2\" in df_tmp.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"df_ccf.shape:\", df_ccf.shape)\n",
    "\n",
    "print(\"df_d_comp_prev.shape:\", df_d_comp_prev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Process data (Create D_ij matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_ccf\n",
    "\n",
    "result = np.zeros((len(df), len(df)))\n",
    "for i_cnt, (row_name_i, row_i) in enumerate(df.iterrows()):\n",
    "    print(str(i_cnt).zfill(4), 75 * \"#\")\n",
    "    \n",
    "    row_in_prev_data = False\n",
    "\n",
    "    for j_cnt, (row_name_j, row_j) in enumerate(df.iterrows()):\n",
    "        if i_cnt == j_cnt:\n",
    "            continue\n",
    "\n",
    "\n",
    "        index_in_cols = row_name_j in df_d_comp_prev.columns\n",
    "        index_in_rows = row_name_i in df_d_comp_prev.index\n",
    "        if index_in_cols and index_in_rows:\n",
    "            if True:\n",
    "#             try:\n",
    "                d_ij = df_d_comp_prev.loc[row_name_i, row_name_j]\n",
    "\n",
    "                if verbose:\n",
    "                    row_in_prev_data = True\n",
    "#                     print(\"Parsed d_ij from previous data\")\n",
    "        else:\n",
    "            if verbose:\n",
    "                tmp = 42\n",
    "                # print(\"Computing d_ij from scratch\")\n",
    "\n",
    "            d_ij = cal_ccf_d(\n",
    "                row_i[\"ccf\"],\n",
    "                row_j[\"ccf\"])\n",
    "            # d_ij = 42.\n",
    "\n",
    "        result[i_cnt][j_cnt] = d_ij\n",
    "\n",
    "    if row_in_prev_data:\n",
    "        print(\"This row is the previous data (GOOD)\")\n",
    "df_d_comp = pd.DataFrame(\n",
    "    result,\n",
    "    index=df.index,\n",
    "    columns=df.index)\n",
    "\n",
    "\n",
    "# Pickling data ######################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "\n",
    "\n",
    "# with open(os.path.join(directory, \"df_d_ij_all_temp.pickle\"), \"wb\") as fle:\n",
    "with open(os.path.join(directory, \"df_d_ij_all.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_d_comp, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# path_i = os.path.join(\"out_data\", \"df_d_ij_all_temp.pickle\")\n",
    "path_i = os.path.join(\"out_data\", \"df_d_ij_all.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_d_comp = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "time_elapsed = time.time() - t0\n",
    "print(\n",
    "    \"Notebook took \",\n",
    "    round(time_elapsed / 60, 4),\n",
    "    \"minutes to finish\")"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
