{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# #############################################################################\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (\n",
    "    bulk_dft_data_path, unique_ids_path,\n",
    "    static_irox_structures_path)\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ignore_ids_iro2): 94\n",
      "len(ignore_ids_iro3): 0\n"
     ]
    }
   ],
   "source": [
    "from out_data.inputs_nersc_iro2 import ignore_ids as ignore_ids_nersc_iro2\n",
    "# from out_data.inputs_nersc_iro3 import ignore_ids as ignore_ids_nersc_iro3\n",
    "ignore_ids_nersc_iro3 = []\n",
    "\n",
    "from out_data.inputs_sher_iro2 import ignore_ids as ignore_ids_sher_iro2\n",
    "from out_data.inputs_sher_iro3 import ignore_ids as ignore_ids_sher_iro3\n",
    "\n",
    "from out_data.inputs_slac_iro2 import ignore_ids as ignore_ids_slac_iro2\n",
    "# from out_data.inputs_slac_iro3 import ignore_ids as ignore_ids_slac_iro3\n",
    "ignore_ids_slac_iro3 = []\n",
    "\n",
    "ignore_ids_iro2 = ignore_ids_nersc_iro2 + ignore_ids_sher_iro2 + ignore_ids_slac_iro2\n",
    "ignore_ids_iro3 = ignore_ids_nersc_iro3 + ignore_ids_sher_iro3 + ignore_ids_slac_iro3\n",
    "\n",
    "print(\"len(ignore_ids_iro2):\", len(ignore_ids_iro2))\n",
    "print(\"len(ignore_ids_iro3):\", len(ignore_ids_iro3))\n",
    "\n",
    "ignore_ids_dict = {\n",
    "    \"AB2\": ignore_ids_iro2,\n",
    "    \"AB3\": ignore_ids_iro3}\n",
    "\n",
    "\n",
    "# Pickling data ######################################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"ignore_ids.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(ignore_ids_dict, fle)\n",
    "# #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from out_data.ids_to_run_nersc_iro2 import ids_to_run as ids_to_run_nersc_iro2\n",
    "from out_data.ids_to_run_nersc_iro3 import ids_to_run as ids_to_run_nersc_iro3\n",
    "\n",
    "from out_data.ids_to_run_slac_iro2 import ids_to_run as ids_to_run_slac_iro2\n",
    "# from out_data.ids_to_run_slac_iro3 import ids_to_run as ids_to_run_slac_iro3\n",
    "ids_to_run_slac_iro3 = []\n",
    "\n",
    "from out_data.ids_to_run_sher_iro2 import ids_to_run as ids_to_run_sher_iro2\n",
    "from out_data.ids_to_run_sher_iro3 import ids_to_run as ids_to_run_sher_iro3\n",
    "\n",
    "ids_to_run_iro2 = ids_to_run_nersc_iro2 + ids_to_run_sher_iro2 + ids_to_run_slac_iro2\n",
    "ids_to_run_iro3 = ids_to_run_nersc_iro3 + ids_to_run_sher_iro3 + ids_to_run_slac_iro3\n",
    "\n",
    "ids_to_run_iro3 = list(set(ids_to_run_iro3))\n",
    "ids_to_run_iro2 = list(set(ids_to_run_iro2))\n",
    "\n",
    "ids_to_run_sher = ids_to_run_sher_iro2 + ids_to_run_sher_iro3\n",
    "ids_to_run_nersc = ids_to_run_nersc_iro2 + ids_to_run_nersc_iro3\n",
    "ids_to_run_slac = ids_to_run_slac_iro2 + ids_to_run_slac_iro3\n",
    "\n",
    "ids_to_run_sher = list(set(ids_to_run_sher))\n",
    "ids_to_run_nersc = list(set(ids_to_run_nersc))\n",
    "ids_to_run_slac = list(set(ids_to_run_slac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich_i = \"AB2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)\n",
    "    df_bulk_dft = df_bulk_dft[(df_bulk_dft[\"source\"] == \"raul\")]\n",
    "\n",
    "with open(static_irox_structures_path, \"rb\") as fle:\n",
    "    df_static = pickle.load(fle)\n",
    "    df_static = df_static[(df_static[\"source\"] == \"chris\")]\n",
    "\n",
    "df_ids = pd.read_csv(unique_ids_path)\n",
    "\n",
    "with open(\"out_data/df_new_jobs.pickle\", \"rb\") as fle:\n",
    "    df_new_jobs = pickle.load(fle)\n",
    "\n",
    "with open(\"out_data/df_irox_long.pickle\", \"rb\") as fle:\n",
    "    df_irox_long = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids_in_process = df_new_jobs[df_new_jobs[\"stoich\"] == stoich_i][\"id\"]\n",
    "unique_ids_in_process = unique_ids_in_process.unique().tolist()\n",
    "unique_ids_in_process = [i for i in unique_ids_in_process if i.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    atoms = row_i[\"atoms\"]\n",
    "    num_atoms = atoms.get_number_of_atoms()\n",
    "    return(num_atoms)\n",
    "\n",
    "df_static[\"num_atoms\"] = df_static.apply(method, axis=1)\n",
    "df_static = df_static.drop([\"atoms\", \"path\", \"source\",], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    new_column_values_dict = {}\n",
    "\n",
    "    stoich_i = row_i[\"stoich\"]\n",
    "\n",
    "    id_old = row_i[\"id_old\"]\n",
    "    id_old_str = str(id_old).zfill(3)\n",
    "\n",
    "    # #########################################################################\n",
    "    if row_i.name in df_bulk_dft.index:\n",
    "        new_column_values_dict[\"done\"] = True\n",
    "    else:\n",
    "        new_column_values_dict[\"done\"] = False\n",
    "\n",
    "    # #########################################################################\n",
    "    if id_old_str in unique_ids_in_process:\n",
    "        new_column_values_dict[\"being_processed\"] = True\n",
    "    else:\n",
    "        new_column_values_dict[\"being_processed\"] = False\n",
    "\n",
    "    # #########################################################################\n",
    "    if stoich_i == \"AB2\":\n",
    "        ignore_ids_i = ignore_ids_iro2\n",
    "    elif stoich_i == \"AB3\":\n",
    "        ignore_ids_i = ignore_ids_iro3\n",
    "    # id_old = str(row_i[\"id_old\"]).zfill(3)\n",
    "\n",
    "    if id_old_str in ignore_ids_i:\n",
    "        new_column_values_dict[\"ignored\"] = True\n",
    "    else:\n",
    "        new_column_values_dict[\"ignored\"] = False\n",
    "\n",
    "    # #########################################################################\n",
    "    # stoich_i = row_i[\"stoich\"] == \"AB2\"\n",
    "    if stoich_i == \"AB2\":\n",
    "        ids_to_run_i = ids_to_run_iro2\n",
    "    elif stoich_i == \"AB3\":\n",
    "        ids_to_run_i = ids_to_run_iro3\n",
    "\n",
    "    if id_old in ids_to_run_i:\n",
    "        new_column_values_dict[\"ids_to_run\"] = True\n",
    "    else:\n",
    "        new_column_values_dict[\"ids_to_run\"] = False\n",
    "\n",
    "\n",
    "    # #########################################################################\n",
    "    if stoich_i == \"AB2\":\n",
    "        if id_old in ids_to_run_sher_iro2:\n",
    "            new_column_values_dict[\"cluster\"] = \"sherlock\"\n",
    "        elif id_old in ids_to_run_nersc_iro2:\n",
    "            new_column_values_dict[\"cluster\"] = \"nersc\"\n",
    "        elif id_old in ids_to_run_slac_iro2:\n",
    "            new_column_values_dict[\"cluster\"] = \"slac\"\n",
    "        else:\n",
    "            new_column_values_dict[\"cluster\"] = np.nan\n",
    "\n",
    "    elif stoich_i == \"AB3\":\n",
    "        if id_old in ids_to_run_sher_iro3:\n",
    "            new_column_values_dict[\"cluster\"] = \"sherlock\"\n",
    "        elif id_old in ids_to_run_nersc_iro3:\n",
    "            new_column_values_dict[\"cluster\"] = \"nersc\"\n",
    "        elif id_old in ids_to_run_slac_iro3:\n",
    "            new_column_values_dict[\"cluster\"] = \"slac\"\n",
    "        else:\n",
    "            new_column_values_dict[\"cluster\"] = np.nan\n",
    "\n",
    "\n",
    "    # #########################################################################\n",
    "    df_new_jobs_i = df_new_jobs[\n",
    "        (df_new_jobs[\"stoich\"] == stoich_i) & \\\n",
    "        (df_new_jobs[\"id\"] == str(id_old).zfill(3))\n",
    "        ]\n",
    "\n",
    "    if len(df_new_jobs_i) == 1:\n",
    "        row_j = df_new_jobs_i.iloc[0]\n",
    "\n",
    "        action_j = row_j[\"action\"]\n",
    "\n",
    "        bool_0 = action_j == 'Job is busy, will skip'\n",
    "        bool_1 = action_j == 'Time out or failed | Restarting isif 3 calc'\n",
    "        bool_2 = action_j == 'Time out or failed | Restarting isif 7 calc'\n",
    "        bool_3 = action_j == 'Job done | ISIF 3 done | --> isif 2'\n",
    "        \n",
    "        if bool_0 or bool_1 or bool_2 or bool_3:\n",
    "            new_column_values_dict[\"running\"] = True\n",
    "        else:\n",
    "            new_column_values_dict[\"running\"] = False\n",
    "\n",
    "        bool_0 = action_j == \"Error, need manual attention\"\n",
    "        bool_1 = action_j == \"Couldn't figure out what to do\"\n",
    "        if bool_0 or bool_1:\n",
    "            new_column_values_dict[\"error\"] = True\n",
    "\n",
    "    elif len(df_new_jobs_i) == 0:\n",
    "        new_column_values_dict[\"running\"] = np.nan\n",
    "    elif len(df_new_jobs_i) > 1:\n",
    "        # print(df_new_jobs_i)\n",
    "        # display(df_new_jobs_i)\n",
    "        new_column_values_dict[\"running\"] = \"TEMP, more than 1 sys\"\n",
    "\n",
    "    # #########################################################################\n",
    "    for key, value in new_column_values_dict.items():\n",
    "        row_i[key] = value\n",
    "    return(row_i)\n",
    "\n",
    "df_i = df_static\n",
    "df_static = df_i.apply(method, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "697 total AB2  structures in df_static\n",
    "\n",
    "------------------------------------\n",
    "87 systems with num_atoms >= 100\n",
    "\n",
    "132 systems with num_atoms >= 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "697 # Total AB2\n",
    "565 # AB2 | < 75 atoms\n",
    "105 # AB2 | < 75 atoms | Not  done\n",
    "# 32 # AB2 | < 75 atoms | Not  done | Not ignored\n",
    "18 # AB2 | < 75 atoms | Not  done | Not ignored\n",
    "\n",
    "\n",
    "# #####################################\n",
    "14  # Currently running\n",
    "7  # That have identified error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (18,)\n",
      "0\n",
      "5\n",
      "['060' '089' '118' '155' '193' '236' '250' '275' '303' '483' '587' '618'\n",
      " '649']\n"
     ]
    }
   ],
   "source": [
    "df = df_static.drop(\"static_id\", axis=1)\n",
    "df = df[\n",
    "    (df[\"stoich\"] == stoich_i) & \\\n",
    "    (df[\"num_atoms\"] < 75) & \\\n",
    "#     (df[\"num_atoms\"] > 75) & \\\n",
    "#     (df[\"num_atoms\"] < 100) & \\\n",
    "#     (df[\"being_processed\"] == False) & \\\n",
    "    (df[\"done\"] == False) & \\\n",
    "    (df[\"ignored\"] == False) & \\\n",
    "#     (df[\"running\"] == True) & \\\n",
    "    [True for i in range(len(df))]\n",
    "    ]\n",
    "print(\"df.shape:\", df.index.unique().shape)\n",
    "# display(df)\n",
    "\n",
    "\n",
    "\n",
    "from running_ids import sherlock_ids_running, slac_ids_running\n",
    "\n",
    "\n",
    "slac_ids_running\n",
    "\n",
    "print(len([i for i in df[\"id_old\"].tolist() if str(i).zfill(3) in sherlock_ids_running]))\n",
    "print(len([i for i in df[\"id_old\"].tolist() if str(i).zfill(3) in slac_ids_running]))\n",
    "\n",
    "# sherlock_ids_running\n",
    "# df[\"id_old\"].tolist()\n",
    "\n",
    "tmp_list_0 = np.sort(\n",
    "[str(i).zfill(3) for i in df[\"id_old\"].tolist() if str(i).zfill(3) not in sherlock_ids_running + slac_ids_running]\n",
    ")\n",
    "print(tmp_list_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>id</th>\n",
       "      <th>num_completed_isif_3</th>\n",
       "      <th>num_revisions</th>\n",
       "      <th>pre_path</th>\n",
       "      <th>source</th>\n",
       "      <th>stoich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Error, need manual attention</td>\n",
       "      <td>060</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>/nfs/slac/g/suncatfs/flores12/PROJ_irox_ml_oer...</td>\n",
       "      <td>slac</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Error, need manual attention</td>\n",
       "      <td>089</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>/scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Error, need manual attention</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Error, need manual attention</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>/scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Error, need manual attention</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Error, need manual attention</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>/scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ALL DONE! | ISIF 2</td>\n",
       "      <td>587</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>/scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ALL DONE! | ISIF 2</td>\n",
       "      <td>618</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>/nfs/slac/g/suncatfs/flores12/PROJ_irox_ml_oer...</td>\n",
       "      <td>slac</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Couldn't figure out what to do</td>\n",
       "      <td>649</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>/nfs/slac/g/suncatfs/flores12/PROJ_irox_ml_oer...</td>\n",
       "      <td>slac</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             action   id  num_completed_isif_3  num_revisions  \\\n",
       "6      Error, need manual attention  060                     3              8   \n",
       "47     Error, need manual attention  089                     2              5   \n",
       "64     Error, need manual attention  118                     1              4   \n",
       "130    Error, need manual attention  236                     2              8   \n",
       "139    Error, need manual attention  250                     1              4   \n",
       "247    Error, need manual attention  483                     3              6   \n",
       "284              ALL DONE! | ISIF 2  587                     3             21   \n",
       "94               ALL DONE! | ISIF 2  618                     3              9   \n",
       "107  Couldn't figure out what to do  649                     0             16   \n",
       "\n",
       "                                              pre_path    source stoich  \n",
       "6    /nfs/slac/g/suncatfs/flores12/PROJ_irox_ml_oer...      slac    AB2  \n",
       "47   /scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...  sherlock    AB2  \n",
       "64   /scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...  sherlock    AB2  \n",
       "130  /scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...  sherlock    AB2  \n",
       "139  /scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...  sherlock    AB2  \n",
       "247  /scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...  sherlock    AB2  \n",
       "284  /scratch/users/flores12/PROJ_irox_ml_oer/ml_bu...  sherlock    AB2  \n",
       "94   /nfs/slac/g/suncatfs/flores12/PROJ_irox_ml_oer...      slac    AB2  \n",
       "107  /nfs/slac/g/suncatfs/flores12/PROJ_irox_ml_oer...      slac    AB2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>being_processed</th>\n",
       "      <th>cluster</th>\n",
       "      <th>done</th>\n",
       "      <th>error</th>\n",
       "      <th>id_old</th>\n",
       "      <th>ids_to_run</th>\n",
       "      <th>ignored</th>\n",
       "      <th>num_atoms</th>\n",
       "      <th>running</th>\n",
       "      <th>static_id</th>\n",
       "      <th>stoich</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_unique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bgvr62z2ce</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sarebilo_71</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cqbax4mr9q</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veliwepe_45</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8tx2vung6y</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tugekato_56</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6amrb4m49u</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>watifago_85</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9e6evkclch</th>\n",
       "      <td>True</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>587</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "      <td>tabihoki_98</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9pbu9hzwct</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>tuvigeno_32</td>\n",
       "      <td>AB2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            being_processed   cluster   done error  id_old  ids_to_run  \\\n",
       "id_unique                                                                \n",
       "bgvr62z2ce            False       NaN  False   NaN     155       False   \n",
       "cqbax4mr9q            False       NaN  False   NaN     193       False   \n",
       "8tx2vung6y            False       NaN  False   NaN     275       False   \n",
       "6amrb4m49u            False       NaN  False   NaN     303       False   \n",
       "9e6evkclch             True  sherlock  False   NaN     587        True   \n",
       "9pbu9hzwct             True       NaN  False   NaN     618       False   \n",
       "\n",
       "            ignored  num_atoms running    static_id stoich  \n",
       "id_unique                                                   \n",
       "bgvr62z2ce    False         30     NaN  sarebilo_71    AB2  \n",
       "cqbax4mr9q    False          9     NaN  veliwepe_45    AB2  \n",
       "8tx2vung6y    False         24     NaN  tugekato_56    AB2  \n",
       "6amrb4m49u    False         12     NaN  watifago_85    AB2  \n",
       "9e6evkclch    False         72   False  tabihoki_98    AB2  \n",
       "9pbu9hzwct    False         54   False  tuvigeno_32    AB2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_new_jobs[\n",
    "    (df_new_jobs[\"id\"].isin(tmp_list_0)) & \\\n",
    "    (df_new_jobs[\"stoich\"] == \"AB2\")\n",
    "    ].sort_values(\"id\")\n",
    "display(df_tmp); print(\"\")\n",
    "\n",
    "df = df_static\n",
    "df_static[\n",
    "    (df[\"id_old\"].isin(tmp_list_0)) & \\\n",
    "    (df[\"stoich\"] == \"AB2\") & \\\n",
    "    (df[\"error\"] != True)\n",
    "    ].sort_values(\"id_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60,\n",
    "# 89,\n",
    "# 118,\n",
    "155,\n",
    "193,\n",
    "# 236,\n",
    "# 250,\n",
    "275,\n",
    "303,\n",
    "# 483,\n",
    "# 649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ids_master_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c08a32787016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrepeated_ids_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids_master_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mids_master_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrepeated_ids_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ids_master_list' is not defined"
     ]
    }
   ],
   "source": [
    "repeated_ids_list = []\n",
    "for i in ids_master_list:\n",
    "    if ids_master_list.count(i) > 1:\n",
    "        repeated_ids_list.append(i)\n",
    "\n",
    "\n",
    "set(repeated_ids_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research-new]",
   "language": "python",
   "name": "conda-env-research-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
