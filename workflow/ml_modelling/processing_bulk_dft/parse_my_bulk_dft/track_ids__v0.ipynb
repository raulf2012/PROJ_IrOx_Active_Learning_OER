{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# #############################################################################\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (\n",
    "    bulk_dft_data_path, unique_ids_path,\n",
    "    static_irox_structures_path)\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)\n",
    "\n",
    "with open(static_irox_structures_path, \"rb\") as fle:\n",
    "    df_static = pickle.load(fle)\n",
    "    \n",
    "df_ids = pd.read_csv(unique_ids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    atoms = row_i[\"atoms\"]\n",
    "    num_atoms = atoms.get_number_of_atoms()\n",
    "    return(num_atoms)\n",
    "\n",
    "df_static[\"num_atoms\"] = df_static.apply(method, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_i = df_static.iloc[0]\n",
    "\n",
    "atoms = row_i[\"atoms\"]\n",
    "num_atoms = atoms.get_number_of_atoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab3_ids = df_ids[df_ids[\"stoich\"] == \"AB3\"][\"unique_ids\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_static.shape:\", df_static.shape)\n",
    "\n",
    "print(\"df_bulk_dft.shape:\", df_bulk_dft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IrO3 Structures"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_static_ab3 = df_static[\n",
    "    (df_static[\"stoich\"] == \"AB3\") & \\\n",
    "    (df_static[\"source\"] == \"chris\") & \\\n",
    "    [True for i in range(len(df_static))]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft_ab3 = df_bulk_dft[\n",
    "    (df_bulk_dft[\"stoich\"] == \"AB3\") & \\\n",
    "    (df_bulk_dft[\"source\"] == \"raul\") & \\\n",
    "    [True for i in range(len(df_bulk_dft))]\n",
    "    ]\n",
    "\n",
    "# df_bulk_dft_ab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft_ab3.index\n",
    "\n",
    "ab3_ids_not_finished = [i for i in df_static_ab3.index if i not in df_bulk_dft_ab3.index]\n",
    "\n",
    "df_i = df_static_ab3.loc[ab3_ids_not_finished]\n",
    "\n",
    "print(\"Structures with greater than 100 atoms\")\n",
    "df_tmp = df_i[df_i[\"num_atoms\"] >= 100]\n",
    "\n",
    "display(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df_i.drop(df_tmp.index)\n",
    "\n",
    "# df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_DATA\"],\n",
    "    \"04_IrOx_surfaces_OER/ml_bulk_irox_dft/iro3\",\n",
    "    \"df_dict.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_dict = pickle.load(fle)\n",
    "df_iro3_sherlock = df_dict[\"df\"]\n",
    "df_new_jobs_sherlock = df_dict[\"df_new_jobs\"]\n",
    "df_iro3_sherlock[\"cluster\"] = \"sherlock\"\n",
    "\n",
    "# #############################################################################\n",
    "# Parsing Sherlock IrO3 DFT Data\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_DATA\"],\n",
    "    \"04_IrOx_surfaces_OER/ml_bulk_irox_dft/iro3\",\n",
    "    \"df_dict_sher.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_dict = pickle.load(fle)\n",
    "df_iro3_nersc = df_dict[\"df\"]\n",
    "df_new_jobs_nersc = df_dict[\"df_new_jobs\"]\n",
    "df_iro3_nersc[\"cluster\"] = \"nersc\"\n",
    "\n",
    "# #############################################################################\n",
    "df_iro3 = pd.concat([\n",
    "    df_iro3_nersc,\n",
    "    df_iro3_sherlock \n",
    "    ], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_running_on_nersc = [\n",
    "    46,\n",
    "    70,\n",
    "    83,\n",
    "    144,\n",
    "    152,\n",
    "    173,\n",
    "    206,\n",
    "    220,\n",
    "    228,\n",
    "    ]\n",
    "\n",
    "ids_running_on_sher = [\n",
    "    2,\n",
    "    22,\n",
    "    51,\n",
    "    101,\n",
    "    250,\n",
    "    ]\n",
    "\n",
    "ids_running = ids_running_on_nersc + ids_running_on_sher\n",
    "\n",
    "len(ids_running)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "236"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df_i[~df_i[\"id_old\"].isin(ids_running)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_iro3\n",
    "\n",
    "# for id_i in df_i[\"id_old\"].tolist():\n",
    "#     df_tmp = df_iro3[df_iro3[\"id\"] == str(id_i).zfill(3)]\n",
    "\n",
    "#     print(id_i)\n",
    "#     display(df_tmp.sort_values(\"revision\"))\n",
    "#     print(40 * \"-\")\n",
    "    \n",
    "    \n",
    "completed_ids = df_iro3[\n",
    "    (df_iro3[\"completed\"] == True) & \\\n",
    "    (df_iro3[\"isif\"] == 2)\n",
    "    ][\"id\"].tolist()\n",
    "\n",
    "not_done_ids = df_iro3[~df_iro3[\"id\"].isin(completed_ids)][\"id\"].unique().tolist()\n",
    "for ind_i, id_i in enumerate(not_done_ids):\n",
    "    df_tmp = df_iro3[df_iro3[\"id\"] == str(id_i).zfill(3)]\n",
    "\n",
    "    print(ind_i, \" | \", id_i)\n",
    "    display(df_tmp.sort_values(\"revision\"))\n",
    "    print(40 * \"-\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(df_iro3.loc[22].iloc[0][\"completed\"])\n",
    "\n",
    "# df_iro3[\"completed\"].isnull()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research-new]",
   "language": "python",
   "name": "conda-env-research-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
