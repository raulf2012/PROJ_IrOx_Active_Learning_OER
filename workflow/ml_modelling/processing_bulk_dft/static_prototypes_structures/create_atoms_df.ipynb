{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Parse Atoms Objects for IrO2 and IrO3 Unique Prototypes\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ase import io\n",
    "from ase.visualize import view\n",
    "\n",
    "from pymatgen.io.vasp.inputs import Poscar\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Reading Structures"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "root_path = os.path.join(\n",
    "    os.environ[\"PROJ_DATA\"],\n",
    "    \"04_IrOx_surfaces_OER/ml_bulk_static_preopt_structures\")\n",
    "\n",
    "\n",
    "master_list = []\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    if \".ipynb_checkpoints\" in root:\n",
    "        continue\n",
    "\n",
    "    if \"iro2\" in root:\n",
    "        stoich_i = \"AB2\"\n",
    "    elif \"iro3\" in root:\n",
    "        stoich_i = \"AB3\"\n",
    "    else:\n",
    "        stoich_i = None\n",
    "\n",
    "    if \"oqmd\" in root:\n",
    "        source_i = \"oqmd\"\n",
    "    else:\n",
    "        source_i = \"chris\"\n",
    "\n",
    "    for file_i in files:\n",
    "        if \".POSCAR\" in file_i or \".cif\" in file_i:\n",
    "            id_i = file_i.split(\"_\")[0]\n",
    "\n",
    "            path_i = root\n",
    "\n",
    "            atoms_i = io.read(\n",
    "                os.path.join(root, file_i))\n",
    "\n",
    "            sys_i = {\n",
    "                \"id_old\": int(id_i),\n",
    "                \"atoms\": atoms_i,\n",
    "                \"stoich\": stoich_i,\n",
    "                \"path\": path_i,\n",
    "                \"source\": source_i,\n",
    "                }\n",
    "            master_list.append(sys_i)\n",
    "\n",
    "df_struct = pd.DataFrame(master_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Setting Unique ID Tag"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"data/ml_irox_data\",\n",
    "    \"unique_ids.csv\")\n",
    "df_id = pd.read_csv(path_i)\n",
    "\n",
    "\n",
    "id_mapp_iro2 = dict(zip(\n",
    "    df_id[df_id[\"stoich\"] == \"AB2\"][\"id\"],\n",
    "    df_id[df_id[\"stoich\"] == \"AB2\"][\"unique_ids\"]))\n",
    "\n",
    "id_mapp_iro3 = dict(zip(\n",
    "    df_id[df_id[\"stoich\"] == \"AB3\"][\"id\"],\n",
    "    df_id[df_id[\"stoich\"] == \"AB3\"][\"unique_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    id_i = row_i[\"id_old\"]\n",
    "\n",
    "    if row_i[\"stoich\"] == \"AB2\":\n",
    "        unique_id_i = id_mapp_iro2[id_i]\n",
    "    elif row_i[\"stoich\"] == \"AB3\":\n",
    "        unique_id_i = id_mapp_iro3[id_i]\n",
    "    else:\n",
    "        print(\"BADDDDD!!!!! fsdfjisajids\")\n",
    "        unique_id_i = None\n",
    "\n",
    "    return(unique_id_i)\n",
    "\n",
    "df_struct[\"id_unique\"] = df_struct.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    )\n",
    "\n",
    "df_struct.set_index(\"id_unique\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Adding secondary index row that is unique and separate from the regular id_unique"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_static_unique_ids = pd.read_csv(\"static_unique_ids.csv\")\n",
    "id_mapp_static_unique = dict(zip(\n",
    "    df_static_unique_ids[\"unique_ids\"],\n",
    "    df_static_unique_ids[\"static_unique_ids\"]))\n",
    "\n",
    "def method(row_i):\n",
    "    id_i = row_i.name\n",
    "    static_id_i = id_mapp_static_unique[id_i]\n",
    "    return(static_id_i)\n",
    "\n",
    "df_struct[\"static_id\"] = df_struct.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    )\n",
    "\n",
    "# df_struct.set_index(\"id_unique\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Analyzing Structures with Bulk Enumerator"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bulk_enumerator_installed = False\n",
    "try:\n",
    "    import bulk_enumerator as be\n",
    "    is_bulk_enumerator_installed = True\n",
    "except:\n",
    "    print(\"bulk_enumerator is not installed/importable\")\n",
    "    print(\"Contact ankitjain.me.iitk@gmail.com to be added as a guest so that you can install the Enumerator package\")\n",
    "    print(\"https://gitlab.com/ankitjainmeiitk/Enumerator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if is_bulk_enumerator_installed:\n",
    "    t0 = time.time()\n",
    "\n",
    "    data_list = []\n",
    "    for id_i, row_i in df_struct.iterrows():\n",
    "        atoms_i = row_i[\"atoms\"]\n",
    "\n",
    "        structure_i = AseAtomsAdaptor.get_structure(atoms_i)\n",
    "        poscar_str_i = Poscar(structure_i).get_string()\n",
    "\n",
    "        b = be.bulk.BULK()\n",
    "        b.set_structure_from_file(poscar_str_i)\n",
    "\n",
    "        spacegroup_i = b.get_spacegroup()\n",
    "        species_i = b.get_species()\n",
    "        wyckoff_i = b.get_wyckoff()\n",
    "        name_i = b.get_name()\n",
    "        parameter_values_i = b.get_parameter_values()\n",
    "\n",
    "        row_dict_i = {\n",
    "            \"id\": id_i,\n",
    "            \"spacegroup_i\": spacegroup_i,\n",
    "            \"species_i\": species_i,\n",
    "            \"wyckoff_i\": wyckoff_i,\n",
    "            \"name_i\": name_i,\n",
    "            \"parameter_values_i\": parameter_values_i,\n",
    "            }\n",
    "        data_list.append(row_dict_i)\n",
    "\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"time to complete for loop: \")\n",
    "    print(t1 - t0)\n",
    "\n",
    "    df_proto = pd.DataFrame(data_list)\n",
    "    df_proto.set_index(\"id\", inplace=True)\n",
    "\n",
    "    print(\n",
    "        \"Number of entries processed: \",\n",
    "        len(df_proto[\"name_i\"].to_list())\n",
    "        )\n",
    "\n",
    "    print(len(\n",
    "        \"Unique entries (some systems with the same prototype): \", \n",
    "        set(df_proto[\"name_i\"].to_list())\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Save data to pickle"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "# if False:\n",
    "    with open(\"out_data/data_structures.pickle\", \"wb\") as fle:\n",
    "        pickle.dump(df_struct, fle)\n",
    "\n",
    "    if is_bulk_enumerator_installed:\n",
    "        with open(\"out_data/data_prototypes.pickle\", \"wb\") as fle:\n",
    "            pickle.dump(df_proto, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    \"out_data\",\n",
    "    \"data_structures.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_struct = pickle.load(fle)\n",
    "# #############################################################################\n",
    "\n",
    "# #############################################################################\n",
    "if is_bulk_enumerator_installed:\n",
    "    path_i = os.path.join(\n",
    "        \"out_data\",\n",
    "        \"data_prototypes.pickle\")\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_proto = pickle.load(fle)\n",
    "else:\n",
    "    # COMBAK Read from PROJ_DATA instead\n",
    "    df_proto = None\n",
    "\n",
    "    path_i = os.path.join(\n",
    "        os.environ[\"PROJ_DATA\"],\n",
    "        \"04_IrOx_surfaces_OER/PROJECT_COMPUTED_OUT_DATA/PROJ_IrOx_Active_Learning_OER\",\n",
    "        \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures\",\n",
    "        \"out_data/data_prototypes.pickle\")\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_proto = pickle.load(fle)\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox]",
   "language": "python",
   "name": "conda-env-PROJ_irox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
