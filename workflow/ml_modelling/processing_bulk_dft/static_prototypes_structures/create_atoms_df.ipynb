{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Parse Atoms Objects for IrO2 and IrO3 Unique Prototypes\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ase import io\n",
    "from ase.visualize import view\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import bulk_enumerator as be\n",
    "import time\n",
    "\n",
    "from pymatgen.io.vasp.inputs import Poscar\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# #############################################################################\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Reading Structures"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "root_path = os.path.join(\n",
    "    os.environ[\"PROJ_DATA\"],\n",
    "    \"04_IrOx_surfaces_OER/ml_bulk_static_preopt_structures\")\n",
    "\n",
    "\n",
    "master_list = []\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    if \".ipynb_checkpoints\" in root:\n",
    "        continue\n",
    "\n",
    "    if \"iro2\" in root:\n",
    "        stoich_i = \"AB2\"\n",
    "    elif \"iro3\" in root:\n",
    "        stoich_i = \"AB3\"\n",
    "    else:\n",
    "        stoich_i = None\n",
    "\n",
    "    if \"oqmd\" in root:\n",
    "        source_i = \"oqmd\"\n",
    "    else:\n",
    "        source_i = \"chris\"\n",
    "\n",
    "    for file_i in files:\n",
    "        if \".POSCAR\" in file_i or \".cif\" in file_i:\n",
    "            id_i = file_i.split(\"_\")[0]\n",
    "\n",
    "            path_i = root.replace(\"/mnt/c/Users/raulf/Dropbox/01_norskov/00_projects/\", \"\")\n",
    "\n",
    "            atoms_i = io.read(\n",
    "                os.path.join(root, file_i))\n",
    "\n",
    "            sys_i = {\n",
    "                \"id_old\": int(id_i),\n",
    "                \"atoms\": atoms_i,\n",
    "                \"stoich\": stoich_i,\n",
    "                \"path\": path_i,\n",
    "                \"source\": source_i,\n",
    "                }\n",
    "            master_list.append(sys_i)\n",
    "\n",
    "df_struct = pd.DataFrame(master_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Setting Unique ID Tag"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"data/ml_irox_data\",\n",
    "    \"unique_ids.csv\")\n",
    "df_id = pd.read_csv(path_i)\n",
    "\n",
    "\n",
    "id_mapp_iro2 = dict(zip(\n",
    "    df_id[df_id[\"stoich\"] == \"AB2\"][\"id\"],\n",
    "    df_id[df_id[\"stoich\"] == \"AB2\"][\"unique_ids\"]))\n",
    "\n",
    "id_mapp_iro3 = dict(zip(\n",
    "    df_id[df_id[\"stoich\"] == \"AB3\"][\"id\"],\n",
    "    df_id[df_id[\"stoich\"] == \"AB3\"][\"unique_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    id_i = row_i[\"id_old\"]\n",
    "\n",
    "    if row_i[\"stoich\"] == \"AB2\":\n",
    "        unique_id_i = id_mapp_iro2[id_i]\n",
    "    elif row_i[\"stoich\"] == \"AB3\":\n",
    "        unique_id_i = id_mapp_iro3[id_i]\n",
    "    else:\n",
    "        print(\"BADDDDD!!!!! fsdfjisajids\")\n",
    "        unique_id_i = None\n",
    "\n",
    "    return(unique_id_i)\n",
    "\n",
    "df_struct[\"id_unique\"] = df_struct.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    )\n",
    "\n",
    "df_struct.set_index(\"id_unique\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Adding secondary index row that is unique and separate from the regular id_unique"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_static_unique_ids = pd.read_csv(\"static_unique_ids.csv\")\n",
    "id_mapp_static_unique = dict(zip(\n",
    "    df_static_unique_ids[\"unique_ids\"],\n",
    "    df_static_unique_ids[\"static_unique_ids\"]))\n",
    "\n",
    "def method(row_i):\n",
    "    id_i = row_i.name\n",
    "    static_id_i = id_mapp_static_unique[id_i]\n",
    "    return(static_id_i)\n",
    "\n",
    "df_struct[\"static_id\"] = df_struct.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    )\n",
    "\n",
    "# df_struct.set_index(\"id_unique\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Analyzing Structures with Bulk Enumerator"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "\n",
    "# data_list = []\n",
    "# for id_i, row_i in df_struct.iterrows():\n",
    "#     atoms_i = row_i[\"atoms\"]\n",
    "\n",
    "#     structure_i = AseAtomsAdaptor.get_structure(atoms_i)\n",
    "#     poscar_str_i = Poscar(structure_i).get_string()\n",
    "\n",
    "#     b = be.bulk.BULK()\n",
    "#     b.set_structure_from_file(poscar_str_i)\n",
    "\n",
    "#     spacegroup_i = b.get_spacegroup()\n",
    "#     species_i = b.get_species()\n",
    "#     wyckoff_i = b.get_wyckoff()\n",
    "#     name_i = b.get_name()\n",
    "#     parameter_values_i = b.get_parameter_values()\n",
    "\n",
    "#     row_dict_i = {\n",
    "#         \"id\": id_i,\n",
    "#         \"spacegroup_i\": spacegroup_i,\n",
    "#         \"species_i\": species_i,\n",
    "#         \"wyckoff_i\": wyckoff_i,\n",
    "#         \"name_i\": name_i,\n",
    "#         \"parameter_values_i\": parameter_values_i,\n",
    "#         }\n",
    "#     data_list.append(row_dict_i)\n",
    "\n",
    "\n",
    "# t1 = time.time()\n",
    "# print(\"time to complete for loop: \")\n",
    "# print(t1 - t0)\n",
    "\n",
    "# df_proto = pd.DataFrame(data_list)\n",
    "# df_proto.set_index(\"id\", inplace=True)\n",
    "\n",
    "# print(\n",
    "#     \"Number of entries processed: \",\n",
    "#     len(df_proto[\"name_i\"].to_list())\n",
    "#     )\n",
    "\n",
    "# print(len(\n",
    "#     \"Unique entries (some systems with the same prototype): \", \n",
    "#     set(df_proto[\"name_i\"].to_list())\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Save data to pickle"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# with open(\"out_data/data_structures.pickle\", \"wb\") as fle:\n",
    "#     pickle.dump(df_struct, fle)\n",
    "\n",
    "# with open(\"out_data/data_prototypes.pickle\", \"wb\") as fle:\n",
    "#     pickle.dump(df_proto, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    \"out_data\",\n",
    "    \"data_structures.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_struct = pickle.load(fle)\n",
    "# #############################################################################\n",
    "\n",
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    \"out_data\",\n",
    "    \"data_prototypes.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_proto = pickle.load(fle)\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Checking that static structures are structurally unique"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# TEMP\n",
    "\n",
    "# ids_to_drop = [\n",
    "#  '826imfvjm5',\n",
    "#  'x5xfz16h95',\n",
    "#  'nl9gb2csx5',\n",
    "#  '65xlxp7o8i',\n",
    "#  'nu64ni7a6i',\n",
    "#  'z17s6dzu6r',\n",
    "#  '8ymh8qnl6o',\n",
    "#  'x4zsxdmanr',\n",
    "#  '6dzhcimdxs',\n",
    "#  'v1bebhmeny',\n",
    "#  'vjvfzpb48y',\n",
    "#  '6fcdbh9fz2',\n",
    "#  '6svsc4bqxh',\n",
    "#  '7qm56wxj8s',\n",
    "#  'mu6omk6k9l',\n",
    "#  'v4zonyzw7d',\n",
    "#  '8uxs7rmu7j',\n",
    "#  '6qmy8j7fz2',\n",
    "#  'vovgximhm2',\n",
    "#  'vhv39q6e9j',\n",
    "#  '8dce6kz2vf',\n",
    "#  '7s64xl8oca',\n",
    "#  '9s617rcd63',\n",
    "#  'c3mp6jmgzq',\n",
    "#  ]\n",
    "\n",
    "\n",
    "# df_proto = df_proto.drop(ids_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"df_proto.name_i.unique().shape:\", df_proto.name_i.unique().shape)\n",
    "\n",
    "duplicates_list = []\n",
    "for proto_i in df_proto.name_i.unique():\n",
    "    df_i = df_proto[df_proto.name_i == proto_i]\n",
    "\n",
    "    if df_i.shape[0] > 1:\n",
    "        # display(df_i)\n",
    "        \n",
    "        df_tmp = df_i\n",
    "        \n",
    "        dupl_ids = df_tmp.index.tolist()\n",
    "        duplicates_list.append(dupl_ids)\n",
    "\n",
    "with open(\"out_data/duplicates_proto.pickle\", \"wb\") as fle:\n",
    "    pickle.dump(duplicates_list, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# df_proto[df_proto[\"stoich\"] == \"AB3\"]\n",
    "# df_struct[df_struct[\"stoich\"] == \"AB2\"].index.shape\n",
    "# df_struct[df_struct[\"stoich\"] == \"AB2\"].index.unique().shape\n",
    "\n",
    "ab3_indices = df_struct[df_struct[\"stoich\"] == \"AB3\"].index.unique().tolist()\n",
    "ab2_indices = df_struct[df_struct[\"stoich\"] == \"AB2\"].index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"df_proto.loc[ab3_indices].shape:\", df_proto.loc[ab3_indices].shape)\n",
    "print(\"AB3:\", df_proto.loc[ab3_indices].name_i.unique().shape)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"df_proto.loc[ab2_indices].shape:\", df_proto.loc[ab2_indices].shape)\n",
    "print(\"AB2:\", df_proto.loc[ab2_indices].name_i.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# df_struct[df_struct[\"stoich\"] == \"AB3\"].shape\n",
    "# df_struct[df_struct[\"stoich\"] == \"AB2\"].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# TEMP | Number of atoms in structures"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "def method(row_i, argument_0, optional_arg=None):\n",
    "    new_column_values_dict = {\"num_atoms\": None}\n",
    "\n",
    "    new_column_values_dict[\"num_atoms\"] = row_i[\"atoms\"].get_number_of_atoms()\n",
    "\n",
    "    # #########################################################################\n",
    "    for key, value in new_column_values_dict.items():\n",
    "        row_i[key] = value\n",
    "    return(row_i)\n",
    "\n",
    "df_i = df_struct\n",
    "\n",
    "arg1 = \"TEMP_0\"\n",
    "df_i = df_i.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    args=(arg1, ),\n",
    "    optional_arg=\"TEMP_1\"\n",
    "    )\n",
    "df_struct = df_i\n",
    "\n",
    "df_struct_ab3 = df_struct[df_struct[\"stoich\"] == \"AB3\"]\n",
    "\n",
    "df_struct_ab3\n",
    "\n",
    "print(df_struct_ab3.shape)\n",
    "print(df_struct_ab3[df_struct_ab3[\"num_atoms\"] > 100].shape)\n",
    "\n",
    "df_struct_ab3[df_struct_ab3[\"num_atoms\"] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "df_tmp = df_struct[df_struct.stoich == \"AB2\"]\n",
    "\n",
    "# df_tmp.shape\n",
    "\n",
    "df_tmp[df_tmp.num_atoms <= 75].shape"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
