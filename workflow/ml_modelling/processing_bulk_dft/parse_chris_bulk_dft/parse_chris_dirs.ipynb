{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Chris's DFT Data on NERSC\n",
    "---\n",
    "\n",
    "\n",
    "Author(s): Raul A. Flores"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ID IrO3-146 isn't availabe in the parsed folders\n",
    "\n",
    "-171.82382373\n",
    "Ir8O24\n",
    "\n",
    "# #############################################################################\n",
    "# Have these columns by the end\n",
    "['atoms',\n",
    " 'energy',\n",
    " 'energy_pa',\n",
    " 'force_max',\n",
    " 'force_sum',\n",
    " 'form_e_chris',\n",
    " 'path',\n",
    " 'stoich',\n",
    " 'id_old',\n",
    " 'source']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"chris_prototypes_structures/oqmd_iro3\",\n",
    "    ))\n",
    "\n",
    "sys.path.insert(0, os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"data\",\n",
    "    ))\n",
    "\n",
    "import pickle\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "from ase import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\n",
    "    \"/mnt/f/GDrive/norskov_research_storage\",\n",
    "    \"00_projects/PROJ_irox_2/chris_nersc_files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse ID List from Files from Chris"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"data/ml_irox_data/iro2_training_data.csv\")\n",
    "train_data_iro2 = pd.read_csv(file_path_i)\n",
    "train_data_iro2.set_index(\"id\", inplace=True)\n",
    "\n",
    "file_path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"data/ml_irox_data/iro3_training_data.csv\")\n",
    "train_data_iro3 = pd.read_csv(file_path_i)\n",
    "train_data_iro3.set_index(\"id\", inplace=True)\n",
    "\n",
    "train_data_dict = {\n",
    "    \"iro2\": train_data_iro2,\n",
    "    \"iro3\": train_data_iro3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse NERSC DFT Data\n",
    "\n",
    "Comment out to read pickled data file instead (saves time)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# master_data_list = []\n",
    "# id_list_nersc = []\n",
    "# for subdir, dirs, files in os.walk(root_dir):\n",
    "#     if \"gas_references\" in subdir:\n",
    "#         continue\n",
    "#     if \"IrO2/Old_ML_calcs\" in subdir:\n",
    "#         continue\n",
    "#     if \"__old__\" in subdir:\n",
    "#         continue\n",
    "#     if \"volume\" in subdir:\n",
    "#         continue\n",
    "\n",
    "#     if \"OUTCAR\" in files:\n",
    "#         dir_i = subdir\n",
    "#         id_i = int(subdir.split(\"/\")[-1].split(\"_\")[0])\n",
    "\n",
    "#         try:\n",
    "#             atoms_i = io.read(os.path.join(dir_i, \"OUTCAR\"))\n",
    "#         except:\n",
    "#             atoms_i = None\n",
    "\n",
    "#         replace_path_snip = os.path.join(\n",
    "#             \"/mnt/f/GDrive/norskov_research_storage\"\n",
    "#             \"00_projects/PROJ_irox_2/chris_nersc_files/\"\n",
    "#             )\n",
    "#         path_short_i = dir_i.replace(replace_path_snip, \"\")\n",
    "\n",
    "#         dict_i = {\n",
    "#             \"id_old\": id_i,\n",
    "#             \"atoms\": atoms_i,\n",
    "#             \"path\": path_short_i}\n",
    "\n",
    "#         master_data_list.append(dict_i)\n",
    "\n",
    "\n",
    "# # Save Data ###################################################################\n",
    "# directory = \"out_data\"\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "\n",
    "# with open(os.path.join(directory, \"parse_data.pickle\"), \"wb\") as fle:\n",
    "#     pickle.dump(master_data_list, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out_data/parse_data.pickle\", \"rb\") as fle:\n",
    "    master_data_list = pickle.load(fle)\n",
    "\n",
    "df = pd.DataFrame(master_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process dataframe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# #############################################################################\n",
    "def method(row_i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if \"IrO2\" in row_i[\"path\"]:\n",
    "        sys_i = \"AB2\"\n",
    "    elif \"IrO3\" in row_i[\"path\"]:\n",
    "        sys_i = \"AB3\"\n",
    "    else:\n",
    "        sys_i = None\n",
    "    return(sys_i)\n",
    "\n",
    "df[\"stoich\"] = df.apply(\n",
    "    method,\n",
    "    axis=1)\n",
    "\n",
    "# #############################################################################\n",
    "# #############################################################################\n",
    "def method(row_i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ignore_list = [\n",
    "        \"IrO3/winnersIrO3\",\n",
    "        \"IrO3/full_relax\",\n",
    "        \"IrO3/full_relax_ML1\",\n",
    "        \"IrO3/full_relax_ML2\",\n",
    "        \"IrO3/full_relax_ML3\",\n",
    "        \"IrO3/full_relax_ML4\",\n",
    "        \"IrO3/single_point\",\n",
    "        \"IrO3/volume_relax\",\n",
    "        \"IrO3/volume_relax_ML1\",\n",
    "        \"IrO3/volume_relax_ML2\",\n",
    "        \"IrO3/volume_relax_ML3\",\n",
    "        \"IrO3/volume_relax_ML4\",\n",
    "        ]\n",
    "    ignore = False\n",
    "    for ignore_seg_i in ignore_list:\n",
    "        if ignore_seg_i in row_i[\"path\"]:\n",
    "            ignore = True\n",
    "\n",
    "    return(ignore)\n",
    "\n",
    "df[\"ignore_tag\"] = df.apply(\n",
    "    method,\n",
    "    axis=1)\n",
    "\n",
    "# #############################################################################\n",
    "# #############################################################################\n",
    "def method(row_i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if \"volume\" in row_i[\"path\"]:\n",
    "        out = True\n",
    "    else:\n",
    "        out = False\n",
    "    return(out)\n",
    "\n",
    "df[\"volume_tag\"] = df.apply(\n",
    "    method,\n",
    "    axis=1)\n",
    "\n",
    "# #############################################################################\n",
    "# #############################################################################\n",
    "\n",
    "\n",
    "df = df[df[\"ignore_tag\"] == False]\n",
    "df = df[df[\"volume_tag\"] == False]\n",
    "\n",
    "\n",
    "good_bye_list = [\n",
    "    \"ignore_tag\",\n",
    "    \"volume_tag\",\n",
    "    ]\n",
    "\n",
    "# df_dft_calcs.drop(good_bye_list, axis=1, inplace=True)\n",
    "df.drop(good_bye_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IrO2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_iro2 = df[df[\"stoich\"] == \"IrO2\"]\n",
    "df_iro2 = df[df[\"stoich\"] == \"AB2\"]\n",
    "\n",
    "master_data = []\n",
    "for id_i, row_i in train_data_dict[\"iro2\"].iterrows():\n",
    "\n",
    "    if row_i[\"source\"] != \"chris\":\n",
    "        continue\n",
    "\n",
    "    form_e_chris_i = row_i[\"form_e_chris\"]\n",
    "\n",
    "    df_i = df_iro2[df_iro2[\"id_old\"] == id_i]\n",
    "\n",
    "    if len(df_i) == 0:\n",
    "        print(id_i, \" | There are no rows for this id!!!!\")\n",
    "\n",
    "    df_0 = df_i[df_i[\"path\"].str.contains(\"final_opt_new1-3\")]\n",
    "    df_1 = df_i[df_i[\"path\"].str.contains(\"final_relax\")]\n",
    "\n",
    "    row_i = None\n",
    "    if len(df_0) > 0:\n",
    "        if len(df_0) > 1:\n",
    "            print(\"NOOOOOOOOOO!!!!!!!!!\")\n",
    "        row_j = df_0.iloc[0]\n",
    "\n",
    "    else:\n",
    "        if len(df_1) > 0:\n",
    "            if len(df_1) > 1:\n",
    "                print(\"NOOOOOOOOOO!!!!!!!!!\")\n",
    "            row_j = df_1.iloc[0]\n",
    "        else:\n",
    "            tmp = 42\n",
    "\n",
    "    master_data.append(row_j)\n",
    "\n",
    "df_iro2_unique = pd.concat(master_data, axis=1, sort=True).transpose()\n",
    "# df_iro2_unique.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IrO3"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iro3 = df[df[\"stoich\"] == \"AB3\"]\n",
    "\n",
    "master_data = []\n",
    "for id_i, row_i in train_data_dict[\"iro3\"].iterrows():\n",
    "\n",
    "    if row_i[\"source\"] != \"chris\":\n",
    "        continue\n",
    "\n",
    "    form_e_chris_i = row_i[\"form_e_chris\"]\n",
    "\n",
    "    df_i = df_iro3[df_iro3[\"id_old\"] == id_i]\n",
    "\n",
    "    if len(df_i) == 0:\n",
    "        print(id_i, \" | There are no rows for this id!!!!\")\n",
    "        row_j = pd.Series({\"id_old\": int(id_i)})\n",
    "    else:\n",
    "        df_0 = df_i[df_i[\"path\"].str.contains(\"final_opt_new1-3_sorted\")]\n",
    "        if len(df_0) > 0:\n",
    "            if len(df_0) > 1:\n",
    "                print(\"NOOOOOOOOOO!!!!!!!!!\")\n",
    "            row_j = df_0.iloc[0]\n",
    "        else:\n",
    "            row_j = df_i.iloc[0]\n",
    "\n",
    "    master_data.append(row_j)\n",
    "\n",
    "df_iro3_unique = pd.concat(master_data, axis=1, sort=True).transpose()\n",
    "# df_iro3_unique = df_iro3_unique.astype({\"id\": int})\n",
    "# df_iro3_unique.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining IrO2 and IrO3 dataframes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iro2_dft = df_iro2_unique\n",
    "df_iro3_dft = df_iro3_unique\n",
    "\n",
    "df_dft_calcs = pd.concat([\n",
    "    df_iro2_dft,\n",
    "    df_iro3_dft,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data to pickle"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(\"out_data/df_dft_calcs.pickle\", \"wb\") as fle:\n",
    "    pickle.dump(df_dft_calcs, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft_calcs[df_dft_calcs[\"id_old\"] == 192].iloc[0][\"atoms\"].get_potential_energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_list = [192, 195, 118, 136, 160, 202, 72, 126, 111, 106, 27]\n",
    "df_dft_calcs[df_dft_calcs[\"id_old\"].isin(new_id_list)].loc[76][\"path\"]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:research-new]",
   "language": "python",
   "name": "conda-env-research-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
