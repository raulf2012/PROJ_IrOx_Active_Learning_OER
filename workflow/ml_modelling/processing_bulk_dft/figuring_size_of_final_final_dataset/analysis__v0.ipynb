{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Import Modules\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# /mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_Active_Learning_OER/workflow/ml_modelling\n",
    "\n",
    "sys.path.insert(0, \"/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_Active_Learning_OER/workflow/ml_modelling\")\n",
    "\n",
    "from ml_methods import get_ml_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich = \"AB3\"\n",
    "verbose = True\n",
    "drop_too_many_atoms = True\n",
    "# drop_too_many_atoms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data_for_al(\n",
    "# stoich=\"AB2\",\n",
    "# verbose=True,\n",
    "# drop_too_many_atoms=True,\n",
    "# ):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# | - get_data_for_al\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (ids_to_discard__too_many_atoms_path)\n",
    "\n",
    "# | - Get all necessary dfs\n",
    "df_dict = get_ml_dataframes(\n",
    "    names=[\n",
    "        \"bulk_dft_data_path\",\n",
    "        \"unique_ids_path\",\n",
    "        # \"prototypes_data_path\",\n",
    "        \"static_irox_structures_path\",\n",
    "        # \"static_irox_structures_kirsten_path\",\n",
    "        # \"oqmd_irox_data_path\",\n",
    "        \"df_features_pre_opt_path\",\n",
    "        \"df_features_pre_opt_kirsten_path\",\n",
    "        \"df_features_post_opt_path\",\n",
    "        # \"oer_bulk_structures_path\",\n",
    "        # \"df_ccf_path\",\n",
    "        \"df_dij_path\",\n",
    "        # \"ids_to_discard__too_many_atoms_path\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "df_ids = df_dict.get(\"unique_ids\", None)\n",
    "df_bulk_dft = df_dict.get(\"bulk_dft_data\", None)\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft.source == \"raul\"]\n",
    "\n",
    "df_features_pre = df_dict.get(\"df_features_pre_opt\", None)\n",
    "# df_features_pre = df_dict.get(\"df_features_pre_opt_kirsten\", None)\n",
    "df_features_post = df_dict.get(\"df_features_post_opt\", None)\n",
    "\n",
    "df_dij = df_dict.get(\"df_dij\", None)\n",
    "\n",
    "\n",
    "df_static_irox = df_dict.get(\"static_irox_structures\", None)\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Filter ids to user specifications\n",
    "df_ids = df_ids[\n",
    "    (df_ids[\"stoich\"] == stoich) & \\\n",
    "    (df_ids[\"source\"] != \"oqmd\") & \\\n",
    "    (df_ids[\"source\"] != \"raul_oer\") & \\\n",
    "    [True for i in range(len(df_ids))]]\n",
    "ids = df_ids[\"unique_ids\"]\n",
    "\n",
    "#__|\n",
    "\n",
    "# #########################################################################\n",
    "\n",
    "# | - DFT dataframe\n",
    "df_i = df_bulk_dft\n",
    "\n",
    "# print(\"isidfjisdjifjsidjf8yu2894h90832uy4908tyu98023wht0982quj098gtfujw3e\")\n",
    "# print(df_i.index.shape)\n",
    "# print(df_i.index.unique().shape)\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_bulk_dft = df_i\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 systems for AB3 not computed\n",
    "# 210 systems for AB2 not computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "109\n",
    "\n",
    "10 + 210 - 10 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Features post-DFT\n",
    "df_i = df_features_post\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_features_post = df_i\n",
    "\n",
    "# Only use post-DFT features from my data set\n",
    "df_features_post = \\\n",
    "    df_features_post[df_features_post[\"data\"][\"source\"] == \"raul\"]\n",
    "\n",
    "df_features_post = df_features_post[\"voronoi\"]\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Dropping certain rows\n",
    "all_ids = list(set(\n",
    "    df_bulk_dft.index.tolist() + \\\n",
    "    df_features_pre.index.tolist() + \\\n",
    "    df_features_post.index.tolist() ))\n",
    "\n",
    "\n",
    "ids_to_drop = []\n",
    "\n",
    "# #########################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures/out_data\",\n",
    "    \"ids_to_discard__proto_dupl.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    ids_to_discard__proto_dupl = pickle.load(fle)\n",
    "    ids_to_drop.extend(ids_to_discard__proto_dupl)\n",
    "# #########################################################################\n",
    "\n",
    "if drop_too_many_atoms:\n",
    "    # #####################################################################\n",
    "    with open(ids_to_discard__too_many_atoms_path, \"rb\") as fle:\n",
    "        ids_to_drop__too_many_atoms = pickle.load(fle)\n",
    "        ids_to_drop.extend(ids_to_drop__too_many_atoms)\n",
    "\n",
    "        # ids_to_drop = ids_to_drop__too_many_atoms\n",
    "        # ids_to_drop = [i for i in ids_to_drop if i in all_ids]\n",
    "    # #####################################################################\n",
    "\n",
    "\n",
    "ids_to_drop = [i for i in ids_to_drop if i in all_ids]\n",
    "print(\"len(ids_to_drop)\", len(ids_to_drop))\n",
    "\n",
    "df_features_pre = df_features_pre.drop(\n",
    "    labels=ids_to_drop, axis=0)\n",
    "\n",
    "tmp = df_bulk_dft.index.intersection(\n",
    "    df_features_pre.index\n",
    "    ).unique()\n",
    "print(\"dksljkfjsijfijsdijfi\", len(df_bulk_dft.index) - len(tmp))\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.loc[\n",
    "    df_bulk_dft.index.intersection(\n",
    "        df_features_pre.index\n",
    "        ).unique()\n",
    "    ]\n",
    "\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ids_to_drop__too_many_atoms)\n",
    "\n",
    "ids_to_drop__too_many_atoms\n",
    "\n",
    "# ids.values\n",
    "\n",
    "ids_to_drop_abx = np.intersect1d(\n",
    "    ids_to_drop__too_many_atoms,\n",
    "    ids.values,\n",
    "    )\n",
    "\n",
    "len(ids_to_drop_abx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.intersect1d(\n",
    "    ids_not_in__df_i,\n",
    "    # ids_to_drop_abx,\n",
    "    ids_to_drop__too_many_atoms,\n",
    "    )\n",
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "697 - 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "458 + 29 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 458 structures for AB2\n",
    "# 243 structures for AB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "458 + 243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# out_dict = dict()\n",
    "\n",
    "# out_dict[\"df_features_post\"] = df_features_post\n",
    "# out_dict[\"df_features_pre\"] = df_features_pre\n",
    "# out_dict[\"df_bulk_dft\"] = df_bulk_dft\n",
    "\n",
    "# # TEMP\n",
    "# out_dict[\"df_ids\"] = df_ids\n",
    "# out_dict[\"df_dij\"] = df_dij\n",
    "# out_dict[\"df_static_irox\"] = df_static_irox\n",
    "\n",
    "\n",
    "# # return(out_dict)\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # | - Featurs pre-DFT\n",
    "# df_i = df_features_pre\n",
    "\n",
    "# # Common ids between user ids and df\n",
    "# common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "# ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "# df_i = df_i.loc[common_ids]\n",
    "\n",
    "# if verbose:\n",
    "#     print(\"len(ids):\", len(ids))\n",
    "#     print(\"len(common_ids)\", len(common_ids))\n",
    "#     print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "#     print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "# df_features_pre = df_i\n",
    "\n",
    "# df_features_pre = df_features_pre[\"voronoi\"]\n",
    "# #__|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
