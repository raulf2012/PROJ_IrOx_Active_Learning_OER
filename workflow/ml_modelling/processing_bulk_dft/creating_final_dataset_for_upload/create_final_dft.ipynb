{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \n",
    "    os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        \"workflow/ml_modelling\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "from ml_methods import get_ml_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_dict = get_ml_dataframes()\n",
    "\n",
    "# list(DF_dict.keys())\n",
    "\n",
    "bulk_dft_data = DF_dict['bulk_dft_data']\n",
    "unique_ids = DF_dict['unique_ids']\n",
    "prototypes_data = DF_dict['prototypes_data']\n",
    "static_irox_structures = DF_dict['static_irox_structures']\n",
    "static_irox_structures_kirsten = DF_dict['static_irox_structures_kirsten']\n",
    "oqmd_irox_data = DF_dict['oqmd_irox_data']\n",
    "df_features_pre_opt = DF_dict['df_features_pre_opt']\n",
    "df_features_pre_opt_kirsten = DF_dict['df_features_pre_opt_kirsten']\n",
    "df_features_post_opt = DF_dict['df_features_post_opt']\n",
    "oer_bulk_structures = DF_dict['oer_bulk_structures']\n",
    "df_ccf = DF_dict['df_ccf']\n",
    "df_dij = DF_dict['df_dij']\n",
    "ids_to_discard__too_many_atoms = DF_dict['ids_to_discard__too_many_atoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tmp = bulk_dft_data[bulk_dft_data.stoich == \"AB2\"]\n",
    "\n",
    "# # ids_to_discard__too_many_atoms\n",
    "\n",
    "# print(df_tmp.shape[0])\n",
    "\n",
    "# # df_tmp.loc[\n",
    "# #     [i for i in df_tmp.index.tolist() if i not in ids_to_discard__too_many_atoms]\n",
    "# #     ].shape\n",
    "\n",
    "# len([i for i in df_tmp.index.tolist() if i not in ids_to_discard__too_many_atoms])\n",
    "\n",
    "# print(len(ids_to_discard__too_many_atoms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_dft_data = bulk_dft_data[bulk_dft_data.source == \"raul\"]\n",
    "# bulk_dft_data.shape\n",
    "\n",
    "static_irox_structures = static_irox_structures[static_irox_structures.source == \"chris\"]\n",
    "# static_irox_structures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# static_irox_structures[\"num_of_atoms\"] = [i.get_number_of_atoms() for i in static_irox_structures.atoms]\n",
    "static_irox_structures.loc[:, \"num_of_atoms\"] = [i.get_number_of_atoms() for i in static_irox_structures.atoms]\n",
    "\n",
    "static_irox_structures = static_irox_structures[static_irox_structures.num_of_atoms <= 75]\n",
    "# static_irox_structures = static_irox_structures[static_irox_structures.num_of_atoms < 75]\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TEMP:\", static_irox_structures.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_irox_structures[static_irox_structures.stoich == \"AB2\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_ind = static_irox_structures.index\n",
    "\n",
    "dft_ind = bulk_dft_data.index\n",
    "\n",
    "intersection_indices = static_ind.intersection(dft_ind)\n",
    "\n",
    "bulk_dft_data = bulk_dft_data.loc[intersection_indices]\n",
    "\n",
    "bulk_dft_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_dft_data_ab2 = bulk_dft_data[bulk_dft_data.stoich == \"AB2\"]\n",
    "bulk_dft_data_ab3 = bulk_dft_data[bulk_dft_data.stoich == \"AB3\"]\n",
    "\n",
    "print(\"bulk_dft_data_ab2.shape:\", bulk_dft_data_ab2.shape)\n",
    "print(\"bulk_dft_data_ab3.shape:\", bulk_dft_data_ab3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Post-DFT Duplicates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/00_ml_workflow/191102_new_workflow/00_abx_al_runs\",\n",
    "    \"out_data/duplicates.pickle\")\n",
    "\n",
    "\n",
    "# /mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_Active_Learning_OER/\n",
    "\n",
    "# #########################################################\n",
    "import pickle; import os\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    duplicates = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_dft_data_ab2 = bulk_dft_data_ab2.drop(duplicates[\"AB2\"])\n",
    "print(bulk_dft_data_ab2.shape)\n",
    "\n",
    "bulk_dft_data_ab3 = bulk_dft_data_ab3.drop(duplicates[\"AB3\"])\n",
    "print(bulk_dft_data_ab3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "384 + 191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(duplicates[\"AB2\"]))\n",
    "\n",
    "print(len(list(set(duplicates[\"AB2\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = pd.concat([\n",
    "    bulk_dft_data_ab2,\n",
    "    bulk_dft_data_ab3,\n",
    "    ])\n",
    "\n",
    "df_dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_dft_final_no_dupl.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_dft, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"workflow/ml_modelling/processing_bulk_dft/creating_final_dataset_for_upload\",\n",
    "\"out_data/df_dft_final_no_dupl.pickle\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# intersection_indices = \n",
    "\n",
    "# static_ind.intersection(dft_ind)\n",
    "\n",
    "# dft_ind.intersection(static_ind)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
