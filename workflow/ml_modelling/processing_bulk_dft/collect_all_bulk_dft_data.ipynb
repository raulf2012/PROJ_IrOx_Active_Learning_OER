{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #############################################################################\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "\n",
    "from proj_data_irox import (\n",
    "    bulk_dft_data_path,\n",
    "    unique_ids_path,\n",
    "    prototypes_data_path,\n",
    "    static_irox_structures_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_i = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"workflow/ml_modelling\",\n",
    "#     \"processing_bulk_dft/parse_chris_bulk_dft/out_data\",\n",
    "#     \"df_dft_calcs.pickle\")\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     df_chris = pickle.load(fle)\n",
    "# df_chris[\"source\"] = \"chris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/processing_bulk_dft\",\n",
    "    \"parse_my_bulk_dft/out_data\",\n",
    "    \"df_bulk_raul_irox.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_raul_irox = pickle.load(fle)\n",
    "    \n",
    "df_raul_irox[\"source\"] = \"raul\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/processing_bulk_dft\",\n",
    "    \"parse_my_oer_bulk_dft/out_data\",\n",
    "    \"df_oer_bulk.pickle\")\n",
    "\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_oer_bulk = pickle.load(fle)\n",
    "\n",
    "# df_raul_irox[\"source\"] = \"raul\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj_data_irox import oqmd_irox_data_path\n",
    "with open(oqmd_irox_data_path, \"rb\") as fle:\n",
    "    df_oqmd_data = pickle.load(fle)\n",
    "\n",
    "df_oqmd_data = df_oqmd_data.drop(\n",
    "    labels=[\n",
    "        \"source\",\n",
    "#         \"id_unique\",\n",
    "        ],\n",
    "    axis=1,\n",
    "    )\n",
    "\n",
    "df_oqmd_data[\"source\"] = \"oqmd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Chris and Raul data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [\n",
    "    df_raul_irox,\n",
    "    df_oer_bulk,\n",
    "    # df_chris,\n",
    "    df_oqmd_data,\n",
    "    ]\n",
    "\n",
    "df_m = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping unique ID scheme"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = pd.read_csv(unique_ids_path)\n",
    "\n",
    "id_mapp_iro2 = dict(zip(\n",
    "    df_id[df_id[\"stoich\"] == \"AB2\"][\"id\"],\n",
    "    df_id[df_id[\"stoich\"] == \"AB2\"][\"unique_ids\"]))\n",
    "\n",
    "id_mapp_iro3 = dict(zip(\n",
    "    df_id[df_id[\"stoich\"] == \"AB3\"][\"id\"],\n",
    "    df_id[df_id[\"stoich\"] == \"AB3\"][\"unique_ids\"]))\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "def method(row_i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    if row_i[\"source\"] == \"raul_oer\":\n",
    "        id_unique_i = row_i.name\n",
    "    else:\n",
    "        id_i = row_i[\"id_old\"]\n",
    "\n",
    "        if row_i[\"stoich\"] == \"IrO2\" or row_i[\"stoich\"] == \"AB2\":\n",
    "            mapping_dict = id_mapp_iro2\n",
    "        elif row_i[\"stoich\"] == \"IrO3\" or row_i[\"stoich\"] == \"AB3\":\n",
    "            mapping_dict = id_mapp_iro3\n",
    "        else:\n",
    "            print(\"BAD BAD | Couldn't process id: \", row_i)\n",
    "\n",
    "        id_unique_i = mapping_dict[id_i]\n",
    "\n",
    "    return(id_unique_i)\n",
    "\n",
    "df_m[\"id_unique\"] = df_m.apply(method, axis=1)\n",
    "df_m.set_index(\"id_unique\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding energy per atom column"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    atoms_i = row_i[\"atoms\"]\n",
    "    energy = None\n",
    "    if atoms_i is None:\n",
    "        energy = None\n",
    "    else:\n",
    "        try:\n",
    "            energy = atoms_i.get_potential_energy()\n",
    "        except:\n",
    "            energy = None\n",
    "    return(energy)\n",
    "df_m[\"energy\"] = df_m.apply(method, axis=1)\n",
    "\n",
    "def method(row_i):\n",
    "    energy_norm_i = None\n",
    "\n",
    "    atoms_i = row_i[\"atoms\"]\n",
    "    # energy_pa = row_i[\"energy_pa\"]\n",
    "    energy_pa = row_i.get(\"energy_pa\", np.nan)\n",
    "    \n",
    "\n",
    "    if not np.isnan(energy_pa) and row_i[\"source\"] == \"oqmd\":\n",
    "        energy_norm_i = energy_pa\n",
    "\n",
    "    else:\n",
    "        if atoms_i is None:\n",
    "            energy_norm_i = None\n",
    "        else:\n",
    "            num_atoms_i = len(atoms_i.get_atomic_numbers())\n",
    "            energy_norm_i = row_i[\"energy\"] / num_atoms_i\n",
    "\n",
    "    return(energy_norm_i)\n",
    "df_m[\"energy_pa\"] = df_m.apply(method, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Formation Enthalpy and Gibbs Free Energy"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj_data_irox import calc_dH\n",
    "\n",
    "\n",
    "def method(row_i, calc_dH):\n",
    "    energy_pa = row_i[\"energy_pa\"]\n",
    "    stoich = row_i[\"stoich\"]\n",
    "    \n",
    "    dH = calc_dH(energy_pa, stoich=stoich)\n",
    "    \n",
    "    return(dH)\n",
    "\n",
    "df_m[\"dH\"] = df_m.apply(method, args=(calc_dH, ), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing rows with missing atoms objects"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_m[df_m[\"atoms\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count number of atoms"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    atoms_i = row_i[\"atoms\"]\n",
    "    num_atoms_i = atoms_i.get_number_of_atoms()\n",
    "    return(num_atoms_i)\n",
    "\n",
    "df_m[\"num_atoms\"] = df_m.apply(\n",
    "    method,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    atoms_i = row_i[\"atoms\"]\n",
    "    volume = atoms_i.get_volume()\n",
    "\n",
    "    return(volume)\n",
    "\n",
    "df_m[\"volume\"] = df_m.apply(\n",
    "    method,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m[\"volume_pa\"] = df_m.volume / df_m.num_atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "with open(os.path.join(directory, \"df_bulk_dft.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_m, fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox]",
   "language": "python",
   "name": "conda-env-PROJ_irox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
