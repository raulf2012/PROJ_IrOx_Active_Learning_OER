{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import bulk_dft_data_path\n",
    "\n",
    "# #############################################################################\n",
    "from ase_modules.ase_methods import view_in_vesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase_modules.ase_methods import view_in_vesta\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling\",\n",
    "    \"ccf_similarity_analysis/out_data\",\n",
    "    \"all_ids_to_elim_1.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    all_ids_to_elim = pickle.load(fle)\n",
    "\n",
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft = df_bulk_dft[\n",
    "    (df_bulk_dft[\"source\"] != \"oqmd\") & \\\n",
    "    (df_bulk_dft[\"source\"] != \"raul_oer\") & \\\n",
    "    (df_bulk_dft[\"source\"] != \"chris\") & \\\n",
    "    [True for i in range(len(df_bulk_dft))]\n",
    "    ]\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.drop(all_ids_to_elim)"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft = df_bulk_dft.sort_values(\"energy_pa\")\n",
    "\n",
    "# row_i = df_bulk_dft.iloc[2]\n",
    "row_i = df_bulk_dft.loc[\"cqbrnhbacg\"]\n",
    "\n",
    "\n",
    "atoms = row_i[\"atoms\"]\n",
    "atoms\n",
    "\n",
    "# view_in_vesta(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.analysis import local_env\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "structure = AseAtomsAdaptor.get_structure(atoms)\n",
    "\n",
    "\n",
    "CrysNN = local_env.CrystalNN(\n",
    "    weighted_cn=False,\n",
    "    cation_anion=False,\n",
    "    distance_cutoffs=(0.5, 1),\n",
    "    x_diff_weight=3.0,\n",
    "    porous_adjustment=True,\n",
    "    search_cutoff=7,\n",
    "    fingerprint_length=None)\n",
    "\n",
    "\n",
    "coord_data_dict = {\n",
    "    # \"\": ,\n",
    "    }\n",
    "\n",
    "data_master = []\n",
    "for i_cnt, site_i in enumerate(structure.sites):\n",
    "    site_elem_i = site_i.species_string\n",
    "\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    data_dict_i[\"element\"] = site_elem_i\n",
    "    data_dict_i[\"structure_index\"] = i_cnt\n",
    "\n",
    "    nn_info_i = CrysNN.get_nn_info(structure, i_cnt)\n",
    "\n",
    "    if site_elem_i == \"Ir\":\n",
    "        if len(nn_info_i) != 6:\n",
    "            print(\"IOPSJDIFIDSJFID\")\n",
    "\n",
    "    if site_elem_i == \"O\":\n",
    "        tmp = nn_info_i\n",
    "\n",
    "    neighbor_list = []\n",
    "    for neighbor_j in nn_info_i:\n",
    "        neigh_elem_j = neighbor_j[\"site\"].species_string\n",
    "        neighbor_list.append(neigh_elem_j)\n",
    "\n",
    "    neighbor_count_dict = dict()\n",
    "    for i in neighbor_list:\n",
    "        neighbor_count_dict[i] = neighbor_count_dict.get(i, 0) + 1\n",
    "    \n",
    "    data_dict_i[\"neighbor_count\"] = neighbor_count_dict\n",
    "    \n",
    "    data_master.append(data_dict_i)\n",
    "\n",
    "df_tmp = pd.DataFrame(data_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out if octahedra are corner sharing edge sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_info_i\n",
    "\n",
    "def number_of_neighbors(nn_info):\n",
    "    num_neighbors = len(nn_info)\n",
    "    return(num_neighbors)\n",
    "\n",
    "\n",
    "\n",
    "def atom_is_in_central_octahedra(nn_info, verbose=True):\n",
    "    is_octahedra = False\n",
    "\n",
    "    correct_number_of_ligands = False\n",
    "    correct_ligand_type = False\n",
    "    \n",
    "\n",
    "    num_nn = number_of_neighbors(nn_info)\n",
    "\n",
    "    if num_nn == 6:\n",
    "        correct_number_of_ligands = True\n",
    "        if verbose:\n",
    "            print(\"6 nearest neighbors!\")\n",
    "\n",
    "    nn_elems_unique = list(set([i[\"site\"].species_string for i in nn_info_i]))\n",
    "    if (len(nn_elems_unique) == 1) & (nn_elems_unique[0] == \"O\"):\n",
    "        correct_ligand_type = True\n",
    "        if verbose:\n",
    "            print(\"Only 1 type of NN and it's oxygen\")\n",
    "    \n",
    "    if correct_ligand_type and correct_number_of_ligands:\n",
    "        is_octahedra = True\n",
    "\n",
    "    return(is_octahedra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_is_in_central_octahedra(nn_info_i, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_indices_list = []\n",
    "for i_cnt, site_i in enumerate(structure.sites):\n",
    "    if site_i.species_string == \"Ir\":\n",
    "        ir_indices_list.append(i_cnt)\n",
    "\n",
    "\n",
    "for index_i in ir_indices_list:\n",
    "    nn_info_i = CrysNN.get_nn_info(structure, index_i)\n",
    "\n",
    "    neighbor_list_indics_i = [i[\"site_index\"] for i in nn_info_i]\n",
    "\n",
    "    for index_j in ir_indices_list:\n",
    "        \n",
    "        if index_i == index_j:\n",
    "            continue\n",
    "\n",
    "        print(index_i, index_j)\n",
    "\n",
    "        nn_info_j = CrysNN.get_nn_info(structure, index_j)\n",
    "        neighbor_list_indics_j = [i[\"site_index\"] for i in nn_info_j]\n",
    "\n",
    "\n",
    "        num_shared_neigh = len(list(\n",
    "            set(neighbor_list_indics_j) & set(neighbor_list_indics_i)))"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# neigh_elem_j\n",
    "# neighbor_list\n",
    "\n",
    "# neighbor_count_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# dir(tmp[0][\"site\"])\n",
    "\n",
    "# # tmp[0][\"site\"].specie\n",
    "# # tmp[0][\"site\"].species\n",
    "\n",
    "# tmp[0][\"site\"].species_string\n",
    "\n",
    "\n",
    "# # species\n",
    "# # species_and_occu\n",
    "# # species_string"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
