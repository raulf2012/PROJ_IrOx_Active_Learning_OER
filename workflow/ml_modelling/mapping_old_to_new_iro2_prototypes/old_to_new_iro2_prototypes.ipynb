{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating mapping between the old and new prototype numbering system for IrO2 \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "from ase import io\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from jupyter_modules.jupyter_helpers.following_tail import FollowingTail\n",
    "\n",
    "from pymatgen.io.vasp.inputs import Poscar\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "import bulk_enumerator as be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_files = False\n",
    "compare_old_new = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bulk_protos(row_i, row_j):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    props_to_compare = [\n",
    "        \"name_i\",\n",
    "        \"parameter_values_i\",\n",
    "        \"spacegroup_i\",\n",
    "        \"species_i\",\n",
    "        \"wyckoff_i\",\n",
    "        ]\n",
    "\n",
    "    bool_compare_list = []\n",
    "    for prop_k in props_to_compare:\n",
    "\n",
    "        # *********************************************************************\n",
    "        # *********************************************************************\n",
    "        if prop_k == \"name_i\":\n",
    "            val_i = row_i[\"prototype_info\"][prop_k]\n",
    "            val_j = row_j[\"prototype_info\"][prop_k]\n",
    "\n",
    "            if val_i == val_j:\n",
    "                bool_compare_list.append(True)\n",
    "            else:\n",
    "                bool_compare_list.append(False)\n",
    "\n",
    "        # *********************************************************************\n",
    "        # *********************************************************************\n",
    "        if prop_k == \"parameter_values_i\":\n",
    "            tmp = 42\n",
    "\n",
    "        # *********************************************************************\n",
    "        # *********************************************************************\n",
    "        if prop_k == \"spacegroup_i\":\n",
    "            val_i = row_i[\"prototype_info\"][prop_k]\n",
    "            val_j = row_j[\"prototype_info\"][prop_k]\n",
    "\n",
    "            if val_i == val_j:\n",
    "                bool_compare_list.append(True)\n",
    "            else:\n",
    "                bool_compare_list.append(False)\n",
    "\n",
    "        # *********************************************************************\n",
    "        # *********************************************************************\n",
    "        if prop_k == \"species_i\":\n",
    "            val_i = row_i[\"prototype_info\"][prop_k]\n",
    "            val_j = row_j[\"prototype_info\"][prop_k]\n",
    "\n",
    "            if list(set(val_i)) == list(set(val_j)):\n",
    "                bool_compare_list.append(True)\n",
    "            else:\n",
    "                bool_compare_list.append(False)\n",
    "\n",
    "        # *********************************************************************\n",
    "        # *********************************************************************\n",
    "        if prop_k == \"wyckoff_i\":\n",
    "            val_i = row_i[\"prototype_info\"][prop_k]\n",
    "            val_j = row_j[\"prototype_info\"][prop_k]\n",
    "\n",
    "            if list(set(val_i)) == list(set(val_j)):\n",
    "                bool_compare_list.append(True)\n",
    "            else:\n",
    "                bool_compare_list.append(False)\n",
    "\n",
    "\n",
    "    return(bool_compare_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Old Prototype Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parse_files:\n",
    "    root_path = os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        \"chris_prototypes_structures/fixedprototypesIrO2_old\")\n",
    "\n",
    "    master_list = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file_i in files:\n",
    "            if \".cif\" in file_i:\n",
    "                atoms_i = io.read(os.path.join(root, file_i))\n",
    "                id_i = file_i.split(\"_\")[0]\n",
    "\n",
    "                sys_i = {\n",
    "                    \"atoms\": atoms_i,\n",
    "                    \"id\": id_i}\n",
    "\n",
    "                master_list.append(sys_i)\n",
    "\n",
    "    df_old = pd.DataFrame(master_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading New Prototype Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parse_files:\n",
    "    root_path = os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        \"chris_prototypes_structures/fixedprototypesIrO2\")\n",
    "\n",
    "    master_list = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file_i in files:\n",
    "            if \".cif\" in file_i:\n",
    "                atoms_i = io.read(os.path.join(root, file_i))\n",
    "                id_i = file_i.split(\"_\")[0]\n",
    "\n",
    "                sys_i = {\n",
    "                    \"atoms\": atoms_i,\n",
    "                    \"id\": id_i}\n",
    "\n",
    "                master_list.append(sys_i)\n",
    "\n",
    "    df_new = pd.DataFrame(master_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Prototype Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Old Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parse_files:\n",
    "    data_list = []\n",
    "    for i_cnt, row_i in df_old.iterrows():\n",
    "        atoms_i = row_i[\"atoms\"]\n",
    "        structure_i = AseAtomsAdaptor.get_structure(atoms_i)\n",
    "\n",
    "        b = be.bulk.BULK()\n",
    "        b.set_structure_from_file(Poscar(structure_i).get_string())\n",
    "\n",
    "        spacegroup_i = b.get_spacegroup()\n",
    "        species_i = b.get_species()\n",
    "        wyckoff_i = b.get_wyckoff()\n",
    "        name_i = b.get_name()\n",
    "        parameter_values_i = b.get_parameter_values()\n",
    "\n",
    "        row_dict_i = {\n",
    "            \"spacegroup_i\": spacegroup_i,\n",
    "            \"species_i\": species_i,\n",
    "            \"wyckoff_i\": wyckoff_i,\n",
    "            \"name_i\": name_i,\n",
    "            \"parameter_values_i\": parameter_values_i,\n",
    "            }\n",
    "        data_list.append(row_dict_i)\n",
    "\n",
    "    df_old = pd.concat(\n",
    "        [df_old, pd.DataFrame(data_list)],\n",
    "        axis=1, join_axes=[df_old.index],\n",
    "        keys=[\"default_columns\", \"prototype_info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing New Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parse_files:\n",
    "    data_list = []\n",
    "    for i_cnt, row_i in df_new.iterrows():\n",
    "        atoms_i = row_i[\"atoms\"]\n",
    "        structure_i = AseAtomsAdaptor.get_structure(atoms_i)\n",
    "\n",
    "        b = be.bulk.BULK()\n",
    "        b.set_structure_from_file(Poscar(structure_i).get_string())\n",
    "\n",
    "        spacegroup_i = b.get_spacegroup()\n",
    "        species_i = b.get_species()\n",
    "        wyckoff_i = b.get_wyckoff()\n",
    "        name_i = b.get_name()\n",
    "        parameter_values_i = b.get_parameter_values()\n",
    "\n",
    "        row_dict_i = {\n",
    "            \"spacegroup_i\": spacegroup_i,\n",
    "            \"species_i\": species_i,\n",
    "            \"wyckoff_i\": wyckoff_i,\n",
    "            \"name_i\": name_i,\n",
    "            \"parameter_values_i\": parameter_values_i,\n",
    "            }\n",
    "        data_list.append(row_dict_i)\n",
    "\n",
    "    df_new = pd.concat(\n",
    "        [df_new, pd.DataFrame(data_list)],\n",
    "        axis=1, join_axes=[df_new.index],\n",
    "        keys=[\"default_columns\", \"prototype_info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing/Reading Dataframes to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parse_files:\n",
    "    with open(\"tmp_df_new.pickle\", \"wb\") as fle:\n",
    "        pickle.dump(df_new, fle)\n",
    "\n",
    "    with open(\"tmp_df_old.pickle\", \"wb\") as fle:\n",
    "        pickle.dump(df_old, fle)\n",
    "\n",
    "if not parse_files:\n",
    "    with open(\"tmp_df_old.pickle\", \"rb\") as fle:\n",
    "        df_old = pickle.load(fle)\n",
    "        \n",
    "    with open(\"tmp_df_new.pickle\", \"rb\") as fle:\n",
    "        df_new = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Old Structures to New Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortening old df to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_list = df_old.index.tolist()\n",
    "        \n",
    "# filtered_index_list = []\n",
    "# for index_i in index_list:\n",
    "#     if random.random() > 0.96:  # 0.60\n",
    "#         filtered_index_list.append(index_i)\n",
    "\n",
    "# print(\"Shortened length of df_old: \", len(filtered_index_list))\n",
    "\n",
    "# df_old = df_old.loc[filtered_index_list,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing mapping between old and new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_old_new:\n",
    "\n",
    "    follow_tail = FollowingTail(n=35)\n",
    "    follow_tail.activate()\n",
    "\n",
    "    mapping_dict = {}\n",
    "    for tmp_i, (i_cnt, row_i) in enumerate(df_old.iterrows()):\n",
    "\n",
    "        str_i = str(tmp_i) + \" | Processing old id: \" + str(row_i[\"default_columns\"][\"id\"])\n",
    "        follow_tail(str_i)\n",
    "\n",
    "        mapping_dict[row_i[\"default_columns\"][\"id\"]] = []\n",
    "\n",
    "        for j_cnt, row_j in df_new.iterrows():\n",
    "            comp_list_j = compare_bulk_protos(row_i, row_j)\n",
    "            if all(comp_list_j):\n",
    "                mapping_dict[row_i[\"default_columns\"][\"id\"]].append(row_j[\"default_columns\"][\"id\"])\n",
    "                str_i = \"-   id match found: \" + str(row_j[\"default_columns\"][\"id\"])\n",
    "                follow_tail(str_i)\n",
    "\n",
    "        follow_tail(\"----------------------------\")\n",
    "\n",
    "\n",
    "    print(\"--------------------------> Done! <--------------------------\")\n",
    "\n",
    "    with open(\"mapping_dict.json\", \"w\") as fle:\n",
    "        json.dump(mapping_dict, fle, indent=2)\n",
    "\n",
    "else:\n",
    "    with open(\"mapping_iro2_ids_190326_1.json\", \"r\") as fle:\n",
    "        mapping_dict = json.load(fle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Mapping Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following new IDs have more than 1 corresponding old ID:  \n",
      " ['0', '308', '245', '604', '449', '455', '655', '570', '682', '58']\n"
     ]
    }
   ],
   "source": [
    "values_list = list(mapping_dict.values())\n",
    "\n",
    "flattened_values = []\n",
    "for i in values_list:\n",
    "    flattened_values += i\n",
    "    \n",
    "print(\n",
    "    \"The following new IDs have more than 1 corresponding old ID: \",\n",
    "    \"\\n\",\n",
    "    [item for item, count in collections.Counter(flattened_values).items() if count > 1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_id:  225  | new_ids ['0', '308']\n",
      "\n",
      "old_id:  241  | new_ids ['245', '604']\n",
      "\n",
      "old_id:  255  | new_ids ['449', '455']\n",
      "\n",
      "old_id:  258  | new_ids ['0', '308']\n",
      "\n",
      "old_id:  265  | new_ids ['449', '455']\n",
      "\n",
      "old_id:  356  | new_ids ['149', '31']\n",
      "\n",
      "old_id:  40  | new_ids ['107', '259']\n",
      "\n",
      "old_id:  43  | new_ids ['570', '682']\n",
      "\n",
      "old_id:  46  | new_ids ['245', '604']\n",
      "\n",
      "old_id:  92  | new_ids ['570', '682']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in mapping_dict.items():\n",
    "    if len(value) > 1:\n",
    "        print(\"old_id: \", key, \" | new_ids\", value)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following old ID doesn't have a mapping into the new ID list\n",
      "old_id:  210\n",
      "The following old ID doesn't have a mapping into the new ID list\n",
      "old_id:  72\n"
     ]
    }
   ],
   "source": [
    "for key, value in mapping_dict.items():\n",
    "    if len(value) == 0:\n",
    "        print(\"The following old ID doesn't have a mapping into the new ID list\")\n",
    "        print(\"old_id: \", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13347464bea3470eac491906b6b99d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "follow_tail = FollowingTail(n=35)\n",
    "follow_tail.activate()\n",
    "\n",
    "duplicates_list = []\n",
    "\n",
    "for tmp_i, (i_cnt, row_i) in enumerate(df_new.iterrows()):\n",
    "    id_i = row_i[\"default_columns\"][\"id\"]\n",
    "    str_i = str(tmp_i) + \" | Processing old id: \" + str(id_i)\n",
    "    follow_tail(str_i)\n",
    "\n",
    "    mapping_dict[row_i[\"default_columns\"][\"id\"]] = []\n",
    "\n",
    "    for tmp_j, (j_cnt, row_j) in enumerate(df_new.iterrows()):\n",
    "        id_j = row_j[\"default_columns\"][\"id\"]\n",
    "\n",
    "        if i_cnt == j_cnt:\n",
    "            continue\n",
    "\n",
    "        comp_list_j = compare_bulk_protos(row_i, row_j)\n",
    "        if all(comp_list_j):\n",
    "            follow_tail(id_i)\n",
    "            follow_tail(id_j)\n",
    "            duplicates_list.append([id_i, id_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_list_2 = [set(i) for i in duplicates_list]\n",
    "# [set(i) for i in duplicates_list][0] == [set(i) for i in duplicates_list][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0', '308'}\n",
      "{'259', '107'}\n",
      "{'140', '23'}\n",
      "{'31', '149'}\n",
      "{'604', '245'}\n",
      "{'420', '270'}\n",
      "{'449', '455'}\n",
      "{'478', '544'}\n",
      "{'682', '570'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_list_pruned = []\n",
    "for i in duplicates_list_2:   \n",
    "    if i not in duplicates_list_pruned:\n",
    "        duplicates_list_pruned.append(i)\n",
    "\n",
    "[print(i) for i in duplicates_list_pruned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m = df_new\n",
    "# df_m[\n",
    "#     (df_m[\"default_columns\"][\"id\"] == \"0\") &\n",
    "# #     (df_m[\"\"] == \"\") &\n",
    "# #     (df_m[\"\"] == \"\") &\n",
    "#     [True for i in range(len(df_m))]\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m[\n",
    "#     (df_m[\"default_columns\"][\"id\"] == \"308\") &\n",
    "# #     (df_m[\"\"] == \"\") &\n",
    "# #     (df_m[\"\"] == \"\") &\n",
    "#     [True for i in range(len(df_m))]\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from time import sleep\n",
    "# # from jupyter_modules.jupyter_helpers.following_tail import FollowingTail\n",
    "\n",
    "\n",
    "# for i in range(300):\n",
    "#     follow_tail(i)\n",
    "#     sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_list = df_old.index.tolist()\n",
    "        \n",
    "# filtered_index_list = []\n",
    "# for index_i in index_list:\n",
    "#     if random.random() > 0.9:\n",
    "#         filtered_index_list.append(index_i)\n",
    "\n",
    "# len(filtered_index_list)\n",
    "\n",
    "# df_old = df_old.loc[filtered_index_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_list = df_old.index.tolist()\n",
    "\n",
    "# filtered_index_list = []\n",
    "# for index_i in index_list:\n",
    "#     if random.random() > 0.9:\n",
    "#         filtered_index_list.append(index_i)\n",
    "\n",
    "# len(filtered_index_list)\n",
    "\n",
    "# df_old = df_old.loc[filtered_index_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_i = df_old[df_old[\"default_columns\"][\"id\"] == \"225\"].iloc[0]\n",
    "\n",
    "# for j_cnt, row_j in df_new.iterrows():\n",
    "#     comp_list_j = compare_bulk_protos(row_i, row_j)\n",
    "#     if all(comp_list_j):\n",
    "#         print(row_j)\n",
    "#         print(\"\")\n",
    "#         print(\"\")\n",
    "#         print(\"\")\n",
    "# #         print(\"lskfksf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.loc[0]\n",
    "\n",
    "# df_new.loc[231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_i = row_i[\"prototype_info\"][\"wyckoff_i\"]\n",
    "# val_j = row_j[\"prototype_info\"][\"wyckoff_i\"]\n",
    "\n",
    "# print(val_i)\n",
    "# print(val_j)\n",
    "\n",
    "# list(set(val_i)) == list(set(val_j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
