{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# | - Import Modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "def get_ml_dataframes(\n",
    "    names=[\n",
    "        \"bulk_dft_data_path\",\n",
    "        \"unique_ids_path\",\n",
    "        \"prototypes_data_path\",\n",
    "        \"static_irox_structures_path\",\n",
    "        \"static_irox_structures_kirsten_path\",\n",
    "        \"oqmd_irox_data_path\",\n",
    "        \"df_features_pre_opt_path\",\n",
    "        \"df_features_pre_opt_kirsten_path\",\n",
    "        \"df_features_post_opt_path\",\n",
    "        # \"df_features_path\",\n",
    "        # \"df_features_cleaned_path\",\n",
    "        # \"df_features_cleaned_pca_path\",\n",
    "        \"oer_bulk_structures_path\",\n",
    "        \"df_ccf_path\",\n",
    "        \"df_dij_path\",\n",
    "        \"ids_to_discard__too_many_atoms_path\",\n",
    "        ],\n",
    "\n",
    "    ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # | - get_ml_dataframes\n",
    "\n",
    "    # | - Import paths from data file\n",
    "    sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "    from proj_data_irox import (\n",
    "        bulk_dft_data_path,\n",
    "        unique_ids_path,\n",
    "        prototypes_data_path,\n",
    "        static_irox_structures_path,\n",
    "        static_irox_structures_kirsten_path,\n",
    "        oqmd_irox_data_path,\n",
    "        fp_base_path,\n",
    "        df_features_pre_opt_path,\n",
    "        df_features_pre_opt_kirsten_path,\n",
    "        df_features_post_opt_path,\n",
    "        # df_features_path,\n",
    "        # df_features_cleaned_path,\n",
    "        # df_features_cleaned_pca_path,\n",
    "        oer_bulk_structures_path,\n",
    "        df_ccf_path,\n",
    "        df_dij_path,\n",
    "        ids_to_discard__too_many_atoms_path,\n",
    "        )\n",
    "\n",
    "    data_paths = {\n",
    "        \"bulk_dft_data_path\": bulk_dft_data_path,\n",
    "        \"unique_ids_path\": unique_ids_path,\n",
    "        \"prototypes_data_path\": prototypes_data_path,\n",
    "        \"static_irox_structures_path\": static_irox_structures_path,\n",
    "        \"static_irox_structures_kirsten_path\":\n",
    "            static_irox_structures_kirsten_path,\n",
    "        \"oqmd_irox_data_path\": oqmd_irox_data_path,\n",
    "        \"df_features_pre_opt_path\": df_features_pre_opt_path,\n",
    "        \"df_features_pre_opt_kirsten_path\": df_features_pre_opt_kirsten_path,\n",
    "        \"df_features_post_opt_path\": df_features_post_opt_path,\n",
    "        # \"df_features_path\": df_features_path,\n",
    "        # \"df_features_cleaned_path\": df_features_cleaned_path,\n",
    "        # \"df_features_cleaned_pca_path\": df_features_cleaned_pca_path,\n",
    "        \"oer_bulk_structures_path\": oer_bulk_structures_path,\n",
    "        \"df_ccf_path\": df_ccf_path,\n",
    "        \"df_dij_path\": df_dij_path,\n",
    "        \"ids_to_discard__too_many_atoms_path\":\n",
    "            ids_to_discard__too_many_atoms_path,\n",
    "        }\n",
    "    #__|\n",
    "\n",
    "    temp = data_paths\n",
    "    data_dict = dict()\n",
    "    for key, path in temp.items():\n",
    "\n",
    "        if key not in names:\n",
    "            continue\n",
    "\n",
    "        if key[-5:] == \"_path\":\n",
    "            key_new = key[:-5]\n",
    "        else:\n",
    "            key_new = key\n",
    "\n",
    "        is_pickle = False\n",
    "        is_csv = False\n",
    "        try:\n",
    "            ext = path.split(\"/\")[-1].split(\".\")[-1]\n",
    "            if ext == \"pickle\":\n",
    "                is_pickle = True\n",
    "            if ext == \"csv\":\n",
    "                is_csv = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        data_i = None\n",
    "        if is_pickle:\n",
    "            try:\n",
    "                #  print(\"TEMP sidjfijsd9i\", path)\n",
    "                with open(path, \"rb\") as fle:\n",
    "                    data_i = pickle.load(fle)\n",
    "            except:\n",
    "                data_i = None\n",
    "        elif is_csv:\n",
    "            data_i = pd.read_csv(path)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if data_i is None:\n",
    "            print(key)\n",
    "            print(ext)\n",
    "\n",
    "        data_dict[key_new] = data_i\n",
    "\n",
    "    temp = data_dict\n",
    "    return(temp)\n",
    "    #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoich=\"AB3\"\n",
    "verbose=False\n",
    "drop_too_many_atoms=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data_for_al(\n",
    "#     stoich=\"AB2\",\n",
    "#     verbose=True,\n",
    "#     drop_too_many_atoms=True,\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - get_data_for_al\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (ids_to_discard__too_many_atoms_path)\n",
    "\n",
    "# | - Get all necessary dfs\n",
    "df_dict = get_ml_dataframes(\n",
    "    names=[\n",
    "        \"bulk_dft_data_path\",\n",
    "        \"unique_ids_path\",\n",
    "        # \"prototypes_data_path\",\n",
    "        \"static_irox_structures_path\",\n",
    "        # \"static_irox_structures_kirsten_path\",\n",
    "        # \"oqmd_irox_data_path\",\n",
    "        \"df_features_pre_opt_path\",\n",
    "        \"df_features_pre_opt_kirsten_path\",\n",
    "        \"df_features_post_opt_path\",\n",
    "        # \"oer_bulk_structures_path\",\n",
    "        # \"df_ccf_path\",\n",
    "        \"df_dij_path\",\n",
    "        # \"ids_to_discard__too_many_atoms_path\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "df_ids = df_dict.get(\"unique_ids\", None)\n",
    "df_bulk_dft = df_dict.get(\"bulk_dft_data\", None)\n",
    "df_features_pre = df_dict.get(\"df_features_pre_opt\", None)\n",
    "# df_features_pre = df_dict.get(\"df_features_pre_opt_kirsten\", None)\n",
    "df_features_post = df_dict.get(\"df_features_post_opt\", None)\n",
    "\n",
    "df_dij = df_dict.get(\"df_dij\", None)\n",
    "\n",
    "\n",
    "df_static_irox = df_dict.get(\"static_irox_structures\", None)\n",
    "#__|\n",
    "\n",
    "# | - Filter ids to user specifications\n",
    "df_ids = df_ids[\n",
    "    (df_ids[\"stoich\"] == stoich) & \\\n",
    "    (df_ids[\"source\"] != \"oqmd\") & \\\n",
    "    (df_ids[\"source\"] != \"raul_oer\") & \\\n",
    "    [True for i in range(len(df_ids))]]\n",
    "ids = df_ids[\"unique_ids\"]\n",
    "#__|\n",
    "\n",
    "# #####################################################\n",
    "\n",
    "# | - DFT dataframe\n",
    "df_i = df_bulk_dft\n",
    "\n",
    "# print(\"isidfjisdjifjsidjf8yu2894h90832uy4908tyu98023wht0982quj098gtfujw3e\")\n",
    "# print(df_i.index.shape)\n",
    "# print(df_i.index.unique().shape)\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_i = df_i[df_i.source == \"raul\"]\n",
    "\n",
    "df_bulk_dft = df_i\n",
    "\n",
    "print(\"TEMP TEMP TEMP 89ihsjdgf\", \"6dzhcimdxs\" in df_bulk_dft.index)\n",
    "#__|\n",
    "\n",
    "# | - Featurs pre-DFT\n",
    "df_i = df_features_pre\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_features_pre = df_i\n",
    "\n",
    "df_features_pre = df_features_pre[\"voronoi\"]\n",
    "#__|\n",
    "\n",
    "# | - Features post-DFT\n",
    "df_i = df_features_post\n",
    "\n",
    "# Common ids between user ids and df\n",
    "common_ids = list(set(df_i.index) & set(ids))\n",
    "\n",
    "ids_not_in__df_i = [i for i in ids if i not in common_ids]\n",
    "\n",
    "df_i = df_i.loc[common_ids]\n",
    "\n",
    "if verbose:\n",
    "    print(\"len(ids):\", len(ids))\n",
    "    print(\"len(common_ids)\", len(common_ids))\n",
    "    print(\"len(ids_not_in__bulk_dft_data):\", len(ids_not_in__df_i))\n",
    "    print(\"\\n\", \"df_i.shape: \", df_i.shape, sep=\"\")\n",
    "\n",
    "df_features_post = df_i\n",
    "\n",
    "# Only use post-DFT features from my data set\n",
    "df_features_post = \\\n",
    "    df_features_post[df_features_post[\"data\"][\"source\"] == \"raul\"]\n",
    "\n",
    "df_features_post = df_features_post[\"voronoi\"]\n",
    "#__|\n",
    "\n",
    "\n",
    "# | - Dropping certain rows\n",
    "all_ids = list(set(\n",
    "    df_bulk_dft.index.tolist() + \\\n",
    "    df_features_pre.index.tolist() + \\\n",
    "    df_features_post.index.tolist() ))\n",
    "\n",
    "\n",
    "ids_to_drop = []\n",
    "\n",
    "# #########################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures/out_data\",\n",
    "    \"ids_to_discard__proto_dupl.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    ids_to_discard__proto_dupl = pickle.load(fle)\n",
    "    ids_to_drop.extend(ids_to_discard__proto_dupl)\n",
    "# #########################################################################\n",
    "\n",
    "if drop_too_many_atoms:\n",
    "    # #####################################################################\n",
    "    with open(ids_to_discard__too_many_atoms_path, \"rb\") as fle:\n",
    "        ids_to_drop__too_many_atoms = pickle.load(fle)\n",
    "        ids_to_drop.extend(ids_to_drop__too_many_atoms)\n",
    "\n",
    "        # ids_to_drop = ids_to_drop__too_many_atoms\n",
    "        # ids_to_drop = [i for i in ids_to_drop if i in all_ids]\n",
    "    # #####################################################################\n",
    "\n",
    "\n",
    "ids_to_drop = [i for i in ids_to_drop if i in all_ids]\n",
    "\n",
    "# print(\"in ids to drop\", \"6fcdbh9fz2\" in ids_to_drop)\n",
    "\n",
    "print('\"6dzhcimdxs\" in df_features_pre.index:', \"\\n\", \"6dzhcimdxs\" in df_features_pre.index)\n",
    "df_features_pre = df_features_pre.drop(\n",
    "    labels=ids_to_drop, axis=0)\n",
    "print('\"6dzhcimdxs\" in df_features_pre.index:', \"\\n\", \"6dzhcimdxs\" in df_features_pre.index)\n",
    "\n",
    "df_i = df_features_post\n",
    "df_features_post = df_i.loc[\n",
    "    df_i.index.intersection(\n",
    "        df_features_pre.index.unique()\n",
    "        ).unique()\n",
    "    ]\n",
    "\n",
    "\n",
    "print(\"TEMP TEMP TEMP 89ihsjdgf\", \"6dzhcimdxs\" in df_bulk_dft.index)\n",
    "\n",
    "df_bulk_dft = df_bulk_dft.loc[\n",
    "    df_bulk_dft.index.intersection(\n",
    "        df_features_pre.index\n",
    "        ).unique()\n",
    "    ]\n",
    "\n",
    "print(\"TEMP TEMP TEMP 89ihsjdgf\", \"6dzhcimdxs\" in df_bulk_dft.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_discard__proto_dupl\n",
    "\n",
    "# ids_to_drop__too_many_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\"6dzhcimdxs\" in df_features_pre.index:', \"\\n\", \"6dzhcimdxs\" in df_features_pre.index)"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_static_irox = df_static_irox.loc[\n",
    "#     df_static_irox.index.intersection(\n",
    "#         df_features_pre.index\n",
    "#         ).unique()\n",
    "#     ]\n",
    "\n",
    "# ids_static = df_dij.index.intersection(df_static_irox[\"static_id\"])\n",
    "# ids_completed_post_dft = \\\n",
    "#     df_dij.index.intersection(df_features_pre.index)\n",
    "\n",
    "\n",
    "# # print(\"TEMP TEMP TEMP\", \"6fcdbh9fz2\" in df_dij.index)\n",
    "\n",
    "# ids_dij = ids_static.tolist() + ids_completed_post_dft.tolist()\n",
    "# df_dij = df_dij.loc[ids_dij, ids_dij]\n",
    "\n",
    "# #__|\n",
    "\n",
    "# out_dict = dict()\n",
    "\n",
    "# out_dict[\"df_features_post\"] = df_features_post\n",
    "# out_dict[\"df_features_pre\"] = df_features_pre\n",
    "# out_dict[\"df_bulk_dft\"] = df_bulk_dft\n",
    "\n",
    "# # TEMP\n",
    "# out_dict[\"df_ids\"] = df_ids\n",
    "# out_dict[\"df_dij\"] = df_dij\n",
    "# out_dict[\"df_static_irox\"] = df_static_irox\n",
    "\n",
    "\n",
    "# # return(out_dict)\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# al_data_dict = get_data_for_al(\n",
    "#     stoich=\"AB3\",\n",
    "#     verbose=False,\n",
    "#     drop_too_many_atoms=True,\n",
    "#     )\n",
    "\n",
    "# df_features_post = al_data_dict['df_features_post']\n",
    "# df_features_pre = al_data_dict['df_features_pre']\n",
    "# df_bulk_dft = al_data_dict['df_bulk_dft']\n",
    "# df_ids = al_data_dict['df_ids']\n",
    "# df_dij = al_data_dict['df_dij']\n",
    "# df_static_irox = al_data_dict['df_static_irox']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
