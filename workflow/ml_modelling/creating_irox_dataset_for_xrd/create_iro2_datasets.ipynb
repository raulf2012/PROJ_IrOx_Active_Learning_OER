{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ML Active Learning Workflow\n",
    "---\n",
    "\n",
    "32 (Too big, not computed),\n",
    "\n",
    "226 (Not computed),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#| - OUT_OF_SIGHT\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ase.visualize import view\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (\n",
    "    bulk_dft_data_path, unique_ids_path,\n",
    "    df_features_pre_opt_path,\n",
    "    df_features_post_opt_path,\n",
    "    ids_to_discard__too_many_atoms_path,\n",
    "    )\n",
    "\n",
    "from plotting.my_plotly import my_plotly_plot\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "sys.path.insert(0,\n",
    "    os.path.join(os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "\n",
    "from ml_methods import create_mixed_df\n",
    "\n",
    "from ase_modules.ase_methods import view_in_vesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoich_i = \"AB3\"\n",
    "stoich_i = \"AB2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)\n",
    "\n",
    "df_ids = pd.read_csv(unique_ids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering dataframes to the correct stoicheometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP DROP DUPLICATE and OUTLIER SYSTEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ids_to_drop): 188\n",
      "len(ids_to_drop): 187\n"
     ]
    }
   ],
   "source": [
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/ccf_similarity_analysis/out_data\",\n",
    "    \"all_ids_to_elim.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    ids_to_drop__duplicates = pickle.load(fle)\n",
    "    ids_to_drop__duplicates = ids_to_drop__duplicates[stoich_i]\n",
    "\n",
    "# #############################################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"workflow/ml_modelling/visualizing_data/out_data\",\n",
    "    \"outlier_features.json\")\n",
    "with open(path_i, 'r') as f:\n",
    "    ids_to_drop__outliers = json.load(f)\n",
    "\n",
    "with open(ids_to_discard__too_many_atoms_path, \"rb\") as fle:\n",
    "    ids_to_drop__too_many_atoms = pickle.load(fle)\n",
    "\n",
    "# #############################################################################\n",
    "ids_to_drop = [] + \\\n",
    "    ids_to_drop__outliers + \\\n",
    "    ids_to_drop__duplicates + \\\n",
    "    ids_to_drop__too_many_atoms + \\\n",
    "    []\n",
    "\n",
    "print(\"len(ids_to_drop):\", len(ids_to_drop))\n",
    "ids_to_drop = list(set(ids_to_drop))\n",
    "print(\"len(ids_to_drop):\", len(ids_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ids.shape: (697, 5)\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Filter ids ##################################################################\n",
    "df_ids = df_ids[\n",
    "    (df_ids[\"stoich\"] == stoich_i) & \\\n",
    "    (df_ids[\"source\"] != \"oqmd\") & \\\n",
    "    (df_ids[\"source\"] != \"raul_oer\") & \\\n",
    "    [True for i in range(len(df_ids))]\n",
    "    ]\n",
    "\n",
    "print(\"df_ids.shape:\", df_ids.shape)\n",
    "# IDS TO DROP\n",
    "df_ids = df_ids[~df_ids[\"unique_ids\"].isin(ids_to_drop)]\n",
    "unique_ids = df_ids[\"unique_ids\"].tolist()\n",
    "\n",
    "index_filter = np.intersect1d(df_bulk_dft.index, unique_ids)\n",
    "df_bulk_dft = df_bulk_dft.loc[index_filter]\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] != \"chris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "directory = \"out_data/\" + stoich_i + \"_structures\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"atoms\",\n",
    "    \"form_e_chris\",\n",
    "    \"id\",\n",
    "    \"path\",\n",
    "    \"source\",\n",
    "    \"stoich\",\n",
    "    ]\n",
    "\n",
    "df_select = df_bulk_dft.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_bulk_dft = df_bulk_dft.sort_values(\"energy_pa\")\n",
    "\n",
    "df_bulk_dft[\"energy_order_id\"] = [i for i in range(len(df_bulk_dft))]\n",
    "\n",
    "df_select = df_bulk_dft.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.to_csv(\"out_data/data_table_\" + stoich_i + \".csv\")\n",
    "\n",
    "for i_cnt, row_i in df_bulk_dft.iterrows():\n",
    "    atoms = row_i[\"atoms\"]\n",
    "    file_name_i = \"\" + \\\n",
    "        str(row_i[\"energy_order_id\"]).zfill(3) + \\\n",
    "        \"__\" + \\\n",
    "        \"id-unique\" + \\\n",
    "        \"_\" + \\\n",
    "        row_i.name + \\\n",
    "        \"__\" + \\\n",
    "        \"id-short\" + \\\n",
    "        \"_\" + \\\n",
    "        str(row_i[\"id_old\"]).zfill(3) + \\\n",
    "        \".cif\"\n",
    "    \n",
    "    atoms.write(\"out_data/\" + stoich_i + \"_structures/\" + file_name_i)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:research-new]",
   "language": "python",
   "name": "conda-env-research-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
