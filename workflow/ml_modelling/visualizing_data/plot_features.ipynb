{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,\n",
    "    os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        \"workflow/ml_modelling/00_ml_workflow\",\n",
    "        \"190611_new_workflow/02_gaus_proc\"))\n",
    "\n",
    "from gp_methods import gp_workflow\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# | - OUT_OF_SIGHT\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "# import time\n",
    "\n",
    "# import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import chart_studio.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import (\n",
    "    bulk_dft_data_path, unique_ids_path,\n",
    "    df_features_pre_opt_path,\n",
    "    df_features_post_opt_path)\n",
    "\n",
    "from gp_methods import gp_model_gpflow, gp_model_catlearn\n",
    "\n",
    "# from methods import get_trace_j\n",
    "# from plotting.my_plotly import my_plotly_plot\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "from gp_methods import gp_workflow, job_aquisition, test_al_conv\n",
    "\n",
    "sys.path.insert(0,\n",
    "    os.path.join(os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "\n",
    "from ml_methods import create_mixed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoich_i = \"AB2\"\n",
    "stoich_i = \"AB3\"\n",
    "\n",
    "# gp_model = gp_model_gpflow\n",
    "gp_model = gp_model_catlearn\n",
    "\n",
    "aqs_bin_size = 10\n",
    "\n",
    "# output_key = \"form_e_chris\"\n",
    "output_key = \"energy_pa\"\n",
    "\n",
    "verbosity_level = 6  # 1-10 scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_dft_data_path, \"rb\") as fle:\n",
    "    df_bulk_dft = pickle.load(fle)\n",
    "\n",
    "with open(df_features_pre_opt_path, \"rb\") as fle:\n",
    "    df_features_pre = pickle.load(fle)\n",
    "\n",
    "with open(df_features_post_opt_path, \"rb\") as fle:\n",
    "    df_features_post = pickle.load(fle)\n",
    "\n",
    "df_ids = pd.read_csv(unique_ids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_dft.loc[\n",
    "    ['mony9ibt9r', '8avd8d7rbe', 'zwnung6s71', '7f7svsnpvg', 'x48d9oc591']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_drop = ['mony9ibt9r', '8avd8d7rbe', 'zwnung6s71', '7f7svsnpvg', 'x48d9oc591']\n",
    "\n",
    "import json\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(os.path.join(directory, 'outlier_features.json'), 'w') as outfile: \n",
    "    json.dump(ids_to_drop, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Filter ids ##################################################################\n",
    "df_ids = df_ids[\n",
    "    (df_ids[\"stoich\"] == stoich_i) & \\\n",
    "    (df_ids[\"source\"] != \"oqmd\") & \\\n",
    "    # (df_ids[\"source\"] != \"raul\")\n",
    "    [True for i in range(len(df_ids))]\n",
    "    ]\n",
    "\n",
    "# IDS TO DROP\n",
    "df_ids = df_ids[~df_ids[\"unique_ids\"].isin(ids_to_drop)]\n",
    "unique_ids = df_ids[\"unique_ids\"].tolist()\n",
    "\n",
    "# TEMP | Not needed anymore, taken care of on line 9\n",
    "# unique_ids = [x for x in unique_ids if x not in ids_to_drop]\n",
    "\n",
    "# #############################################################################\n",
    "# Training Features ###########################################################\n",
    "index_filter = np.intersect1d(df_features_post.index, unique_ids)\n",
    "df_features_post = df_features_post.loc[index_filter]\n",
    "\n",
    "# #############################################################################\n",
    "# Training Features ###########################################################\n",
    "index_filter = np.intersect1d(df_bulk_dft.index, unique_ids)\n",
    "df_bulk_dft = df_bulk_dft.loc[index_filter]\n",
    "\n",
    "# #############################################################################\n",
    "# Test Features ###############################################################\n",
    "index_filter = np.intersect1d(df_features_pre.index, unique_ids)\n",
    "df_features_pre = df_features_pre.loc[index_filter]\n",
    "\n",
    "# #############################################################################\n",
    "# Filter training data ########################################################\n",
    "df_features_post = \\\n",
    "    df_features_post[df_features_post[\"data\"][\"source\"] != \"chris\"]\n",
    "df_bulk_dft = df_bulk_dft[df_bulk_dft[\"source\"] != \"chris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "sys.path.insert(0,\n",
    "    os.path.join(os.environ[\"PROJ_irox\"], \"workflow/ml_modelling\"))\n",
    "\n",
    "all_ids = df_features_pre.index.unique()\n",
    "\n",
    "computed_ids = df_bulk_dft.index.unique()\n",
    "computed_ids = np.random.choice(computed_ids, size=10)\n",
    "computed_ids = list(computed_ids)\n",
    "\n",
    "# TEMP | Use all training data initially\n",
    "computed_ids = df_bulk_dft.index.tolist()\n",
    "\n",
    "df_post = df_features_post[\"voronoi\"]\n",
    "df_pre = df_features_pre[\"voronoi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# num_training = str(len(computed_ids)).zfill(3)\n",
    "# step_num = str(i_cnt).zfill(3); i_cnt_str = str(i_cnt).zfill(3)\n",
    "# print(step_num, \" | \", num_training + \" \" + 68 * \"#\"); print(80 * \"#\")\n",
    "# row_i = df_gp_params.iloc[0]\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "df_test_tmp = create_mixed_df(\n",
    "    all_ids, computed_ids,\n",
    "    df_post, df_pre, verbose=False)\n",
    "# df_test_tmp = df_pre\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "# #########################################################################\n",
    "# computed_ids = [i for i in computed_ids if i in df_bulk_dft.index]\n",
    "\n",
    "# computed_ids = df_bulk_dft.index.tolist()\n",
    "computed_ids = list(set(computed_ids))\n",
    "\n",
    "\n",
    "# TEMP | Needed because of nan in df_train\n",
    "# computed_ids = [i for i in computed_ids if i in df_post.index]\n",
    "\n",
    "\n",
    "df_bulk_dft_i = df_bulk_dft.loc[computed_ids]\n",
    "# df_train = df_post.loc[computed_ids]\n",
    "\n",
    "df_train = df_post.loc[computed_ids]\n",
    "\n",
    "# #########################################################################\n",
    "# Running GP Model ########################################################\n",
    "# gp_params_i = row_i.to_dict()\n",
    "\n",
    "out = gp_workflow(\n",
    "    df_features_post=df_train, df_test=df_test_tmp,\n",
    "    df_bulk_dft=df_bulk_dft_i, df_bulk_dft_all=df_bulk_dft,\n",
    "    df_ids=df_ids, gp_model=gp_model_catlearn,\n",
    "    opt_hyperparameters=True, gp_params=None,\n",
    "    y_train_key=\"energy_pa\", run_gp=False)\n",
    "model_i = out[\"model\"]; model_inst = out[\"model_inst\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data.shape: (155, 271)\n",
    "train_data.shape: (155, 254)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()\n",
    "\n",
    "train_x = out[\"train_x\"]\n",
    "train_y = out[\"train_y\"]\n",
    "train_y_standard = out[\"train_y_standard\"]\n",
    "\n",
    "test_x = out[\"test_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.concat(\n",
    "    [\n",
    "        train_x,\n",
    "        train_y,\n",
    "        # train_y_standard,\n",
    "        ],\n",
    "    axis=1\n",
    "    )\n",
    "\n",
    "test_x = test_x.drop(\n",
    "    # labels=df_m[\"id_unique\"].unique().tolist(),\n",
    "    labels=df_m.index.unique().tolist(),\n",
    "    )\n",
    "\n",
    "df_m = pd.concat([\n",
    "    df_m,\n",
    "    test_x,\n",
    "    ])\n",
    "\n",
    "df_m[\"id\"] = df_m.index\n",
    "df_m = df_m.sort_values(\"energy_pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_m.fillna(\n",
    "    value=-4.51082304,\n",
    "    method=None,\n",
    "    axis=None,\n",
    "    inplace=False,\n",
    "    limit=None,\n",
    "    downcast=None,\n",
    "    # **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_m.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_m.describe())\n",
    "print(\"\")\n",
    "display(df_m.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = df_m\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x=\"PCA0\",\n",
    "    y=\"PCA1\",\n",
    "    z=\"PCA2\",\n",
    "#     z=\"energy_pa\",\n",
    "    color='energy_pa',\n",
    "#     text='id',\n",
    "\n",
    "    range_x=None,\n",
    "    range_y=None,\n",
    "    range_z=None,\n",
    "    )\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.data[0]\n",
    "\n",
    "df_m.sort_values(\"PCA1\", ascending=False)[0:5][\"index\"].tolist()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
