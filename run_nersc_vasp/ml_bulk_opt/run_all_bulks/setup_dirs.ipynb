{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from shutil import copyfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# #############################################################################\n",
    "import pandas as pd\n",
    "\n",
    "from ase import io\n",
    "from ase.visualize import view\n",
    "\n",
    "# #############################################################################\n",
    "from dft_job_automat.compute_env import ComputerCluster\n",
    "\n",
    "from methods import calc_wall_time\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import proj_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(\n",
    "    os.environ[\"PROJ_irox\"],\n",
    "    \"run_nersc_vasp/ml_bulk_opt\",\n",
    "    \"bulk_opt_init.py\",\n",
    "    )\n",
    "\n",
    "rootdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_files_dir = os.path.join(\n",
    "    os.environ[\"PROJ_DATA\"],\n",
    "    \"04_IrOx_surfaces_OER/ml_bulk_static_preopt_structures\",\n",
    "    \"fixed_prototypes_iro2\",\n",
    "    )\n",
    "\n",
    "data_list = []\n",
    "for subdir, dirs, files in os.walk(structure_files_dir):\n",
    "    for file in files:\n",
    "        file_path_i = os.path.join(subdir, file)\n",
    "\n",
    "        path_short = file_path_i.replace(os.environ[\"PROJ_irox\"] + \"/\", \"\")\n",
    "\n",
    "        atoms_i = io.read(file_path_i)\n",
    "\n",
    "        num_atoms_i = atoms_i.get_number_of_atoms()\n",
    "\n",
    "        data_list.append({\n",
    "            \"path\": file_path_i,\n",
    "            \"path_short\": path_short,\n",
    "            \"file_name\": file,\n",
    "            \"init_atoms\": atoms_i,\n",
    "            \"number_of_atoms\": num_atoms_i,\n",
    "            \"id\": int(file.split(\"_\")[0]),\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df = df.sort_values(\"id\")\n",
    "\n",
    "# Filtering large structures (more than 100 atoms in cell)\n",
    "df = df[df[\"number_of_atoms\"] < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering with id list"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ids_to_run import ids_to_run\n",
    "df = df[df[\"id\"].isin(ids_to_run)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = rootdir\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_job(\n",
    "    wall_time_i=None,\n",
    "    nodes_i=None,\n",
    "    job_0_dir_i=None,\n",
    "    ):\n",
    "    CC = ComputerCluster()\n",
    "\n",
    "    if os.environ[\"COMPENV\"] == \"sherlock\":\n",
    "        def_params = {\n",
    "            \"wall_time\": wall_time_i,\n",
    "            \"nodes\": nodes_i,\n",
    "            \"path_i\": job_0_dir_i}\n",
    "\n",
    "    elif os.environ[\"COMPENV\"] == \"slac\":\n",
    "        def_params = {\n",
    "            \"wall_time\": wall_time_i,\n",
    "            \"cpus\": 12,\n",
    "            \"queue\": \"suncat2\",\n",
    "            \"path_i\": job_0_dir_i}\n",
    "\n",
    "    else:\n",
    "        def_params = {\n",
    "            \"wall_time\": wall_time_i,\n",
    "            # \"queue\": \"premium\",\n",
    "            \"queue\": \"regular\",\n",
    "            \"architecture\": \"knl\",\n",
    "            \"nodes\": nodes_i,\n",
    "            \"path_i\": job_0_dir_i}\n",
    "\n",
    "    CC.submit_job(**def_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_cnt, row_i in df.iterrows():\n",
    "    folder_name = str(row_i[\"id\"]).zfill(3)\n",
    "\n",
    "    job_root_dir_i = os.path.join(\n",
    "        rootdir,\n",
    "        \"job_folders\",\n",
    "        folder_name)\n",
    "\n",
    "    job_0_dir_i = os.path.join(job_root_dir_i, \"_1\")\n",
    "\n",
    "\n",
    "    # Checkif job dir is already present\n",
    "    job_folder = Path(job_root_dir_i)\n",
    "    if job_folder.is_dir():\n",
    "        print(\"Job dir already exists, skipping\")\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(job_0_dir_i)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Write atoms object\n",
    "        atoms_i = row_i[\"init_atoms\"]\n",
    "        io.write(os.path.join(job_0_dir_i, \"init.cif\"), row_i[\"init_atoms\"])\n",
    "\n",
    "\n",
    "        dft_params_dict = {\n",
    "            # \"encut\": 600,\n",
    "            # \"kpar\": 5,\n",
    "            # \"ediffg\": 5e-3,\n",
    "            # \"ediff\": 1e-6\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "        num_atoms = atoms_i.get_number_of_atoms()\n",
    "        wall_time_i = calc_wall_time(num_atoms, factor=1.4)\n",
    "        wall_time_i = int(wall_time_i)\n",
    "\n",
    "        if num_atoms > 100:\n",
    "            nodes_i = 10\n",
    "            dft_params_dict[\"kpar\"] = 10\n",
    "        else:\n",
    "            nodes_i = 5\n",
    "            dft_params_dict[\"kpar\"] = 5\n",
    "\n",
    "        if os.environ[\"COMPENV\"] == \"sherlock\":\n",
    "            print(\"SDIJFIDSJIFJDISJFIJSDIFJIDSJF\")\n",
    "            dft_params_dict[\"npar\"] = 4\n",
    "\n",
    "        if os.environ[\"COMPENV\"] == \"slac\":\n",
    "            dft_params_dict[\"kpar\"] = 3\n",
    "            dft_params_dict[\"npar\"] = 4\n",
    "\n",
    "        if os.environ[\"COMPENV\"] != \"slac\":\n",
    "            if wall_time_i > 600:\n",
    "                wall_time_i = 600\n",
    "        else:\n",
    "            wall_time_i = 8. * wall_time_i\n",
    "\n",
    "            if wall_time_i > 2760:\n",
    "                wall_time_i = 2760\n",
    "\n",
    "        \n",
    "        # Write dft paramters json file to job dir\n",
    "        with open(os.path.join(job_0_dir_i, \"dft-params.json\"), \"w+\") as fle:\n",
    "            json.dump(dft_params_dict, fle, indent=2, skipkeys=True)\n",
    "\n",
    "        # Copy model job script\n",
    "        copyfile(model_file, os.path.join(job_0_dir_i, \"model.py\"))\n",
    "\n",
    "\n",
    "        # Submit job ##############################################################\n",
    "        submit_job(\n",
    "            wall_time_i=int(wall_time_i),\n",
    "            nodes_i=nodes_i,\n",
    "            job_0_dir_i=job_0_dir_i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "#         CC = ComputerCluster()\n",
    "\n",
    "#         if os.environ[\"COMPENV\"] == \"sherlock\":\n",
    "#             def_params = {\n",
    "#                 \"wall_time\": wall_time_i,\n",
    "#                 \"nodes\": nodes_i,\n",
    "#                 \"path_i\": job_0_dir_i}\n",
    "#         elif os.environ[\"COMPENV\"] == \"slac\":\n",
    "#             def_params = {\n",
    "#                 \"wall_time\": wall_time_i,\n",
    "#                 \"cpus\": 30,\n",
    "#                 \"path_i\": job_0_dir_i}\n",
    "\n",
    "#         else:\n",
    "#             def_params = {\n",
    "#                 \"wall_time\": wall_time_i,\n",
    "#                 # \"queue\": \"premium\",\n",
    "#                 \"queue\": \"regular\",\n",
    "#                 \"architecture\": \"knl\",\n",
    "#                 \"nodes\": nodes_i,\n",
    "#                 \"path_i\": job_0_dir_i}\n",
    "\n",
    "#         CC.submit_job(**def_params)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
