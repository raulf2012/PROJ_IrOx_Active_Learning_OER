{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't change the order of the `notebooks_to_run_list` list! The order is criticial for this to work"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_i = \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures/create_atoms_df.ipynb\"\n",
    "\n",
    "notebooks_to_run_list = [\n",
    "    # #####################################################\n",
    "    # Figure S1 (MAE vs PCA comp)\n",
    "                        \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures/create_atoms_df.ipynb\",\n",
    "                    \"workflow/ml_modelling/processing_bulk_dft/parse_oqmd_data/prepare_oqmd_data.ipynb \",\n",
    "                    \"workflow/ml_modelling/processing_bulk_dft/parse_my_oer_bulk_dft/an_parse_oer_bulk_systems.ipynb\",\n",
    "                    \"workflow/ml_modelling/processing_bulk_dft/parse_my_bulk_dft/parse_my_bulk_dft.ipynb\",\n",
    "                \"workflow/ml_modelling/processing_bulk_dft/collect_all_bulk_dft_data.ipynb\",\n",
    "                        \"workflow/ml_modelling/ccf_similarity_analysis/compute_ccf_and_dij_matrix/compute_ccf__v1.ipynb\",\n",
    "                    \"workflow/ml_modelling/ccf_similarity_analysis/compute_ccf_and_dij_matrix/get_d_ij_matrix__v1.ipynb\",\n",
    "                    \"workflow/ml_modelling/processing_bulk_dft/static_prototypes_structures/elim_high_num_atom_cnt.ipynb\",\n",
    "                \"workflow/ml_modelling/00_ml_workflow/get_duplicates_from_al/get_duplicates_list.ipynb\",\n",
    "            \"workflow/ml_modelling/processing_bulk_dft/creating_final_dataset_for_upload/create_final_dft.ipynb\",\n",
    "            \"workflow/ml_modelling/voronoi_featurize/02_fingerprints_pre_opt.ipynb\",\n",
    "        \"workflow/ml_modelling/opt_mae_err_gp_model/cv_error__v3.ipynb\",\n",
    "    \"workflow/ml_modelling/opt_mae_err_gp_model/plotting/plot_cv_error.ipynb\",\n",
    "\n",
    "    # #####################################################\n",
    "    # Figure S2 (IrO2 AL Figure)\n",
    "        \"workflow/ml_modelling/00_ml_workflow/performance_comp/top_10_disc_vs_dft/comp_perf_plots__v2.ipynb\",\n",
    "        \"workflow/ml_modelling/00_ml_workflow/al_plots_for_figure/ml_plots__v5.ipynb\",\n",
    "    \"workflow/ml_modelling/00_ml_workflow/combined_al_plot/create_subplots__v5.ipynb\",\n",
    "\n",
    "    # #####################################################\n",
    "    # Figure S3 (All AL performance traces)\n",
    "        \"workflow/ml_modelling/00_ml_workflow/performance_comp/top_10_disc_vs_dft/comp_perf_plots__v2.ipynb\",\n",
    "    \"workflow/ml_modelling/00_ml_workflow/performance_comp/top_10_disc_vs_dft/01_plot_all_runs/plot_all_runs.ipynb\",\n",
    "\n",
    "    # #####################################################\n",
    "    # Figure S4 (Bulk Pourbaix no IrO3)\n",
    "            \"workflow/energy_treatment_deriv/calc_references/calc_O_Ir_refs__H_G.ipynb\",\n",
    "        \"workflow/07_bulk_pourbaix/01_pourbaix_scripts/sc_create_all_entries.py\",\n",
    "    \"workflow/07_bulk_pourbaix/01_pourbaix_scripts/an_pourbaix_plot.ipynb\",\n",
    "    \n",
    "    # #####################################################\n",
    "    # Figure S5 (OER Scaling)\n",
    "        \"parse_dft_data/parse_all_data_new.ipynb\",\n",
    "    \"workflow/02_oer_analysis/03_ads_e_scaling/an_irox_scaling__v2.ipynb\",\n",
    "    \n",
    "    # #####################################################\n",
    "    # Figure 2 (IrO3 AL Figure)\n",
    "    # Taken care of by previous run of IrO2\n",
    "    \n",
    "    # #####################################################\n",
    "    # Figure 3 (GP parity plot)\n",
    "        \"workflow/ml_modelling/00_ml_workflow/parity_plots/parity_pre_dft.ipynb\", \n",
    "        \"workflow/ml_modelling/00_ml_workflow/parity_plots/parity_post_dft.ipynb\",\n",
    "    \"workflow/ml_modelling/00_ml_workflow/parity_plots/plotting_results.ipynb\",\n",
    "\n",
    "    # #####################################################\n",
    "    # Figure 4 (Bulk Pourbaix w/ IrO3)\n",
    "    # Taken care of above\n",
    "\n",
    "    # #####################################################\n",
    "    # Figure 5 (OER Plot)\n",
    "        \"workflow/07_bulk_pourbaix/01_pourbaix_scripts/sandbox_pourb_transitions.ipynb\",\n",
    "            \"workflow/02_oer_analysis/02_oer_volc/kinetic_volcano_colin__v1.ipynb\",\n",
    "        \"workflow/02_oer_analysis/02_oer_volc/an_irox_volcano_plotly__v1.ipynb\",\n",
    "            \"workflow/energy_treatment_deriv/energy_derivation.ipynb\",\n",
    "        \"workflow/01_surface_energies/02_surface_e_pourb_plot/an_surface-energy_pourbaix__v4.ipynb\",\n",
    "    \"workflow/03_combined_oer_surf_e/an_surface-energy_pourbaix__v4.ipynb\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "notebooks_that_take_stoich_args = [\n",
    "    \"comp_perf_plots__v2.ipynb\",\n",
    "\n",
    "    # Bulk Pourbaix\n",
    "    \"sc_create_all_entries.py\",\n",
    "    \"an_pourbaix_plot.ipynb\",\n",
    "    \n",
    "    # AL IrOx Plots\n",
    "    \"create_subplots__v5.ipynb\",\n",
    "    \n",
    "    # Parity Plot\n",
    "    \"parity_post_dft.ipynb\",\n",
    "    \"parity_pre_dft.ipynb\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for file_i in notebooks_to_run_list:\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    t0_i = time.time()\n",
    "\n",
    "    file_name = file_i.split(\"/\")[-1]\n",
    "    file_ext = file_name.split(\".\")[-1]\n",
    "\n",
    "    print(\"8356\", 55 * \"#\")\n",
    "    print(file_i)\n",
    "    print(file_name)\n",
    "    print(\"8356\", 55 * \"#\")\n",
    "\n",
    "    data_dict_i[\"full_path\"] = file_i\n",
    "    data_dict_i[\"notebook_name\"] = file_name\n",
    "    \n",
    "    # #########################################################\n",
    "    file_path = \"/\".join(file_i.split(\"/\")[0:-1])\n",
    "\n",
    "\n",
    "    python_file_name = file_name.split(\".\")[0] + \".py\"\n",
    "    python_file_full_path = os.path.join(\n",
    "        os.environ[\"PROJ_irox\"],\n",
    "        file_path, python_file_name)\n",
    "\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "    # Change directory\n",
    "    os.chdir(\n",
    "        os.path.join(\n",
    "            os.environ[\"PROJ_irox\"],\n",
    "            file_path))\n",
    "\n",
    "    # #########################################################\n",
    "    # Convert .ipynb file to .py ##############################\n",
    "    bash_comm = \"jupytext --to py \" + file_name\n",
    "\n",
    "    output = None\n",
    "    if not file_ext == \"py\":\n",
    "        try:\n",
    "                output = subprocess.check_output(\n",
    "                    bash_comm,\n",
    "                    stderr=subprocess.STDOUT,\n",
    "                    shell=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            output = e.output\n",
    "\n",
    "        output = output.decode(\"utf-8\")\n",
    "        print(output)\n",
    "\n",
    "    # #########################################################\n",
    "    # Run .py file ############################################\n",
    "    \n",
    "    if file_name in notebooks_that_take_stoich_args:\n",
    "        bash_comm = \"python \" + python_file_full_path + \" AB2\"\n",
    "\n",
    "        output = None\n",
    "        try:\n",
    "            output = subprocess.check_output(\n",
    "                bash_comm, stderr=subprocess.STDOUT, shell=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            output = e.output\n",
    "        output = output.decode(\"utf-8\")\n",
    "        print(output)\n",
    "\n",
    "        # I'll run the next one outside of the if statement as normal by replacing the bash_comm\n",
    "        bash_comm = \"python \" + python_file_full_path + \" AB3\"\n",
    "\n",
    "    else:\n",
    "        bash_comm = \"python \" + python_file_full_path\n",
    "\n",
    "    output = None\n",
    "    try:\n",
    "        output = subprocess.check_output(\n",
    "            bash_comm,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            shell=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        output = e.output\n",
    "\n",
    "    output = output.decode(\"utf-8\")\n",
    "    print(output)\n",
    "\n",
    "    # #########################################################\n",
    "    completed_correctly = \"All done!\" in output\n",
    "    data_dict_i[\"completed\"] = completed_correctly\n",
    "\n",
    "    # #########################################################\n",
    "    # Change directory\n",
    "    os.chdir(orig_dir)\n",
    "    \n",
    "    \n",
    "    tf_i = time.time()\n",
    "    notebook_run_time = tf_i - t0_i\n",
    "    data_dict_i[\"run_time_s\"] = notebook_run_time\n",
    "    data_dict_i[\"run_time_min\"] = notebook_run_time / 60\n",
    "\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    print(3 * \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# df.iloc[4].full_path\n",
    "# df.sort_values(\"run_time_min\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = time.time() - t0\n",
    "run_time = run_time / 60\n",
    "\n",
    "print(run_time, \"min\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # #########################################################\n",
    "# #\n",
    "# file_name = file_i.split(\"/\")[-1]\n",
    "\n",
    "# file_path = \"/\".join(file_i.split(\"/\")[0:-1])\n",
    "\n",
    "# python_file_name = file_name.split(\".\")[0] + \".py\"\n",
    "\n",
    "# python_file_full_path = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     file_path, python_file_name)\n",
    "\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# # Change directory\n",
    "# os.chdir(\n",
    "#     os.path.join(\n",
    "#         os.environ[\"PROJ_irox\"],\n",
    "#         file_path))\n",
    "\n",
    "# # #########################################################\n",
    "# # Convert .ipynb file to .py ##############################\n",
    "# bash_comm = \"jupytext --to py \" + file_name\n",
    "\n",
    "# output = None\n",
    "# try:\n",
    "#     output = subprocess.check_output(\n",
    "#         bash_comm,\n",
    "#         stderr=subprocess.STDOUT,\n",
    "#         shell=True)\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     output = e.output\n",
    "\n",
    "# output = output.decode(\"utf-8\")\n",
    "# print(output)\n",
    "\n",
    "# # #########################################################\n",
    "# # Run .py file ############################################\n",
    "# bash_comm = \"python \" + python_file_full_path\n",
    "\n",
    "# output = None\n",
    "# try:\n",
    "#     output = subprocess.check_output(\n",
    "#         bash_comm,\n",
    "#         stderr=subprocess.STDOUT,\n",
    "#         shell=True)\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     output = e.output\n",
    "\n",
    "# output = output.decode(\"utf-8\")\n",
    "# print(output)\n",
    "\n",
    "# # #########################################################\n",
    "# # \n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# # Change directory\n",
    "# os.chdir(orig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "\n",
    "# os.system(\"ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash_comm = \"run_jupy \" + file_name\n",
    "\n",
    "# os.system(bash_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash_comm = \"python \" + file_name\n",
    "\n",
    "# # os.system(bash_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# correct = subprocess.run(\n",
    "#     [\"python\", file_name],\n",
    "#     # check=True,\n",
    "#     # text=True,\n",
    "#     shell=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# file_path\n",
    "\n",
    "# # file_i\n",
    "\n",
    "# # file_path = \n",
    "# # \"/\".join(file_i.split(\"/\")[0:-1])\n",
    "# file_i\n",
    "\n",
    "\n",
    "# df.iloc[15].full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# bash_comm = \"python \" + python_file_name\n",
    "# # bash_comm = \"python \" + python_file_full_path\n",
    "# print(bash_comm)\n",
    "\n",
    "# output = subprocess.check_output(\n",
    "#     bash_comm,\n",
    "#     stderr=subprocess.STDOUT,\n",
    "#     shell=True,\n",
    "#     )\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(str(output))\n",
    "# print(str(output))\n",
    "\n",
    "# str(output)[0:10]\n",
    "\n",
    "# bash_comm\n",
    "# correct"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox] *",
   "language": "python",
   "name": "conda-env-PROJ_irox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
