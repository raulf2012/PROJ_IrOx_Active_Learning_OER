{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse extra data\n",
    "---\n",
    "\n",
    "I'm coming back to this after a whle\n",
    "\n",
    "There was only really 1 extra row that I needed to get into the dataframe for processing\n",
    "\n",
    "I'll do that here and then read it in here:\n",
    "\n",
    "PROJ_IrOx_Active_Learning_OER/workflow"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Import Modules\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "from methods import job_maint\n",
    "from dft_job_automat.job_analysis import DFT_Jobs_Analysis\n",
    "from dft_job_automat.job_types_classes.dft_methods import DFT_Methods\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(os.environ[\"PROJ_irox\"], \"data\"))\n",
    "from proj_data_irox import read_from_PROJ_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #########################################################\n",
    "# import pickle; import os\n",
    "# path_i = os.path.join(\n",
    "#     data_dir,\n",
    "#     # \"df_master.pickle\",\n",
    "#     \"job_dataframe.pickle\"\n",
    "#     )\n",
    "\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     df_prev = pickle.load(fle, encoding=\"latin1\")\n",
    "# # #########################################################\n",
    "\n",
    "# df_prev.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Script Parameters\n",
    "parse_data = True\n",
    "parse_all_rev = False\n",
    "\n",
    "maint_data = True\n",
    "cross_check_jobs = True\n",
    "\n",
    "parallel_exec = False\n",
    "#__|\n",
    "\n",
    "from job_dirs import dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list_new = [\n",
    "    \"norskov_research_storage/nersc/IrOx_Project_temp_190510/03_OER_Calc/IrO2/100/01_O_covered/02_ooh/02_face_down_2\"\n",
    "    ]\n",
    "\n",
    "dir_list = []\n",
    "for dir_i in dir_list_new:\n",
    "    dir_new = os.path.join(\n",
    "        os.environ[\"gdrive\"],\n",
    "        dir_i)\n",
    "\n",
    "    dir_list.append(dir_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd_orig = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_from_PROJ_DATA:\n",
    "    import pickle; import os\n",
    "    path_i = os.path.join(\n",
    "        os.environ[\"PROJ_DATA\"],\n",
    "        \"04_IrOx_surfaces_OER/PROJECT_COMPUTED_OUT_DATA/PROJ_IrOx_Active_Learning_OER\",\n",
    "        \"parse_dft_data\",\n",
    "        \"out_data/df_data_new.pickle\")\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_m = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parse_data and not read_from_PROJ_DATA:\n",
    "    # | - Instantiate Classes\n",
    "    dft_inst = DFT_Methods(\n",
    "        methods_to_run=[\n",
    "            \"elec_energy\",\n",
    "            \"init_atoms\",\n",
    "            \"atoms_object\",\n",
    "            # \"incar\",\n",
    "            # \"outcar\"\n",
    "            ],\n",
    "        DFT_code=\"VASP\",\n",
    "        )\n",
    "\n",
    "    Jobs = DFT_Jobs_Analysis(\n",
    "        indiv_dir_lst=dir_list,\n",
    "        working_dir=\".\",\n",
    "        folders_exist=True,\n",
    "        load_dataframe=False,\n",
    "        job_type_class=dft_inst,\n",
    "        parse_all_revisions=parse_all_rev,\n",
    "        parallel_exec=parallel_exec,\n",
    "        )\n",
    "\n",
    "    df_all = Jobs.data_frame\n",
    "    df_m = Jobs.filter_early_revisions(Jobs.data_frame)\n",
    "    #__|\n",
    "os.chdir(cwd_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_data_new.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_m, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #########################################################\n",
    "# import pickle; import os\n",
    "# path_i = os.path.join(\n",
    "#     os.environ[\"PROJ_irox\"],\n",
    "#     \"parse_dft_data/out_data\",\n",
    "#     \"df_data_new.pickle\")\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     df_m = pickle.load(fle)\n",
    "# # #########################################################\n",
    "\n",
    "# pd.concat([\n",
    "# df_m, df_m   \n",
    "    \n",
    "# ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Previous DataFrame and Combine Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if maint_data:\n",
    "    # | - Job Maintance\n",
    "    print(25 * \"*\")\n",
    "\n",
    "    tally = {\"successes\": 0, \"failures\": 0, \"running\": 0, \"pending\": 0}\n",
    "\n",
    "    for Job_i in Jobs.Job_list:\n",
    "        path_i = Job_i.full_path\n",
    "        job_i_params = Job_i.job_params\n",
    "\n",
    "        print(path_i)\n",
    "\n",
    "        tally = job_maint(\n",
    "            0,\n",
    "            path_i,\n",
    "            job_i_params,\n",
    "            {\"jobs_man_list\": [Jobs]},\n",
    "            tally,\n",
    "            file_ops=False,\n",
    "            )\n",
    "    #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cross_check_jobs:\n",
    "    # | - NEW | Parse for Job Folders w/o dir_list\n",
    "    from dft_job_automat.job_analysis import (\n",
    "        parse_job_dirs,\n",
    "        compare_parsed_and_user_job_dirs,\n",
    "        )\n",
    "\n",
    "    rt_1 = os.path.join(os.environ[\"wd\"], \"IrOx_Project\")\n",
    "    dirs_to_parse = [\n",
    "        os.path.join(rt_1, \"01_surface_calcs\"),\n",
    "        os.path.join(rt_1, \"02_surface_coverage\"),\n",
    "        os.path.join(rt_1, \"03_OER_Calc\"),\n",
    "        os.path.join(rt_1, \"07_diff_coverages_term\"),\n",
    "        ]\n",
    "\n",
    "    parsed_dir_list = parse_job_dirs(dirs_to_parse)\n",
    "    compare_parsed_and_user_job_dirs(parsed_dir_list, dir_list)\n",
    "\n",
    "    for path_i in parsed_dir_list:\n",
    "        files_i = os.listdir(path_i)\n",
    "    #__|\n",
    "\n",
    "print(datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox]",
   "language": "python",
   "name": "conda-env-PROJ_irox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
